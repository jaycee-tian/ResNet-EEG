{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets.eegdataset import GeneralEEGImageDataset, MySubset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "data_path = '/data0/tianjunchao/dataset/CVPR2021-02785/data/img_pkl/32x32'\n",
    "# dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, train_test_split\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 定义训练集和测试集的 transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    # rotate 30 degrees\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.CenterCrop(224),\n",
    "    # transforms.Normalize([0.512, 0.512, 0.512], [0.228, 0.228, 0.228]),\n",
    "    # transforms.RandomResizedCrop(224),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    # rotate 30 degress\n",
    "    # transforms.Resize((256, 256)),\n",
    "    # # random crop 224x224\n",
    "    transforms.RandomCrop(224),\n",
    "    # transforms.Normalize([0.512, 0.512, 0.512], [0.228, 0.228, 0.228]),\n",
    "])\n",
    "\n",
    "# random 100 numbers from 100 to 10000\n",
    "train_ids = np.random.choice(10000, 100, replace=False)\n",
    "valid_ids = np.random.choice(10000, 100, replace=False)\n",
    "\n",
    "\n",
    "train_dataset = MySubset(dataset, train_ids,train_transforms,target='train')\n",
    "valid_dataset = MySubset(dataset, valid_ids, test_transforms)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, num_workers=3, prefetch_factor=2)\n",
    "valid_loader = DataLoader(\n",
    "    valid_dataset, batch_size=8, num_workers=1, prefetch_factor=1)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader), len(valid_loader))\n",
    "print(13*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个函数，用于展示图片\n",
    "imgs = []\n",
    "epochs = 2\n",
    "count = 0\n",
    "\n",
    "for data1,data2 in zip(train_loader, valid_loader):\n",
    "    imgs.append((data1[0].permute(0,2,3,1),data2[0].permute(0,2,3,1)))\n",
    "    count += 1\n",
    "    if count == epochs:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = 1\n",
    "# draw 4 images in imgs\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(imgs[indexes][0][i])\n",
    "    ax.set_title('train')\n",
    "    ax.axis('off')\n",
    "fig, axes = plt.subplots(1, 4, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(imgs[indexes][1][i])\n",
    "    ax.set_title('valid')\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129 tensor(0.5064, device='cuda:0') tensor(0.2301, device='cuda:0')\n",
      "1409 tensor(0.5069, device='cuda:0') tensor(0.2306, device='cuda:0')\n",
      "2689 tensor(0.5106, device='cuda:0') tensor(0.2306, device='cuda:0')\n",
      "3969 tensor(0.5106, device='cuda:0') tensor(0.2298, device='cuda:0')\n",
      "5249 tensor(0.5108, device='cuda:0') tensor(0.2295, device='cuda:0')\n",
      "6529 tensor(0.5116, device='cuda:0') tensor(0.2288, device='cuda:0')\n",
      "7809 tensor(0.5121, device='cuda:0') tensor(0.2288, device='cuda:0')\n",
      "9089 tensor(0.5128, device='cuda:0') tensor(0.2284, device='cuda:0')\n",
      "10369 tensor(0.5128, device='cuda:0') tensor(0.2282, device='cuda:0')\n",
      "11649 tensor(0.5124, device='cuda:0') tensor(0.2280, device='cuda:0')\n",
      "12929 tensor(0.5125, device='cuda:0') tensor(0.2278, device='cuda:0')\n",
      "14209 tensor(0.5128, device='cuda:0') tensor(0.2277, device='cuda:0')\n",
      "15489 tensor(0.5128, device='cuda:0') tensor(0.2276, device='cuda:0')\n",
      "16769 tensor(0.5128, device='cuda:0') tensor(0.2276, device='cuda:0')\n",
      "18049 tensor(0.5128, device='cuda:0') tensor(0.2275, device='cuda:0')\n",
      "19329 tensor(0.5128, device='cuda:0') tensor(0.2274, device='cuda:0')\n",
      "20609 tensor(0.5127, device='cuda:0') tensor(0.2274, device='cuda:0')\n",
      "21889 tensor(0.5126, device='cuda:0') tensor(0.2276, device='cuda:0')\n",
      "23169 tensor(0.5125, device='cuda:0') tensor(0.2275, device='cuda:0')\n",
      "24449 tensor(0.5123, device='cuda:0') tensor(0.2276, device='cuda:0')\n",
      "25729 tensor(0.5124, device='cuda:0') tensor(0.2276, device='cuda:0')\n",
      "27009 tensor(0.5123, device='cuda:0') tensor(0.2277, device='cuda:0')\n",
      "28289 tensor(0.5123, device='cuda:0') tensor(0.2277, device='cuda:0')\n",
      "29569 tensor(0.5121, device='cuda:0') tensor(0.2279, device='cuda:0')\n",
      "30849 tensor(0.5121, device='cuda:0') tensor(0.2280, device='cuda:0')\n",
      "32129 tensor(0.5122, device='cuda:0') tensor(0.2280, device='cuda:0')\n",
      "33409 tensor(0.5122, device='cuda:0') tensor(0.2279, device='cuda:0')\n",
      "34689 tensor(0.5122, device='cuda:0') tensor(0.2279, device='cuda:0')\n",
      "35969 tensor(0.5123, device='cuda:0') tensor(0.2278, device='cuda:0')\n",
      "37249 tensor(0.5121, device='cuda:0') tensor(0.2279, device='cuda:0')\n",
      "38529 tensor(0.5122, device='cuda:0') tensor(0.2278, device='cuda:0')\n",
      "39809 tensor(0.5122, device='cuda:0') tensor(0.2278, device='cuda:0')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。请查看单元格中的代码，以确定故障的可能原因。有关详细信息，请单击 <a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>。有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "# 计算均值和标准差\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "n_batches = 0\n",
    "data_stack = torch.zeros((1, 224, 224)).to('cuda')\n",
    "for images, _ in dataloader:\n",
    "    # print(images.shape)\n",
    "    # images.shape is batchsizex3x224x224\n",
    "    # only keep batchsizex1x224x224\n",
    "    images = images[:, 0, :, :].squeeze().to('cuda')\n",
    "    data_stack = torch.cat((data_stack, images), dim=0)\n",
    "    if n_batches%10 == 0:\n",
    "        print(data_stack.shape[0],torch.mean(data_stack[1:]), torch.std(data_stack[1:]))\n",
    "    n_batches += 1\n",
    "    # data_list.append(images)\n",
    "    # batch_mean = torch.mean(images)\n",
    "    # batch_std = torch.std(images)\n",
    "    # mean+=batch_mean\n",
    "    # std+=batch_std\n",
    "    # n_batches+=1\n",
    "    # if n_batches%10 == 0:\n",
    "    #     # %.3f保留三位小数\n",
    "    #     print('batch: %d, mean: %.3f, std: %.3f' % (n_batches, mean/n_batches, std/n_batches))\n",
    "        \n",
    "\n",
    "\n",
    "# mean /= len(dataset)\n",
    "# std /= len(dataset)\n",
    "\n",
    "# print(\"mean:\", mean)\n",
    "# print(\"std:\", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data import filter_sample, filter_two_samples\n",
    "\n",
    "\n",
    "images_list = []\n",
    "label_list = []\n",
    "\n",
    "# 创建一个字典来保存每个标签出现的次数\n",
    "label_counts = {}\n",
    "\n",
    "sum_label = 0\n",
    "for i, (raw_image, raw_labels) in enumerate(dataloader):\n",
    "\n",
    "    image, labels = filter_sample(raw_image, raw_labels)\n",
    "    sum_label += len(labels)\n",
    "    label = labels.numpy()\n",
    "    for j in range(len(label)):\n",
    "        \n",
    "        # if label_counts.get(label[j], 0) >= TARGET_COUNT:\n",
    "        #     continue\n",
    "        # 如果标签还没有出现过两次，将元素添加到结果列表中\n",
    "        # result.append((image1[j],image2[j], label[j]))\n",
    "        label_counts[label[j]] = label_counts.get(label[j], 0) + 1\n",
    "    # 如果每个类别的样本都出现了目标次数，跳出循环\n",
    "    print('epoch',i,'label_counts',len(label_counts),'sum_label',sum_label)\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
