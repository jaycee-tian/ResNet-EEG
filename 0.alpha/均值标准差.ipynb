{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setpath\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from prepare.eegdataset import DGeneralEEGImageDataset, MySubset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "data_path = '/data0/tianjunchao/dataset/CVPR2021-02785/data/img_pkl/32x32'\n",
    "# dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "dataset = DGeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=128, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_samples:  129 mean: 0.5236 std: 0.2083\n",
      "n_samples:  1409 mean: 0.5220 std: 0.2065\n",
      "n_samples:  2689 mean: 0.5220 std: 0.2070\n",
      "n_samples:  3969 mean: 0.5221 std: 0.2066\n",
      "n_samples:  5249 mean: 0.5221 std: 0.2068\n",
      "n_samples:  6529 mean: 0.5219 std: 0.2068\n",
      "n_samples:  7809 mean: 0.5218 std: 0.2070\n",
      "n_samples:  9089 mean: 0.5218 std: 0.2070\n",
      "n_samples:  10369 mean: 0.5219 std: 0.2071\n",
      "n_samples:  11649 mean: 0.5219 std: 0.2071\n",
      "n_samples:  12929 mean: 0.5219 std: 0.2071\n",
      "n_samples:  14209 mean: 0.5219 std: 0.2071\n",
      "n_samples:  15489 mean: 0.5219 std: 0.2071\n",
      "n_samples:  16769 mean: 0.5219 std: 0.2072\n",
      "n_samples:  18049 mean: 0.5219 std: 0.2071\n",
      "n_samples:  19329 mean: 0.5219 std: 0.2072\n",
      "n_samples:  20609 mean: 0.5219 std: 0.2072\n",
      "n_samples:  21889 mean: 0.5219 std: 0.2072\n",
      "n_samples:  23169 mean: 0.5219 std: 0.2072\n",
      "n_samples:  24449 mean: 0.5219 std: 0.2073\n",
      "n_samples:  25729 mean: 0.5219 std: 0.2072\n",
      "n_samples:  27009 mean: 0.5219 std: 0.2072\n",
      "n_samples:  28289 mean: 0.5219 std: 0.2071\n",
      "n_samples:  29569 mean: 0.5219 std: 0.2071\n",
      "n_samples:  30849 mean: 0.5219 std: 0.2071\n",
      "n_samples:  32129 mean: 0.5220 std: 0.2071\n",
      "n_samples:  33409 mean: 0.5220 std: 0.2071\n",
      "n_samples:  34689 mean: 0.5220 std: 0.2071\n",
      "n_samples:  35969 mean: 0.5220 std: 0.2071\n",
      "n_samples:  37249 mean: 0.5220 std: 0.2071\n",
      "n_samples:  38529 mean: 0.5220 std: 0.2072\n",
      "n_samples:  39809 mean: 0.5219 std: 0.2072\n"
     ]
    }
   ],
   "source": [
    "# 计算均值和标准差\n",
    "mean = 0.0\n",
    "std = 0.0\n",
    "n_batches = 0\n",
    "data_stack = torch.zeros((1, 224, 224)).to('cuda')\n",
    "for images, _ in dataloader:\n",
    "    images = images[:, 0, :, :].squeeze().to('cuda')\n",
    "    data_stack = torch.cat((data_stack, images), dim=0)\n",
    "    if n_batches%10 == 0:\n",
    "        print('n_samples: ', data_stack.shape[0], 'mean: %.4f'%torch.mean(data_stack[1:]).item(), 'std: %.4f'%torch.std(data_stack[1:]).item())\n",
    "    n_batches += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
