{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/data0/tianjunchao/code/Tian-EEG-Image/')\n",
    "import torch\n",
    "from prepare.eegdataset import GeneralEEGImageDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "from utils.eegutils import get_test_setting\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tsne_torch import TorchTSNE as TSNE\n",
    "\n",
    "import run.resnet as resnet\n",
    "import torch.nn as nn\n",
    "data_path = '/data0/tianjunchao/dataset/CVPR2021-02785/data/img_pkl/32x32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = get_test_setting(dataset=GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8))\n",
    "\n",
    "from utils.eegutils import get_device\n",
    "from tsnecuda import TSNE\n",
    "\n",
    "dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "# dataset = get_test_setting(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GeneralEEGImageDataset' object has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdecomposition\u001b[39;00m \u001b[39mimport\u001b[39;00m PCA\n\u001b[1;32m      3\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m pca_results \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mfit_transform(dataset\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mscatter(pca_results[:,\u001b[39m0\u001b[39m], pca_results[:,\u001b[39m1\u001b[39m], c\u001b[39m=\u001b[39mdataset[:\u001b[39m1000\u001b[39m]\u001b[39m.\u001b[39mtargets)\n\u001b[1;32m      6\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GeneralEEGImageDataset' object has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "\n",
    "# pca\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=50)\n",
    "pca_results = pca.fit_transform(dataset[:1000].data)\n",
    "plt.scatter(pca_results[:,0], pca_results[:,1], c=dataset[:1000].targets)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "initializing...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This function was deprecated since version 1.9 and is now removed. Please use the `torch.linalg.eig` function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m file_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m4.materials/tsne_results_\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     44\u001b[0m \u001b[39mfor\u001b[39;00m model_name \u001b[39min\u001b[39;00m model_list:\n\u001b[0;32m---> 45\u001b[0m     tsne_results, labels \u001b[39m=\u001b[39m tsne_visualization(model_name, train_loader, perplexity\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, n_iter\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n\u001b[1;32m     46\u001b[0m     torch\u001b[39m.\u001b[39msave((tsne_results, labels), file_name\u001b[39m+\u001b[39mmodel_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     47\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39msave file: \u001b[39m\u001b[39m\"\u001b[39m, file_name\u001b[39m+\u001b[39mmodel_name\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m, in \u001b[0;36mtsne_visualization\u001b[0;34m(model_name, trainloader, perplexity, n_iter)\u001b[0m\n\u001b[1;32m     34\u001b[0m features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat(features, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     35\u001b[0m tsne \u001b[39m=\u001b[39m TSNE(n_components\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, perplexity\u001b[39m=\u001b[39mperplexity, n_iter\u001b[39m=\u001b[39mn_iter,verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 36\u001b[0m tsne_results \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39;49mfit_transform(features[:n_samples])\n\u001b[1;32m     37\u001b[0m \u001b[39mreturn\u001b[39;00m tsne_results, labels[:n_samples]\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/tsne_torch/tsne_torch.py:256\u001b[0m, in \u001b[0;36mTorchTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[39mLearns the t-stochastic neighbor embedding of the given data.\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[39m:return: ndarray (n_samples, n_components)\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 256\u001b[0m     \u001b[39mreturn\u001b[39;00m _tsne(\n\u001b[1;32m    257\u001b[0m         X,\n\u001b[1;32m    258\u001b[0m         no_dims\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_components,\n\u001b[1;32m    259\u001b[0m         initial_dims\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitial_dims,\n\u001b[1;32m    260\u001b[0m         perplexity\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mperplexity,\n\u001b[1;32m    261\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    262\u001b[0m         max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_iter\n\u001b[1;32m    263\u001b[0m     )\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/tsne_torch/tsne_torch.py:158\u001b[0m, in \u001b[0;36m_tsne\u001b[0;34m(X, no_dims, initial_dims, perplexity, max_iter, verbose)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[39m# Initialize variables\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m initial_dims \u001b[39m<\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[0;32m--> 158\u001b[0m     X \u001b[39m=\u001b[39m _pca_torch(X, initial_dims)\n\u001b[1;32m    159\u001b[0m \u001b[39melif\u001b[39;00m verbose:\n\u001b[1;32m    160\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mskipping PCA because initial_dims is larger than input dimensionality\u001b[39m\u001b[39m\"\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/tsne_torch/tsne_torch.py:124\u001b[0m, in \u001b[0;36m_pca_torch\u001b[0;34m(X, no_dims)\u001b[0m\n\u001b[1;32m    121\u001b[0m (n, d) \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    122\u001b[0m X \u001b[39m=\u001b[39m X \u001b[39m-\u001b[39m torch\u001b[39m.\u001b[39mmean(X, \u001b[39m0\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m (l, M) \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49meig(torch\u001b[39m.\u001b[39;49mmm(X\u001b[39m.\u001b[39;49mt(), X), \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    125\u001b[0m \u001b[39m# split M real\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(d):\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/torch/_linalg_utils.py:127\u001b[0m, in \u001b[0;36meig\u001b[0;34m(self, eigenvectors, e, v)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meig\u001b[39m(\n\u001b[1;32m    125\u001b[0m     \u001b[39mself\u001b[39m: Tensor, eigenvectors: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m, e\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, v\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m    126\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    128\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis function was deprecated since version 1.9 and is now removed. Please use the `torch.linalg.eig` function instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    129\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This function was deprecated since version 1.9 and is now removed. Please use the `torch.linalg.eig` function instead."
     ]
    }
   ],
   "source": [
    "device = get_device(0)\n",
    "def tsne_visualization(model_name, trainloader, perplexity=30, n_iter=1000):\n",
    "    \n",
    "    model = resnet.ResNet(num_classes=40,model_name=model_name, pretrained=True)\n",
    "    model = list(model.children())[0]\n",
    "\n",
    "    feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "    feature_extractor = feature_extractor.to(device)\n",
    "    feature_extractor.eval()      \n",
    "    # 提取训练数据的特征向量\n",
    "    features = []\n",
    "    labels = []\n",
    "    # tsne = TSNE(n_components=2)\n",
    "    tsne = TSNE(n_components=2, perplexity=perplexity, n_iter=n_iter,verbose=True)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, targets = data\n",
    "        # to device\n",
    "        inputs = inputs.to(device)\n",
    "        labels.extend(targets)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # features.append(feature_extractor(inputs).squeeze())\n",
    "            tsne_results = tsne.fit_transform(inputs[:n_samples])\n",
    "        break\n",
    "    # features = np.concatenate(features)\n",
    "    # labels = np.concatenate(labels)\n",
    "\n",
    "    # 使用T-SNE算法将特征向量降至2维\n",
    "    # features = torch.cat(features, dim=0)\n",
    "    return tsne_results, labels[:n_samples]\n",
    "# list names of resnet\n",
    "\n",
    "model_list = [resnet.resnet_name_A,resnet.resnet_name_B,resnet.resnet_name_C,resnet.resnet_name_D,resnet.resnet_name_E]\n",
    "tsne_list = []\n",
    "label_list = []\n",
    "file_name = \"4.materials/tsne_results_\"\n",
    "for model_name in model_list:\n",
    "    tsne_results, labels = tsne_visualization(model_name, train_loader, perplexity=30, n_iter=1000)\n",
    "    torch.save((tsne_results, labels), file_name+model_name+\".txt\")\n",
    "    print(\"save file: \", file_name+model_name+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw 5 tsne in one figure\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(5):\n",
    "    plt.subplot(5, 1, i+1)\n",
    "    plt.scatter(tsne_list[i][:, 0], tsne_list[i][:, 1], c=label_list[i], cmap='tab10')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader),len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = list(model.children())\n",
    "print(len(modules))\n",
    "print(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.max(imgs),torch.min(imgs))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 将通道维度放在最后，以符合imshow的要求\n",
    "imgs = np.transpose(imgs, (0, 2, 3, 1))\n",
    "\n",
    "# 打印16张图像\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(imgs[i])\n",
    "    ax.set_axis_off()\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imgs[1]\n",
    "plt.imshow(img)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()\n",
    "# 分别画出每个通道的图像\n",
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.imshow(img[..., i])\n",
    "    ax.set_title('Channel {}'.format(i+1))\n",
    "\n",
    "# 调整子图之间的间距\n",
    "plt.tight_layout()\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# resnet \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet = models.resnet101(pretrained=True)\n",
    "# print(resnet)\n",
    "resnet.fc = nn.Conv2d(resnet.fc.in_features, 40, kernel_size=1)\n",
    "# print(resnet)\n",
    "modules = list(resnet.children())\n",
    "print(len(modules))\n",
    "print(modules)\n",
    "# [:-1]\n",
    "# resnet.flatten_features_output = False\n",
    "# feature_extractor = nn.Sequential(*modules)\n",
    "# random_input = torch.randn(19, 3, 224, 224)\n",
    "# output = feature_extractor(random_input)\n",
    "# print(output.shape)\n",
    "# print(feature_extractor)\n",
    "# classifiers = resnet.fc\n",
    "# output = classifiers(output)\n",
    "# print(output.shape)\n",
    "# print(resnet(random_input))\n",
    "# print(classifiers)\n",
    "# # print(feature_extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = nn.Sequential(*list(resnet.children())[:-2])\n",
    "print(xx(random_input).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,1+len(list(resnet.children()))):\n",
    "    print(list(resnet.children())[-i])\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet50\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "resnet = models.resnet50(pretrained=True)\n",
    "print(resnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.98**100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "\n",
    "# Define the range of x values to plot\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# Define the alpha and beta parameters for the beta distribution\n",
    "alphas = [1, 2, 3, 4, 5, 6]\n",
    "betas = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(12, 8))\n",
    "\n",
    "# Loop over the alpha and beta values and plot the corresponding beta distribution\n",
    "for i, (alpha, beta_param) in enumerate(zip(alphas, betas)):\n",
    "    row = i // 3  # Determine the row index\n",
    "    col = i % 3   # Determine the column index\n",
    "\n",
    "    # Generate a beta distribution object\n",
    "    dist = beta(alpha, beta_param)\n",
    "\n",
    "    # Compute the PDF values for the given x values\n",
    "    pdf = dist.pdf(x)\n",
    "\n",
    "    # Plot the PDF of the beta distribution in the corresponding subplot\n",
    "    axes[row, col].plot(x, pdf, label=r'$\\alpha={}, \\beta={}$'.format(alpha, beta_param))\n",
    "    axes[row, col].set_title(r'Beta distribution with $\\alpha={}, \\beta={}$'.format(alpha, beta_param))\n",
    "    axes[row, col].set_xlabel('x')\n",
    "    axes[row, col].set_ylabel('PDF')\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "\n",
    "# Define the range of x values to plot\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# Define the alpha and beta parameters for the beta distribution\n",
    "alphas = np.array(range(0,16))*0.1\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=4, ncols=4, figsize=(12, 8))\n",
    "\n",
    "# Loop over the alpha and beta values and plot the corresponding beta distribution\n",
    "for i, alpha in enumerate(alphas):\n",
    "    row = i // 4  # Determine the row index\n",
    "    col = i % 4   # Determine the column index\n",
    "\n",
    "    # Generate a beta distribution object\n",
    "    dist = beta(alpha, alpha)\n",
    "\n",
    "    # Compute the PDF values for the given x values\n",
    "    pdf = dist.pdf(x)\n",
    "\n",
    "    # Plot the PDF of the beta distribution in the corresponding subplot\n",
    "    axes[row, col].plot(x, pdf, label=r'$\\alpha={:.1f}$'.format(alpha))\n",
    "    axes[row, col].set_title(r'Beta distribution with $\\alpha={:.1f}$'.format(alpha))\n",
    "    axes[row, col].set_xlabel('x')\n",
    "    axes[row, col].set_ylabel('PDF')\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import beta\n",
    "\n",
    "# Define the range of x values to plot\n",
    "x = np.linspace(0, 1, 100)\n",
    "\n",
    "# Define the alpha and beta parameters for the beta distribution\n",
    "alphas = np.array(range(1,10))*0.01+0.9\n",
    "betas = np.array(range(1,10))*0.01+0.9\n",
    "\n",
    "# Create a 2x3 grid of subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))\n",
    "\n",
    "# Loop over the alpha and beta values and plot the corresponding beta distribution\n",
    "for i, (alpha, beta_param) in enumerate(zip(alphas, betas)):\n",
    "    row = i // 3  # Determine the row index\n",
    "    col = i % 3   # Determine the column index\n",
    "\n",
    "    # Generate a beta distribution object\n",
    "    dist = beta(alpha, beta_param)\n",
    "\n",
    "    # Compute the PDF values for the given x values\n",
    "    pdf = dist.pdf(x)\n",
    "\n",
    "    # Plot the PDF of the beta distribution in the corresponding subplot\n",
    "    axes[row, col].plot(x, pdf, label=r'$\\alpha={:.2f}, \\beta={:.2f}$'.format(alpha, beta_param))\n",
    "    axes[row, col].set_title(r'Beta distribution with $\\alpha={:.2f}, \\beta={:.2f}$'.format(alpha, beta_param))\n",
    "    axes[row, col].set_xlabel('x')\n",
    "    axes[row, col].set_ylabel('PDF')\n",
    "    axes[row, col].legend()\n",
    "\n",
    "# Adjust the layout of the subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from models.resnet import ResNet\n",
    "\n",
    "\n",
    "model = ResNet(num_classes=40,model_name='resnet152', pretrained=True)\n",
    "# print if parameters are trainable\n",
    "\n",
    "print('------------------')\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param.requires_grad)\n",
    "\n",
    "# freeze all parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用scikit-learn中的t-SNE算法进行降维\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_feature(feat_matrix, feat_labels):\n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    feat_matrix_tsne = tsne.fit_transform(feat_matrix)\n",
    "\n",
    "    # 绘制可视化图像\n",
    "    plt.scatter(feat_matrix_tsne[:, 0], feat_matrix_tsne[:, 1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "------------------\n",
      "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "------------------\n",
      "ReLU(inplace=True)\n",
      "------------------\n",
      "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "------------------\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "------------------\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "------------------\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (3): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (4): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (5): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "------------------\n",
      "Sequential(\n",
      "  (0): Bottleneck(\n",
      "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (downsample): Sequential(\n",
      "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (1): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      "  (2): Bottleneck(\n",
      "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "  )\n",
      ")\n",
      "------------------\n",
      "AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "------------------\n",
      "Sequential(\n",
      "  (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): Dropout(p=0.5, inplace=False)\n",
      "  (3): Linear(in_features=1024, out_features=40, bias=True)\n",
      ")\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = resnet.ResNet(num_classes=40,model_name=resnet.resnet_name_C, pretrained=True)\n",
    "model = list(model.children())[0]\n",
    "modules = list(model.children())\n",
    "for i in range(len(modules)):\n",
    "    print(modules[i])\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
