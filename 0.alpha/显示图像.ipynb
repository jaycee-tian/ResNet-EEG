{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setpath\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from prepare.eegdataset import C_GeneralEEGImageDataset, DC_GeneralEEGImageDataset, GeneralEEGImageDataset, MySubset, N_GeneralEEGImageDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "data_path = '/data0/tianjunchao/dataset/CVPR2021-02785/data/img_pkl/32x32'\n",
    "# dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "train_transforms = transforms.Compose([\n",
    "    # transforms.RandomHorizontalFlip(),\n",
    "    # transforms.RandomVerticalFlip(),\n",
    "    # transforms.RandomRotation((30)),\n",
    "    # transforms.RandomCrop(224),\n",
    "    # transforms.ToTensor(),\n",
    "    # one channel\n",
    "    transforms.Resize((256, 256)),\n",
    "    # transforms.RandomRotation(20),\n",
    "    transforms.RandomCrop(224),\n",
    "    transforms.Normalize([0.512, 0.512, 0.512], [0.228, 0.228, 0.228]),\n",
    "])\n",
    "n_samples = 1\n",
    "dataset = C_GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8, n_samples=n_samples)\n",
    "# dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "# dataset = GeneralEEGImageDataset(path=data_path, n_channels=1, grid_size=4, n_samples=n_samples)\n",
    "scale = 2\n",
    "dataset = MySubset(dataset, range(len(dataset)), transform=None)\n",
    "# dataset = MySubset(dataset, range(len(dataset)), train_transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 len 128 label_counts 40\n",
      "epoch 1 len 128 label_counts 40\n",
      "epoch 2 len 128 label_counts 40\n"
     ]
    }
   ],
   "source": [
    "from prepare.data import filter_two_samples\n",
    "\n",
    "\n",
    "images_list = []\n",
    "label_list = []\n",
    "\n",
    "# 创建一个字典来保存每个标签出现的次数\n",
    "label_counts = {}\n",
    "\n",
    "# 创建一个空列表来保存结果\n",
    "result = []\n",
    "\n",
    "# 设置目标标签出现的次数\n",
    "TARGET_COUNT = 8\n",
    "\n",
    "for i, (images, labels) in enumerate(dataloader):\n",
    "\n",
    "    # 2 x batchsize x 3 x 224 x 224 to batchsize x 2 x 3 x 224 x 224\n",
    "    images = torch.stack(images, dim=1)\n",
    "\n",
    "    # image1, image2, labels = filter_two_samples(raw_image1, raw_image2, raw_labels,alpha=0)\n",
    "    \n",
    "    label = labels.numpy()\n",
    "    for j in range(len(label)):\n",
    "        \n",
    "        if label_counts.get(label[j], 0) >= TARGET_COUNT:\n",
    "            continue\n",
    "        # 如果标签还没有出现过两次，将元素添加到结果列表中\n",
    "        result.append((images[j], label[j]))\n",
    "        label_counts[label[j]] = label_counts.get(label[j], 0) + 1\n",
    "    # 如果每个类别的样本都出现了目标次数，跳出循环\n",
    "    if all(count == TARGET_COUNT for count in label_counts.values()):\n",
    "        break\n",
    "    print('epoch',i,'len',len(labels),'label_counts',len(label_counts))\n",
    "# 按照 y 从小到大排序\n",
    "result.sort(key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_y:  0\n",
      "mean:  tensor(0.3896) median:  tensor(0.3154) std:  tensor(0.2180)\n",
      "mean:  tensor(0.4878) median:  tensor(0.4990) std:  tensor(0.1953)\n",
      "mean:  tensor(0.4994) median:  tensor(0.5084) std:  tensor(0.1996)\n",
      "mean:  tensor(0.5054) median:  tensor(0.5091) std:  tensor(0.1998)\n",
      "mean:  tensor(0.5207) median:  tensor(0.5236) std:  tensor(0.1960)\n",
      "mean:  tensor(0.5182) median:  tensor(0.5202) std:  tensor(0.1877)\n",
      "mean:  tensor(0.5340) median:  tensor(0.5412) std:  tensor(0.2274)\n",
      "mean:  tensor(0.5081) median:  tensor(0.5124) std:  tensor(0.2042)\n",
      "mean:  tensor(0.5513) median:  tensor(0.5688) std:  tensor(0.1885)\n",
      "mean:  tensor(0.5069) median:  tensor(0.5116) std:  tensor(0.2035)\n",
      "mean:  tensor(0.5469) median:  tensor(0.5615) std:  tensor(0.2110)\n",
      "mean:  tensor(0.5235) median:  tensor(0.5245) std:  tensor(0.1956)\n",
      "mean:  tensor(0.4548) median:  tensor(0.4381) std:  tensor(0.2098)\n",
      "mean:  tensor(0.5210) median:  tensor(0.5256) std:  tensor(0.2069)\n",
      "mean:  tensor(0.4941) median:  tensor(0.4841) std:  tensor(0.2020)\n",
      "mean:  tensor(0.5223) median:  tensor(0.5353) std:  tensor(0.1941)\n",
      "-------------------------------------\n",
      "target_y:  1\n",
      "mean:  tensor(0.5280) median:  tensor(0.5413) std:  tensor(0.2107)\n",
      "mean:  tensor(0.5683) median:  tensor(0.5925) std:  tensor(0.2156)\n",
      "mean:  tensor(0.4871) median:  tensor(0.4807) std:  tensor(0.2107)\n",
      "mean:  tensor(0.5152) median:  tensor(0.5232) std:  tensor(0.1888)\n",
      "mean:  tensor(0.5090) median:  tensor(0.5079) std:  tensor(0.2012)\n",
      "mean:  tensor(0.5323) median:  tensor(0.5318) std:  tensor(0.1974)\n",
      "mean:  tensor(0.4582) median:  tensor(0.4442) std:  tensor(0.1985)\n",
      "mean:  tensor(0.5089) median:  tensor(0.5058) std:  tensor(0.2151)\n",
      "mean:  tensor(0.5195) median:  tensor(0.5219) std:  tensor(0.1964)\n",
      "mean:  tensor(0.5354) median:  tensor(0.5468) std:  tensor(0.1909)\n",
      "mean:  tensor(0.4186) median:  tensor(0.4045) std:  tensor(0.2147)\n",
      "mean:  tensor(0.5341) median:  tensor(0.5476) std:  tensor(0.1979)\n",
      "mean:  tensor(0.5550) median:  tensor(0.5709) std:  tensor(0.2101)\n",
      "mean:  tensor(0.5104) median:  tensor(0.5115) std:  tensor(0.1819)\n",
      "mean:  tensor(0.4108) median:  tensor(0.3775) std:  tensor(0.2287)\n",
      "mean:  tensor(0.4928) median:  tensor(0.4833) std:  tensor(0.2017)\n",
      "-------------------------------------\n",
      "target_y:  2\n",
      "mean:  tensor(0.5453) median:  tensor(0.5476) std:  tensor(0.3055)\n",
      "mean:  tensor(0.4736) median:  tensor(0.3043) std:  tensor(0.4169)\n",
      "mean:  tensor(0.4684) median:  tensor(0.4601) std:  tensor(0.1766)\n",
      "mean:  tensor(0.5200) median:  tensor(0.5144) std:  tensor(0.1954)\n",
      "mean:  tensor(0.4223) median:  tensor(0.3878) std:  tensor(0.2341)\n",
      "mean:  tensor(0.5162) median:  tensor(0.5191) std:  tensor(0.1868)\n",
      "mean:  tensor(0.4648) median:  tensor(0.4310) std:  tensor(0.2378)\n",
      "mean:  tensor(0.5123) median:  tensor(0.5043) std:  tensor(0.2077)\n",
      "mean:  tensor(0.5523) median:  tensor(0.5727) std:  tensor(0.2025)\n",
      "mean:  tensor(0.5139) median:  tensor(0.5155) std:  tensor(0.1857)\n",
      "mean:  tensor(0.5162) median:  tensor(0.5247) std:  tensor(0.1968)\n",
      "mean:  tensor(0.5250) median:  tensor(0.5328) std:  tensor(0.1822)\n",
      "mean:  tensor(0.5171) median:  tensor(0.5080) std:  tensor(0.2254)\n",
      "mean:  tensor(0.5245) median:  tensor(0.5154) std:  tensor(0.1951)\n",
      "mean:  tensor(0.5620) median:  tensor(0.5848) std:  tensor(0.2254)\n",
      "mean:  tensor(0.5197) median:  tensor(0.5306) std:  tensor(0.2615)\n",
      "-------------------------------------\n",
      "target_y:  3\n",
      "mean:  tensor(0.4935) median:  tensor(0.4891) std:  tensor(0.1909)\n",
      "mean:  tensor(0.5063) median:  tensor(0.5066) std:  tensor(0.1921)\n",
      "mean:  tensor(0.4979) median:  tensor(0.4884) std:  tensor(0.1975)\n",
      "mean:  tensor(0.5176) median:  tensor(0.5419) std:  tensor(0.2222)\n",
      "mean:  tensor(0.5035) median:  tensor(0.4964) std:  tensor(0.2083)\n",
      "mean:  tensor(0.4973) median:  tensor(0.4940) std:  tensor(0.1956)\n",
      "mean:  tensor(0.5171) median:  tensor(0.5293) std:  tensor(0.2141)\n",
      "mean:  tensor(0.4947) median:  tensor(0.4893) std:  tensor(0.1880)\n",
      "mean:  tensor(0.5243) median:  tensor(0.5281) std:  tensor(0.2169)\n",
      "mean:  tensor(0.5334) median:  tensor(0.5621) std:  tensor(0.2249)\n",
      "mean:  tensor(0.5129) median:  tensor(0.5130) std:  tensor(0.1901)\n",
      "mean:  tensor(0.5256) median:  tensor(0.5301) std:  tensor(0.1959)\n",
      "mean:  tensor(0.6721) median:  tensor(0.7350) std:  tensor(0.1969)\n",
      "mean:  tensor(0.5177) median:  tensor(0.5101) std:  tensor(0.2525)\n",
      "mean:  tensor(0.5464) median:  tensor(0.5582) std:  tensor(0.1985)\n",
      "mean:  tensor(0.5020) median:  tensor(0.5031) std:  tensor(0.1942)\n",
      "-------------------------------------\n",
      "target_y:  4\n",
      "mean:  tensor(0.5094) median:  tensor(0.5209) std:  tensor(0.2025)\n",
      "mean:  tensor(0.5216) median:  tensor(0.5269) std:  tensor(0.1910)\n",
      "mean:  tensor(0.5456) median:  tensor(0.5696) std:  tensor(0.2222)\n",
      "mean:  tensor(0.4995) median:  tensor(0.4997) std:  tensor(0.1952)\n",
      "mean:  tensor(0.4702) median:  tensor(0.4417) std:  tensor(0.2153)\n",
      "mean:  tensor(0.5234) median:  tensor(0.5246) std:  tensor(0.1976)\n",
      "mean:  tensor(0.6769) median:  tensor(0.7119) std:  tensor(0.1943)\n",
      "mean:  tensor(0.5335) median:  tensor(0.5372) std:  tensor(0.1798)\n",
      "mean:  tensor(0.4050) median:  tensor(0.3637) std:  tensor(0.2349)\n",
      "mean:  tensor(0.5226) median:  tensor(0.5219) std:  tensor(0.1815)\n",
      "mean:  tensor(0.7234) median:  tensor(0.8226) std:  tensor(0.2861)\n",
      "mean:  tensor(0.5282) median:  tensor(0.5418) std:  tensor(0.1915)\n",
      "mean:  tensor(0.5009) median:  tensor(0.5076) std:  tensor(0.2400)\n",
      "mean:  tensor(0.5204) median:  tensor(0.5346) std:  tensor(0.2573)\n",
      "mean:  tensor(0.4939) median:  tensor(0.4938) std:  tensor(0.2103)\n",
      "mean:  tensor(0.5203) median:  tensor(0.5339) std:  tensor(0.2092)\n",
      "-------------------------------------\n",
      "target_y:  5\n",
      "mean:  tensor(0.4983) median:  tensor(0.4987) std:  tensor(0.2292)\n",
      "mean:  tensor(0.5121) median:  tensor(0.5105) std:  tensor(0.1952)\n",
      "mean:  tensor(0.5280) median:  tensor(0.5307) std:  tensor(0.2205)\n",
      "mean:  tensor(0.5270) median:  tensor(0.5244) std:  tensor(0.1915)\n",
      "mean:  tensor(0.4853) median:  tensor(0.4889) std:  tensor(0.2150)\n",
      "mean:  tensor(0.5087) median:  tensor(0.5157) std:  tensor(0.1913)\n",
      "mean:  tensor(0.5805) median:  tensor(0.6088) std:  tensor(0.2000)\n",
      "mean:  tensor(0.5213) median:  tensor(0.5283) std:  tensor(0.2028)\n",
      "mean:  tensor(0.4694) median:  tensor(0.4686) std:  tensor(0.2426)\n",
      "mean:  tensor(0.5324) median:  tensor(0.5555) std:  tensor(0.2192)\n",
      "mean:  tensor(0.4872) median:  tensor(0.4727) std:  tensor(0.1745)\n",
      "mean:  tensor(0.5189) median:  tensor(0.5107) std:  tensor(0.1934)\n",
      "mean:  tensor(0.6731) median:  tensor(0.7102) std:  tensor(0.2025)\n",
      "mean:  tensor(0.5228) median:  tensor(0.5342) std:  tensor(0.2035)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m median_list \u001b[39m=\u001b[39m []\n\u001b[1;32m     13\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m x_list:\n\u001b[0;32m---> 14\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmean: \u001b[39m\u001b[39m'\u001b[39m, torch\u001b[39m.\u001b[39;49mmean(x), \u001b[39m'\u001b[39m\u001b[39mmedian: \u001b[39m\u001b[39m'\u001b[39m, torch\u001b[39m.\u001b[39mmedian(x), \u001b[39m'\u001b[39m\u001b[39mstd: \u001b[39m\u001b[39m'\u001b[39m, torch\u001b[39m.\u001b[39mstd(x))\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m-------------------------------------\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 40个类别，每个类取出8x2个样本，均值和标准差\n",
    "for i in range(40):\n",
    "\n",
    "    target_y = i\n",
    "    filtered_result = [xs for xs,y in result if y == target_y]\n",
    "    x_list = []  \n",
    "    for fr in filtered_result:\n",
    "        x_list.extend(fr)\n",
    "    print('target_y: ', target_y)\n",
    "    mean_list = []\n",
    "    std_list = []\n",
    "    median_list = []\n",
    "    for x in x_list:\n",
    "        print('mean: ', torch.mean(x), 'median: ', torch.median(x), 'std: ', torch.std(x))\n",
    "    print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将结果分成10段\n",
    "sample_per_img = 16\n",
    "num_classes = 40\n",
    "num_images = TARGET_COUNT * num_classes * n_samples * scale // sample_per_img\n",
    "# resutl = [(imgs1, label), (imgs2, label), ...]\n",
    "segment_size = len(result) // num_images\n",
    "segments = [result[i:i+segment_size] for i in range(0, len(result), segment_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def a function to show images\n",
    "import os\n",
    "\n",
    "from utils.eegutils import getNow\n",
    "\n",
    "\n",
    "def show_images(it, imgs, labels,img_dir=None):\n",
    "    # 将通道维度放在最后，以符合imshow的要求\n",
    "    imgs = np.transpose(imgs, (0, 2, 3, 1))\n",
    "\n",
    "    n_imgs = len(labels)\n",
    "    ncols = 4\n",
    "    nrows = n_imgs//ncols\n",
    "\n",
    "    # print('imgs.shape: ', imgs.shape)\n",
    "    # 打印16张图像\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(10, 10))\n",
    "    # 显示每个图像的标签\n",
    "\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.set_title(labels[i])\n",
    "        ax.imshow(imgs[i])\n",
    "        ax.set_axis_off()\n",
    "\n",
    "    # 调整子图之间的间距\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if img_dir is not None:\n",
    "    # 显示图像\n",
    "    # plt.show()\n",
    "        plt.savefig(img_dir+ str(it)+' - ' +str(labels[0])+'~'+str(labels[len(labels)-1])+'.png')\n",
    "        plt.close()\n",
    "\n",
    "def show_channels(img):\n",
    "    plt.imshow(img)\n",
    "\n",
    "    # 显示图像\n",
    "    plt.show()\n",
    "    # 分别画出每个通道的图像\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\n",
    "\n",
    "    for i, ax in enumerate(axes):\n",
    "        ax.imshow(img[..., i])\n",
    "        ax.set_title('Channel {}'.format(i+1))\n",
    "\n",
    "    # 调整子图之间的间距\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 显示图像\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# draw images in each segment\n",
    "def draw_list(segment):\n",
    "    images = []\n",
    "    labels = []\n",
    "    # c,w,h = segment[0][0].shape\n",
    "    _, c,w,h = segment[0][0].shape\n",
    "    # 遍历segment中的每个元素\n",
    "    for i, data in enumerate(segment):\n",
    "        xs, y = data\n",
    "        for x in xs:\n",
    "            images.append(x)\n",
    "            labels.append(y)\n",
    "            \n",
    "    images = torch.stack(images, dim=0).view(len(labels), c, w, h)\n",
    "    return images,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dir = '4.materials/labels/'+getNow()+'/'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "for i, segment in enumerate(segments):\n",
    "    images,labels = draw_list(segment)\n",
    "    show_images(i,images, labels,img_dir=img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
