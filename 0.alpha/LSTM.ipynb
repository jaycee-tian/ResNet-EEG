{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0]\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import setpath\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "\n",
    "from prepare.show import get_material_dir\n",
    "from run.start import get_device\n",
    "\n",
    "import torch\n",
    "from prepare.eegdataset import C_GeneralEEGImageDataset, GeneralEEGImageDataset, GeneralEEGPointDataset, N2_GeneralEEGImageDataset\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from run.others import SmallNet\n",
    "from prepare.data import filter_two_samples\n",
    "import run.resnet as resnet\n",
    "import torch.nn as nn\n",
    "data_path = '/data0/tianjunchao/dataset/CVPR2021-02785/data/img_pkl/32x32'\n",
    "\n",
    "from utils.eegutils import getNow\n",
    "\n",
    "dataset = GeneralEEGPointDataset(path=data_path, n_channels=1, grid_size=8)\n",
    "# dataset = get_test_setting(dataset)\n",
    "train_loader = DataLoader(dataset, batch_size=128)\n",
    "device = get_device()\n",
    "material_dir = get_material_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "input_size = 717\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 40\n",
    "learning_rate = 0.001\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "# mlp model, 2 layers, relu，dropout, batchnorm\n",
    "class MLPModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLPModel, self).__init__()\n",
    "        self.base = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(hidden_size),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(0.5),\n",
    "            nn.BatchNorm1d(hidden_size)\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base(x)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/313], Loss: 3.8078, Acc: 2.58%\n",
      "Epoch [1/100], Step [20/313], Loss: 3.7439, Acc: 2.66%\n",
      "Epoch [1/100], Step [30/313], Loss: 3.7580, Acc: 2.63%\n",
      "Epoch [1/100], Step [40/313], Loss: 3.7730, Acc: 2.79%\n",
      "Epoch [1/100], Step [50/313], Loss: 3.7915, Acc: 2.73%\n",
      "Epoch [1/100], Step [60/313], Loss: 3.7617, Acc: 2.72%\n",
      "Epoch [1/100], Step [70/313], Loss: 3.7123, Acc: 2.67%\n",
      "Epoch [1/100], Step [80/313], Loss: 3.7479, Acc: 2.72%\n",
      "Epoch [1/100], Step [90/313], Loss: 3.7687, Acc: 2.75%\n",
      "Epoch [1/100], Step [100/313], Loss: 3.7252, Acc: 2.74%\n",
      "Epoch [1/100], Step [110/313], Loss: 3.7279, Acc: 2.79%\n",
      "Epoch [1/100], Step [120/313], Loss: 3.7337, Acc: 2.81%\n",
      "Epoch [1/100], Step [130/313], Loss: 3.7153, Acc: 2.76%\n",
      "Epoch [1/100], Step [140/313], Loss: 3.7247, Acc: 2.76%\n",
      "Epoch [1/100], Step [150/313], Loss: 3.7571, Acc: 2.76%\n",
      "Epoch [1/100], Step [160/313], Loss: 3.7144, Acc: 2.71%\n",
      "Epoch [1/100], Step [170/313], Loss: 3.7308, Acc: 2.71%\n",
      "Epoch [1/100], Step [180/313], Loss: 3.7469, Acc: 2.70%\n",
      "Epoch [1/100], Step [190/313], Loss: 3.6887, Acc: 2.71%\n",
      "Epoch [1/100], Step [200/313], Loss: 3.6719, Acc: 2.77%\n",
      "Epoch [1/100], Step [210/313], Loss: 3.7356, Acc: 2.82%\n",
      "Epoch [1/100], Step [220/313], Loss: 3.6662, Acc: 2.85%\n",
      "Epoch [1/100], Step [230/313], Loss: 3.7295, Acc: 2.85%\n",
      "Epoch [1/100], Step [240/313], Loss: 3.6994, Acc: 2.85%\n",
      "Epoch [1/100], Step [250/313], Loss: 3.7222, Acc: 2.89%\n",
      "Epoch [1/100], Step [260/313], Loss: 3.6445, Acc: 2.94%\n",
      "Epoch [1/100], Step [270/313], Loss: 3.6697, Acc: 2.92%\n",
      "Epoch [1/100], Step [280/313], Loss: 3.6858, Acc: 2.92%\n",
      "Epoch [1/100], Step [290/313], Loss: 3.7104, Acc: 2.95%\n",
      "Epoch [1/100], Step [300/313], Loss: 3.6856, Acc: 2.97%\n",
      "Epoch [1/100], Step [310/313], Loss: 3.7062, Acc: 3.00%\n",
      "Epoch [2/100], Step [10/313], Loss: 3.7154, Acc: 2.89%\n",
      "Epoch [2/100], Step [20/313], Loss: 3.6936, Acc: 3.44%\n",
      "Epoch [2/100], Step [30/313], Loss: 3.7157, Acc: 3.41%\n",
      "Epoch [2/100], Step [40/313], Loss: 3.6831, Acc: 3.61%\n",
      "Epoch [2/100], Step [50/313], Loss: 3.7417, Acc: 3.53%\n",
      "Epoch [2/100], Step [60/313], Loss: 3.6969, Acc: 3.67%\n",
      "Epoch [2/100], Step [70/313], Loss: 3.6474, Acc: 3.82%\n",
      "Epoch [2/100], Step [80/313], Loss: 3.7066, Acc: 3.95%\n",
      "Epoch [2/100], Step [90/313], Loss: 3.7607, Acc: 3.95%\n",
      "Epoch [2/100], Step [100/313], Loss: 3.6956, Acc: 3.96%\n",
      "Epoch [2/100], Step [110/313], Loss: 3.6878, Acc: 4.03%\n",
      "Epoch [2/100], Step [120/313], Loss: 3.7093, Acc: 4.00%\n",
      "Epoch [2/100], Step [130/313], Loss: 3.6530, Acc: 4.02%\n",
      "Epoch [2/100], Step [140/313], Loss: 3.6529, Acc: 4.01%\n",
      "Epoch [2/100], Step [150/313], Loss: 3.7524, Acc: 3.98%\n",
      "Epoch [2/100], Step [160/313], Loss: 3.6361, Acc: 4.03%\n",
      "Epoch [2/100], Step [170/313], Loss: 3.6817, Acc: 4.06%\n",
      "Epoch [2/100], Step [180/313], Loss: 3.6922, Acc: 4.06%\n",
      "Epoch [2/100], Step [190/313], Loss: 3.6279, Acc: 4.06%\n",
      "Epoch [2/100], Step [200/313], Loss: 3.6335, Acc: 4.09%\n",
      "Epoch [2/100], Step [210/313], Loss: 3.6746, Acc: 4.05%\n",
      "Epoch [2/100], Step [220/313], Loss: 3.6292, Acc: 4.06%\n",
      "Epoch [2/100], Step [230/313], Loss: 3.6949, Acc: 4.03%\n",
      "Epoch [2/100], Step [240/313], Loss: 3.6850, Acc: 4.00%\n",
      "Epoch [2/100], Step [250/313], Loss: 3.6895, Acc: 4.00%\n",
      "Epoch [2/100], Step [260/313], Loss: 3.6100, Acc: 4.03%\n",
      "Epoch [2/100], Step [270/313], Loss: 3.6438, Acc: 3.98%\n",
      "Epoch [2/100], Step [280/313], Loss: 3.6652, Acc: 3.98%\n",
      "Epoch [2/100], Step [290/313], Loss: 3.6823, Acc: 3.99%\n",
      "Epoch [2/100], Step [300/313], Loss: 3.6534, Acc: 4.03%\n",
      "Epoch [2/100], Step [310/313], Loss: 3.6993, Acc: 4.02%\n",
      "Epoch [3/100], Step [10/313], Loss: 3.6728, Acc: 4.77%\n",
      "Epoch [3/100], Step [20/313], Loss: 3.6662, Acc: 4.53%\n",
      "Epoch [3/100], Step [30/313], Loss: 3.7011, Acc: 4.53%\n",
      "Epoch [3/100], Step [40/313], Loss: 3.6644, Acc: 4.61%\n",
      "Epoch [3/100], Step [50/313], Loss: 3.7181, Acc: 4.50%\n",
      "Epoch [3/100], Step [60/313], Loss: 3.6694, Acc: 4.61%\n",
      "Epoch [3/100], Step [70/313], Loss: 3.6344, Acc: 4.67%\n",
      "Epoch [3/100], Step [80/313], Loss: 3.6634, Acc: 4.71%\n",
      "Epoch [3/100], Step [90/313], Loss: 3.7112, Acc: 4.59%\n",
      "Epoch [3/100], Step [100/313], Loss: 3.6765, Acc: 4.52%\n",
      "Epoch [3/100], Step [110/313], Loss: 3.6569, Acc: 4.55%\n",
      "Epoch [3/100], Step [120/313], Loss: 3.6939, Acc: 4.59%\n",
      "Epoch [3/100], Step [130/313], Loss: 3.6423, Acc: 4.66%\n",
      "Epoch [3/100], Step [140/313], Loss: 3.6457, Acc: 4.62%\n",
      "Epoch [3/100], Step [150/313], Loss: 3.7344, Acc: 4.61%\n",
      "Epoch [3/100], Step [160/313], Loss: 3.5953, Acc: 4.63%\n",
      "Epoch [3/100], Step [170/313], Loss: 3.6231, Acc: 4.61%\n",
      "Epoch [3/100], Step [180/313], Loss: 3.6779, Acc: 4.64%\n",
      "Epoch [3/100], Step [190/313], Loss: 3.6139, Acc: 4.64%\n",
      "Epoch [3/100], Step [200/313], Loss: 3.5875, Acc: 4.62%\n",
      "Epoch [3/100], Step [210/313], Loss: 3.6555, Acc: 4.60%\n",
      "Epoch [3/100], Step [220/313], Loss: 3.6182, Acc: 4.59%\n",
      "Epoch [3/100], Step [230/313], Loss: 3.6921, Acc: 4.56%\n",
      "Epoch [3/100], Step [240/313], Loss: 3.6739, Acc: 4.50%\n",
      "Epoch [3/100], Step [250/313], Loss: 3.6640, Acc: 4.51%\n",
      "Epoch [3/100], Step [260/313], Loss: 3.6029, Acc: 4.54%\n",
      "Epoch [3/100], Step [270/313], Loss: 3.6298, Acc: 4.50%\n",
      "Epoch [3/100], Step [280/313], Loss: 3.6445, Acc: 4.50%\n",
      "Epoch [3/100], Step [290/313], Loss: 3.6467, Acc: 4.49%\n",
      "Epoch [3/100], Step [300/313], Loss: 3.6389, Acc: 4.52%\n",
      "Epoch [3/100], Step [310/313], Loss: 3.6800, Acc: 4.52%\n",
      "Epoch [4/100], Step [10/313], Loss: 3.6609, Acc: 5.39%\n",
      "Epoch [4/100], Step [20/313], Loss: 3.6485, Acc: 4.84%\n",
      "Epoch [4/100], Step [30/313], Loss: 3.6723, Acc: 4.77%\n",
      "Epoch [4/100], Step [40/313], Loss: 3.6526, Acc: 4.96%\n",
      "Epoch [4/100], Step [50/313], Loss: 3.7090, Acc: 4.94%\n",
      "Epoch [4/100], Step [60/313], Loss: 3.6461, Acc: 4.99%\n",
      "Epoch [4/100], Step [70/313], Loss: 3.6247, Acc: 4.98%\n",
      "Epoch [4/100], Step [80/313], Loss: 3.6621, Acc: 5.03%\n",
      "Epoch [4/100], Step [90/313], Loss: 3.6937, Acc: 5.01%\n",
      "Epoch [4/100], Step [100/313], Loss: 3.6568, Acc: 5.05%\n",
      "Epoch [4/100], Step [110/313], Loss: 3.6226, Acc: 5.06%\n",
      "Epoch [4/100], Step [120/313], Loss: 3.6839, Acc: 5.10%\n",
      "Epoch [4/100], Step [130/313], Loss: 3.6276, Acc: 5.14%\n",
      "Epoch [4/100], Step [140/313], Loss: 3.6286, Acc: 5.12%\n",
      "Epoch [4/100], Step [150/313], Loss: 3.6941, Acc: 5.11%\n",
      "Epoch [4/100], Step [160/313], Loss: 3.5692, Acc: 5.19%\n",
      "Epoch [4/100], Step [170/313], Loss: 3.5680, Acc: 5.16%\n",
      "Epoch [4/100], Step [180/313], Loss: 3.6507, Acc: 5.13%\n",
      "Epoch [4/100], Step [190/313], Loss: 3.5932, Acc: 5.18%\n",
      "Epoch [4/100], Step [200/313], Loss: 3.5651, Acc: 5.20%\n",
      "Epoch [4/100], Step [210/313], Loss: 3.6159, Acc: 5.24%\n",
      "Epoch [4/100], Step [220/313], Loss: 3.5748, Acc: 5.25%\n",
      "Epoch [4/100], Step [230/313], Loss: 3.6451, Acc: 5.23%\n",
      "Epoch [4/100], Step [240/313], Loss: 3.6335, Acc: 5.16%\n",
      "Epoch [4/100], Step [250/313], Loss: 3.6530, Acc: 5.17%\n",
      "Epoch [4/100], Step [260/313], Loss: 3.5943, Acc: 5.19%\n",
      "Epoch [4/100], Step [270/313], Loss: 3.5955, Acc: 5.15%\n",
      "Epoch [4/100], Step [280/313], Loss: 3.5873, Acc: 5.15%\n",
      "Epoch [4/100], Step [290/313], Loss: 3.6216, Acc: 5.16%\n",
      "Epoch [4/100], Step [300/313], Loss: 3.6117, Acc: 5.17%\n",
      "Epoch [4/100], Step [310/313], Loss: 3.6849, Acc: 5.14%\n",
      "Epoch [5/100], Step [10/313], Loss: 3.6682, Acc: 5.94%\n",
      "Epoch [5/100], Step [20/313], Loss: 3.6151, Acc: 5.55%\n",
      "Epoch [5/100], Step [30/313], Loss: 3.6564, Acc: 5.42%\n",
      "Epoch [5/100], Step [40/313], Loss: 3.6161, Acc: 5.45%\n",
      "Epoch [5/100], Step [50/313], Loss: 3.6912, Acc: 5.28%\n",
      "Epoch [5/100], Step [60/313], Loss: 3.6228, Acc: 5.33%\n",
      "Epoch [5/100], Step [70/313], Loss: 3.6117, Acc: 5.46%\n",
      "Epoch [5/100], Step [80/313], Loss: 3.6417, Acc: 5.59%\n",
      "Epoch [5/100], Step [90/313], Loss: 3.6646, Acc: 5.70%\n",
      "Epoch [5/100], Step [100/313], Loss: 3.5962, Acc: 5.68%\n",
      "Epoch [5/100], Step [110/313], Loss: 3.5844, Acc: 5.62%\n",
      "Epoch [5/100], Step [120/313], Loss: 3.6688, Acc: 5.62%\n",
      "Epoch [5/100], Step [130/313], Loss: 3.6218, Acc: 5.65%\n",
      "Epoch [5/100], Step [140/313], Loss: 3.6166, Acc: 5.66%\n",
      "Epoch [5/100], Step [150/313], Loss: 3.6597, Acc: 5.59%\n",
      "Epoch [5/100], Step [160/313], Loss: 3.5322, Acc: 5.62%\n",
      "Epoch [5/100], Step [170/313], Loss: 3.5006, Acc: 5.64%\n",
      "Epoch [5/100], Step [180/313], Loss: 3.6192, Acc: 5.60%\n",
      "Epoch [5/100], Step [190/313], Loss: 3.5511, Acc: 5.62%\n",
      "Epoch [5/100], Step [200/313], Loss: 3.5278, Acc: 5.68%\n",
      "Epoch [5/100], Step [210/313], Loss: 3.5836, Acc: 5.69%\n",
      "Epoch [5/100], Step [220/313], Loss: 3.5364, Acc: 5.68%\n",
      "Epoch [5/100], Step [230/313], Loss: 3.6035, Acc: 5.69%\n",
      "Epoch [5/100], Step [240/313], Loss: 3.6239, Acc: 5.64%\n",
      "Epoch [5/100], Step [250/313], Loss: 3.6458, Acc: 5.67%\n",
      "Epoch [5/100], Step [260/313], Loss: 3.5889, Acc: 5.68%\n",
      "Epoch [5/100], Step [270/313], Loss: 3.5872, Acc: 5.65%\n",
      "Epoch [5/100], Step [280/313], Loss: 3.5746, Acc: 5.67%\n",
      "Epoch [5/100], Step [290/313], Loss: 3.5764, Acc: 5.67%\n",
      "Epoch [5/100], Step [300/313], Loss: 3.6169, Acc: 5.68%\n",
      "Epoch [5/100], Step [310/313], Loss: 3.6460, Acc: 5.66%\n",
      "Epoch [6/100], Step [10/313], Loss: 3.6338, Acc: 6.72%\n",
      "Epoch [6/100], Step [20/313], Loss: 3.6088, Acc: 5.86%\n",
      "Epoch [6/100], Step [30/313], Loss: 3.6419, Acc: 5.78%\n",
      "Epoch [6/100], Step [40/313], Loss: 3.5878, Acc: 5.88%\n",
      "Epoch [6/100], Step [50/313], Loss: 3.6860, Acc: 5.62%\n",
      "Epoch [6/100], Step [60/313], Loss: 3.5826, Acc: 5.72%\n",
      "Epoch [6/100], Step [70/313], Loss: 3.5746, Acc: 5.79%\n",
      "Epoch [6/100], Step [80/313], Loss: 3.6252, Acc: 5.86%\n",
      "Epoch [6/100], Step [90/313], Loss: 3.6237, Acc: 5.98%\n",
      "Epoch [6/100], Step [100/313], Loss: 3.5824, Acc: 6.01%\n",
      "Epoch [6/100], Step [110/313], Loss: 3.5303, Acc: 5.99%\n",
      "Epoch [6/100], Step [120/313], Loss: 3.6439, Acc: 6.02%\n",
      "Epoch [6/100], Step [130/313], Loss: 3.5685, Acc: 6.09%\n",
      "Epoch [6/100], Step [140/313], Loss: 3.6000, Acc: 6.05%\n",
      "Epoch [6/100], Step [150/313], Loss: 3.6517, Acc: 6.04%\n",
      "Epoch [6/100], Step [160/313], Loss: 3.5091, Acc: 6.14%\n",
      "Epoch [6/100], Step [170/313], Loss: 3.4817, Acc: 6.19%\n",
      "Epoch [6/100], Step [180/313], Loss: 3.6127, Acc: 6.22%\n",
      "Epoch [6/100], Step [190/313], Loss: 3.4895, Acc: 6.22%\n",
      "Epoch [6/100], Step [200/313], Loss: 3.4871, Acc: 6.29%\n",
      "Epoch [6/100], Step [210/313], Loss: 3.5305, Acc: 6.34%\n",
      "Epoch [6/100], Step [220/313], Loss: 3.5048, Acc: 6.30%\n",
      "Epoch [6/100], Step [230/313], Loss: 3.5953, Acc: 6.30%\n",
      "Epoch [6/100], Step [240/313], Loss: 3.5987, Acc: 6.30%\n",
      "Epoch [6/100], Step [250/313], Loss: 3.6416, Acc: 6.31%\n",
      "Epoch [6/100], Step [260/313], Loss: 3.5643, Acc: 6.34%\n",
      "Epoch [6/100], Step [270/313], Loss: 3.5261, Acc: 6.34%\n",
      "Epoch [6/100], Step [280/313], Loss: 3.5221, Acc: 6.35%\n",
      "Epoch [6/100], Step [290/313], Loss: 3.5157, Acc: 6.36%\n",
      "Epoch [6/100], Step [300/313], Loss: 3.5980, Acc: 6.36%\n",
      "Epoch [6/100], Step [310/313], Loss: 3.6496, Acc: 6.33%\n",
      "Epoch [7/100], Step [10/313], Loss: 3.6013, Acc: 7.03%\n",
      "Epoch [7/100], Step [20/313], Loss: 3.5947, Acc: 6.56%\n",
      "Epoch [7/100], Step [30/313], Loss: 3.6120, Acc: 6.56%\n",
      "Epoch [7/100], Step [40/313], Loss: 3.5717, Acc: 6.62%\n",
      "Epoch [7/100], Step [50/313], Loss: 3.6094, Acc: 6.48%\n",
      "Epoch [7/100], Step [60/313], Loss: 3.5496, Acc: 6.48%\n",
      "Epoch [7/100], Step [70/313], Loss: 3.5481, Acc: 6.50%\n",
      "Epoch [7/100], Step [80/313], Loss: 3.5675, Acc: 6.50%\n",
      "Epoch [7/100], Step [90/313], Loss: 3.5958, Acc: 6.54%\n",
      "Epoch [7/100], Step [100/313], Loss: 3.5250, Acc: 6.64%\n",
      "Epoch [7/100], Step [110/313], Loss: 3.4793, Acc: 6.58%\n",
      "Epoch [7/100], Step [120/313], Loss: 3.6034, Acc: 6.65%\n",
      "Epoch [7/100], Step [130/313], Loss: 3.5463, Acc: 6.77%\n",
      "Epoch [7/100], Step [140/313], Loss: 3.5243, Acc: 6.78%\n",
      "Epoch [7/100], Step [150/313], Loss: 3.6223, Acc: 6.78%\n",
      "Epoch [7/100], Step [160/313], Loss: 3.4232, Acc: 6.91%\n",
      "Epoch [7/100], Step [170/313], Loss: 3.4429, Acc: 6.94%\n",
      "Epoch [7/100], Step [180/313], Loss: 3.5651, Acc: 6.94%\n",
      "Epoch [7/100], Step [190/313], Loss: 3.4533, Acc: 6.95%\n",
      "Epoch [7/100], Step [200/313], Loss: 3.4890, Acc: 7.05%\n",
      "Epoch [7/100], Step [210/313], Loss: 3.4975, Acc: 7.14%\n",
      "Epoch [7/100], Step [220/313], Loss: 3.4287, Acc: 7.14%\n",
      "Epoch [7/100], Step [230/313], Loss: 3.5734, Acc: 7.16%\n",
      "Epoch [7/100], Step [240/313], Loss: 3.5214, Acc: 7.16%\n",
      "Epoch [7/100], Step [250/313], Loss: 3.6015, Acc: 7.16%\n",
      "Epoch [7/100], Step [260/313], Loss: 3.5335, Acc: 7.13%\n",
      "Epoch [7/100], Step [270/313], Loss: 3.4792, Acc: 7.11%\n",
      "Epoch [7/100], Step [280/313], Loss: 3.4665, Acc: 7.12%\n",
      "Epoch [7/100], Step [290/313], Loss: 3.5007, Acc: 7.10%\n",
      "Epoch [7/100], Step [300/313], Loss: 3.5551, Acc: 7.11%\n",
      "Epoch [7/100], Step [310/313], Loss: 3.5627, Acc: 7.08%\n",
      "Epoch [8/100], Step [10/313], Loss: 3.5302, Acc: 7.81%\n",
      "Epoch [8/100], Step [20/313], Loss: 3.5323, Acc: 7.23%\n",
      "Epoch [8/100], Step [30/313], Loss: 3.5870, Acc: 7.34%\n",
      "Epoch [8/100], Step [40/313], Loss: 3.5377, Acc: 7.23%\n",
      "Epoch [8/100], Step [50/313], Loss: 3.5999, Acc: 7.20%\n",
      "Epoch [8/100], Step [60/313], Loss: 3.5116, Acc: 7.16%\n",
      "Epoch [8/100], Step [70/313], Loss: 3.5361, Acc: 7.23%\n",
      "Epoch [8/100], Step [80/313], Loss: 3.5575, Acc: 7.25%\n",
      "Epoch [8/100], Step [90/313], Loss: 3.5314, Acc: 7.32%\n",
      "Epoch [8/100], Step [100/313], Loss: 3.4787, Acc: 7.47%\n",
      "Epoch [8/100], Step [110/313], Loss: 3.4040, Acc: 7.44%\n",
      "Epoch [8/100], Step [120/313], Loss: 3.5456, Acc: 7.51%\n",
      "Epoch [8/100], Step [130/313], Loss: 3.4837, Acc: 7.66%\n",
      "Epoch [8/100], Step [140/313], Loss: 3.4653, Acc: 7.71%\n",
      "Epoch [8/100], Step [150/313], Loss: 3.5590, Acc: 7.73%\n",
      "Epoch [8/100], Step [160/313], Loss: 3.3651, Acc: 7.77%\n",
      "Epoch [8/100], Step [170/313], Loss: 3.4160, Acc: 7.84%\n",
      "Epoch [8/100], Step [180/313], Loss: 3.5370, Acc: 7.76%\n",
      "Epoch [8/100], Step [190/313], Loss: 3.3647, Acc: 7.78%\n",
      "Epoch [8/100], Step [200/313], Loss: 3.4030, Acc: 7.89%\n",
      "Epoch [8/100], Step [210/313], Loss: 3.4270, Acc: 7.95%\n",
      "Epoch [8/100], Step [220/313], Loss: 3.3093, Acc: 8.03%\n",
      "Epoch [8/100], Step [230/313], Loss: 3.5296, Acc: 8.03%\n",
      "Epoch [8/100], Step [240/313], Loss: 3.4839, Acc: 8.07%\n",
      "Epoch [8/100], Step [250/313], Loss: 3.5397, Acc: 8.11%\n",
      "Epoch [8/100], Step [260/313], Loss: 3.4480, Acc: 8.14%\n",
      "Epoch [8/100], Step [270/313], Loss: 3.3773, Acc: 8.14%\n",
      "Epoch [8/100], Step [280/313], Loss: 3.4141, Acc: 8.18%\n",
      "Epoch [8/100], Step [290/313], Loss: 3.4436, Acc: 8.20%\n",
      "Epoch [8/100], Step [300/313], Loss: 3.5090, Acc: 8.18%\n",
      "Epoch [8/100], Step [310/313], Loss: 3.4792, Acc: 8.19%\n",
      "Epoch [9/100], Step [10/313], Loss: 3.4869, Acc: 8.20%\n",
      "Epoch [9/100], Step [20/313], Loss: 3.4668, Acc: 8.48%\n",
      "Epoch [9/100], Step [30/313], Loss: 3.5330, Acc: 8.23%\n",
      "Epoch [9/100], Step [40/313], Loss: 3.4985, Acc: 8.38%\n",
      "Epoch [9/100], Step [50/313], Loss: 3.5593, Acc: 8.25%\n",
      "Epoch [9/100], Step [60/313], Loss: 3.4680, Acc: 8.36%\n",
      "Epoch [9/100], Step [70/313], Loss: 3.4717, Acc: 8.31%\n",
      "Epoch [9/100], Step [80/313], Loss: 3.5111, Acc: 8.36%\n",
      "Epoch [9/100], Step [90/313], Loss: 3.4560, Acc: 8.39%\n",
      "Epoch [9/100], Step [100/313], Loss: 3.4324, Acc: 8.43%\n",
      "Epoch [9/100], Step [110/313], Loss: 3.3575, Acc: 8.46%\n",
      "Epoch [9/100], Step [120/313], Loss: 3.5191, Acc: 8.51%\n",
      "Epoch [9/100], Step [130/313], Loss: 3.4780, Acc: 8.61%\n",
      "Epoch [9/100], Step [140/313], Loss: 3.4249, Acc: 8.77%\n",
      "Epoch [9/100], Step [150/313], Loss: 3.4652, Acc: 8.81%\n",
      "Epoch [9/100], Step [160/313], Loss: 3.3211, Acc: 8.90%\n",
      "Epoch [9/100], Step [170/313], Loss: 3.3587, Acc: 9.02%\n",
      "Epoch [9/100], Step [180/313], Loss: 3.4897, Acc: 8.97%\n",
      "Epoch [9/100], Step [190/313], Loss: 3.3463, Acc: 9.05%\n",
      "Epoch [9/100], Step [200/313], Loss: 3.3177, Acc: 9.20%\n",
      "Epoch [9/100], Step [210/313], Loss: 3.3687, Acc: 9.28%\n",
      "Epoch [9/100], Step [220/313], Loss: 3.2957, Acc: 9.27%\n",
      "Epoch [9/100], Step [230/313], Loss: 3.4681, Acc: 9.31%\n",
      "Epoch [9/100], Step [240/313], Loss: 3.4268, Acc: 9.35%\n",
      "Epoch [9/100], Step [250/313], Loss: 3.4714, Acc: 9.34%\n",
      "Epoch [9/100], Step [260/313], Loss: 3.3499, Acc: 9.39%\n",
      "Epoch [9/100], Step [270/313], Loss: 3.3242, Acc: 9.39%\n",
      "Epoch [9/100], Step [280/313], Loss: 3.2769, Acc: 9.41%\n",
      "Epoch [9/100], Step [290/313], Loss: 3.4226, Acc: 9.43%\n",
      "Epoch [9/100], Step [300/313], Loss: 3.4336, Acc: 9.42%\n",
      "Epoch [9/100], Step [310/313], Loss: 3.4459, Acc: 9.42%\n",
      "Epoch [10/100], Step [10/313], Loss: 3.4245, Acc: 8.98%\n",
      "Epoch [10/100], Step [20/313], Loss: 3.4501, Acc: 9.22%\n",
      "Epoch [10/100], Step [30/313], Loss: 3.4245, Acc: 9.71%\n",
      "Epoch [10/100], Step [40/313], Loss: 3.4050, Acc: 9.90%\n",
      "Epoch [10/100], Step [50/313], Loss: 3.4425, Acc: 9.83%\n",
      "Epoch [10/100], Step [60/313], Loss: 3.3660, Acc: 9.73%\n",
      "Epoch [10/100], Step [70/313], Loss: 3.4063, Acc: 9.87%\n",
      "Epoch [10/100], Step [80/313], Loss: 3.4462, Acc: 9.80%\n",
      "Epoch [10/100], Step [90/313], Loss: 3.4290, Acc: 10.00%\n",
      "Epoch [10/100], Step [100/313], Loss: 3.3863, Acc: 10.16%\n",
      "Epoch [10/100], Step [110/313], Loss: 3.2534, Acc: 10.11%\n",
      "Epoch [10/100], Step [120/313], Loss: 3.4732, Acc: 10.17%\n",
      "Epoch [10/100], Step [130/313], Loss: 3.3959, Acc: 10.34%\n",
      "Epoch [10/100], Step [140/313], Loss: 3.3808, Acc: 10.36%\n",
      "Epoch [10/100], Step [150/313], Loss: 3.4245, Acc: 10.38%\n",
      "Epoch [10/100], Step [160/313], Loss: 3.1914, Acc: 10.50%\n",
      "Epoch [10/100], Step [170/313], Loss: 3.3005, Acc: 10.58%\n",
      "Epoch [10/100], Step [180/313], Loss: 3.4038, Acc: 10.62%\n",
      "Epoch [10/100], Step [190/313], Loss: 3.2481, Acc: 10.77%\n",
      "Epoch [10/100], Step [200/313], Loss: 3.2793, Acc: 10.90%\n",
      "Epoch [10/100], Step [210/313], Loss: 3.3041, Acc: 11.00%\n",
      "Epoch [10/100], Step [220/313], Loss: 3.2364, Acc: 11.03%\n",
      "Epoch [10/100], Step [230/313], Loss: 3.3431, Acc: 11.04%\n",
      "Epoch [10/100], Step [240/313], Loss: 3.3405, Acc: 11.08%\n",
      "Epoch [10/100], Step [250/313], Loss: 3.3631, Acc: 11.10%\n",
      "Epoch [10/100], Step [260/313], Loss: 3.2103, Acc: 11.14%\n",
      "Epoch [10/100], Step [270/313], Loss: 3.2564, Acc: 11.13%\n",
      "Epoch [10/100], Step [280/313], Loss: 3.2008, Acc: 11.18%\n",
      "Epoch [10/100], Step [290/313], Loss: 3.3635, Acc: 11.18%\n",
      "Epoch [10/100], Step [300/313], Loss: 3.3507, Acc: 11.20%\n",
      "Epoch [10/100], Step [310/313], Loss: 3.3360, Acc: 11.20%\n",
      "Epoch [11/100], Step [10/313], Loss: 3.2934, Acc: 11.72%\n",
      "Epoch [11/100], Step [20/313], Loss: 3.3314, Acc: 11.25%\n",
      "Epoch [11/100], Step [30/313], Loss: 3.3268, Acc: 11.12%\n",
      "Epoch [11/100], Step [40/313], Loss: 3.2968, Acc: 11.52%\n",
      "Epoch [11/100], Step [50/313], Loss: 3.4053, Acc: 11.42%\n",
      "Epoch [11/100], Step [60/313], Loss: 3.2975, Acc: 11.55%\n",
      "Epoch [11/100], Step [70/313], Loss: 3.3146, Acc: 11.60%\n",
      "Epoch [11/100], Step [80/313], Loss: 3.4164, Acc: 11.69%\n",
      "Epoch [11/100], Step [90/313], Loss: 3.3458, Acc: 11.84%\n",
      "Epoch [11/100], Step [100/313], Loss: 3.2691, Acc: 11.94%\n",
      "Epoch [11/100], Step [110/313], Loss: 3.2155, Acc: 11.97%\n",
      "Epoch [11/100], Step [120/313], Loss: 3.3950, Acc: 11.97%\n",
      "Epoch [11/100], Step [130/313], Loss: 3.2986, Acc: 12.09%\n",
      "Epoch [11/100], Step [140/313], Loss: 3.3286, Acc: 12.17%\n",
      "Epoch [11/100], Step [150/313], Loss: 3.3397, Acc: 12.11%\n",
      "Epoch [11/100], Step [160/313], Loss: 3.1964, Acc: 12.18%\n",
      "Epoch [11/100], Step [170/313], Loss: 3.1838, Acc: 12.25%\n",
      "Epoch [11/100], Step [180/313], Loss: 3.3408, Acc: 12.28%\n",
      "Epoch [11/100], Step [190/313], Loss: 3.1216, Acc: 12.46%\n",
      "Epoch [11/100], Step [200/313], Loss: 3.2429, Acc: 12.62%\n",
      "Epoch [11/100], Step [210/313], Loss: 3.1970, Acc: 12.80%\n",
      "Epoch [11/100], Step [220/313], Loss: 3.1154, Acc: 12.83%\n",
      "Epoch [11/100], Step [230/313], Loss: 3.2867, Acc: 12.90%\n",
      "Epoch [11/100], Step [240/313], Loss: 3.3187, Acc: 12.99%\n",
      "Epoch [11/100], Step [250/313], Loss: 3.2814, Acc: 12.99%\n",
      "Epoch [11/100], Step [260/313], Loss: 3.0510, Acc: 13.03%\n",
      "Epoch [11/100], Step [270/313], Loss: 3.1153, Acc: 13.08%\n",
      "Epoch [11/100], Step [280/313], Loss: 3.0807, Acc: 13.15%\n",
      "Epoch [11/100], Step [290/313], Loss: 3.3199, Acc: 13.10%\n",
      "Epoch [11/100], Step [300/313], Loss: 3.2959, Acc: 13.10%\n",
      "Epoch [11/100], Step [310/313], Loss: 3.2279, Acc: 13.12%\n",
      "Epoch [12/100], Step [10/313], Loss: 3.1791, Acc: 13.05%\n",
      "Epoch [12/100], Step [20/313], Loss: 3.2764, Acc: 13.52%\n",
      "Epoch [12/100], Step [30/313], Loss: 3.2530, Acc: 13.41%\n",
      "Epoch [12/100], Step [40/313], Loss: 3.1931, Acc: 13.36%\n",
      "Epoch [12/100], Step [50/313], Loss: 3.2481, Acc: 13.69%\n",
      "Epoch [12/100], Step [60/313], Loss: 3.1772, Acc: 13.97%\n",
      "Epoch [12/100], Step [70/313], Loss: 3.1589, Acc: 14.33%\n",
      "Epoch [12/100], Step [80/313], Loss: 3.3144, Acc: 14.31%\n",
      "Epoch [12/100], Step [90/313], Loss: 3.2227, Acc: 14.45%\n",
      "Epoch [12/100], Step [100/313], Loss: 3.2193, Acc: 14.60%\n",
      "Epoch [12/100], Step [110/313], Loss: 3.0672, Acc: 14.60%\n",
      "Epoch [12/100], Step [120/313], Loss: 3.2550, Acc: 14.64%\n",
      "Epoch [12/100], Step [130/313], Loss: 3.1601, Acc: 14.73%\n",
      "Epoch [12/100], Step [140/313], Loss: 3.2027, Acc: 14.85%\n",
      "Epoch [12/100], Step [150/313], Loss: 3.2341, Acc: 14.79%\n",
      "Epoch [12/100], Step [160/313], Loss: 2.9963, Acc: 14.92%\n",
      "Epoch [12/100], Step [170/313], Loss: 3.1547, Acc: 14.93%\n",
      "Epoch [12/100], Step [180/313], Loss: 3.1980, Acc: 14.90%\n",
      "Epoch [12/100], Step [190/313], Loss: 3.0068, Acc: 15.13%\n",
      "Epoch [12/100], Step [200/313], Loss: 3.1421, Acc: 15.30%\n",
      "Epoch [12/100], Step [210/313], Loss: 3.0687, Acc: 15.42%\n",
      "Epoch [12/100], Step [220/313], Loss: 3.0293, Acc: 15.43%\n",
      "Epoch [12/100], Step [230/313], Loss: 3.2152, Acc: 15.51%\n",
      "Epoch [12/100], Step [240/313], Loss: 3.2411, Acc: 15.57%\n",
      "Epoch [12/100], Step [250/313], Loss: 3.1373, Acc: 15.56%\n",
      "Epoch [12/100], Step [260/313], Loss: 3.0445, Acc: 15.63%\n",
      "Epoch [12/100], Step [270/313], Loss: 3.0389, Acc: 15.67%\n",
      "Epoch [12/100], Step [280/313], Loss: 2.9437, Acc: 15.67%\n",
      "Epoch [12/100], Step [290/313], Loss: 3.2037, Acc: 15.67%\n",
      "Epoch [12/100], Step [300/313], Loss: 3.1600, Acc: 15.70%\n",
      "Epoch [12/100], Step [310/313], Loss: 3.1517, Acc: 15.70%\n",
      "Epoch [13/100], Step [10/313], Loss: 3.0929, Acc: 16.02%\n",
      "Epoch [13/100], Step [20/313], Loss: 3.2679, Acc: 16.13%\n",
      "Epoch [13/100], Step [30/313], Loss: 3.1861, Acc: 15.86%\n",
      "Epoch [13/100], Step [40/313], Loss: 3.1027, Acc: 16.27%\n",
      "Epoch [13/100], Step [50/313], Loss: 3.1749, Acc: 16.11%\n",
      "Epoch [13/100], Step [60/313], Loss: 3.0990, Acc: 16.13%\n",
      "Epoch [13/100], Step [70/313], Loss: 3.1189, Acc: 16.45%\n",
      "Epoch [13/100], Step [80/313], Loss: 3.3282, Acc: 16.59%\n",
      "Epoch [13/100], Step [90/313], Loss: 3.1239, Acc: 16.75%\n",
      "Epoch [13/100], Step [100/313], Loss: 3.1800, Acc: 16.74%\n",
      "Epoch [13/100], Step [110/313], Loss: 3.0059, Acc: 16.75%\n",
      "Epoch [13/100], Step [120/313], Loss: 3.1646, Acc: 16.89%\n",
      "Epoch [13/100], Step [130/313], Loss: 2.9950, Acc: 16.96%\n",
      "Epoch [13/100], Step [140/313], Loss: 3.1056, Acc: 17.15%\n",
      "Epoch [13/100], Step [150/313], Loss: 3.1812, Acc: 17.11%\n",
      "Epoch [13/100], Step [160/313], Loss: 2.9214, Acc: 17.20%\n",
      "Epoch [13/100], Step [170/313], Loss: 3.0058, Acc: 17.33%\n",
      "Epoch [13/100], Step [180/313], Loss: 3.0838, Acc: 17.33%\n",
      "Epoch [13/100], Step [190/313], Loss: 2.8638, Acc: 17.64%\n",
      "Epoch [13/100], Step [200/313], Loss: 3.0289, Acc: 17.74%\n",
      "Epoch [13/100], Step [210/313], Loss: 2.8969, Acc: 17.87%\n",
      "Epoch [13/100], Step [220/313], Loss: 2.8969, Acc: 17.92%\n",
      "Epoch [13/100], Step [230/313], Loss: 3.1461, Acc: 17.99%\n",
      "Epoch [13/100], Step [240/313], Loss: 3.1336, Acc: 18.04%\n",
      "Epoch [13/100], Step [250/313], Loss: 3.0400, Acc: 18.08%\n",
      "Epoch [13/100], Step [260/313], Loss: 2.8763, Acc: 18.18%\n",
      "Epoch [13/100], Step [270/313], Loss: 3.0456, Acc: 18.15%\n",
      "Epoch [13/100], Step [280/313], Loss: 2.9056, Acc: 18.17%\n",
      "Epoch [13/100], Step [290/313], Loss: 3.0743, Acc: 18.16%\n",
      "Epoch [13/100], Step [300/313], Loss: 3.0580, Acc: 18.18%\n",
      "Epoch [13/100], Step [310/313], Loss: 3.0354, Acc: 18.21%\n",
      "Epoch [14/100], Step [10/313], Loss: 3.0551, Acc: 19.22%\n",
      "Epoch [14/100], Step [20/313], Loss: 3.1252, Acc: 18.87%\n",
      "Epoch [14/100], Step [30/313], Loss: 3.0417, Acc: 18.98%\n",
      "Epoch [14/100], Step [40/313], Loss: 3.0046, Acc: 18.93%\n",
      "Epoch [14/100], Step [50/313], Loss: 3.0186, Acc: 19.03%\n",
      "Epoch [14/100], Step [60/313], Loss: 2.9587, Acc: 18.92%\n",
      "Epoch [14/100], Step [70/313], Loss: 2.9670, Acc: 19.25%\n",
      "Epoch [14/100], Step [80/313], Loss: 3.1918, Acc: 19.38%\n",
      "Epoch [14/100], Step [90/313], Loss: 2.9681, Acc: 19.61%\n",
      "Epoch [14/100], Step [100/313], Loss: 3.1053, Acc: 19.63%\n",
      "Epoch [14/100], Step [110/313], Loss: 2.9379, Acc: 19.53%\n",
      "Epoch [14/100], Step [120/313], Loss: 2.9170, Acc: 19.64%\n",
      "Epoch [14/100], Step [130/313], Loss: 2.8636, Acc: 19.78%\n",
      "Epoch [14/100], Step [140/313], Loss: 2.9883, Acc: 19.87%\n",
      "Epoch [14/100], Step [150/313], Loss: 3.2050, Acc: 19.81%\n",
      "Epoch [14/100], Step [160/313], Loss: 2.7785, Acc: 19.85%\n",
      "Epoch [14/100], Step [170/313], Loss: 2.8593, Acc: 20.02%\n",
      "Epoch [14/100], Step [180/313], Loss: 2.9403, Acc: 20.03%\n",
      "Epoch [14/100], Step [190/313], Loss: 2.7877, Acc: 20.28%\n",
      "Epoch [14/100], Step [200/313], Loss: 2.8551, Acc: 20.54%\n",
      "Epoch [14/100], Step [210/313], Loss: 2.7835, Acc: 20.73%\n",
      "Epoch [14/100], Step [220/313], Loss: 2.7311, Acc: 20.82%\n",
      "Epoch [14/100], Step [230/313], Loss: 3.0064, Acc: 20.94%\n",
      "Epoch [14/100], Step [240/313], Loss: 2.9109, Acc: 21.04%\n",
      "Epoch [14/100], Step [250/313], Loss: 2.9099, Acc: 21.08%\n",
      "Epoch [14/100], Step [260/313], Loss: 2.7466, Acc: 21.16%\n",
      "Epoch [14/100], Step [270/313], Loss: 2.9475, Acc: 21.17%\n",
      "Epoch [14/100], Step [280/313], Loss: 2.6886, Acc: 21.23%\n",
      "Epoch [14/100], Step [290/313], Loss: 2.9339, Acc: 21.28%\n",
      "Epoch [14/100], Step [300/313], Loss: 3.0098, Acc: 21.31%\n",
      "Epoch [14/100], Step [310/313], Loss: 2.9119, Acc: 21.31%\n",
      "Epoch [15/100], Step [10/313], Loss: 2.7672, Acc: 21.41%\n",
      "Epoch [15/100], Step [20/313], Loss: 3.0356, Acc: 21.37%\n",
      "Epoch [15/100], Step [30/313], Loss: 2.9971, Acc: 21.56%\n",
      "Epoch [15/100], Step [40/313], Loss: 2.8938, Acc: 21.39%\n",
      "Epoch [15/100], Step [50/313], Loss: 2.8929, Acc: 21.91%\n",
      "Epoch [15/100], Step [60/313], Loss: 2.8749, Acc: 22.16%\n",
      "Epoch [15/100], Step [70/313], Loss: 2.7724, Acc: 22.10%\n",
      "Epoch [15/100], Step [80/313], Loss: 2.9703, Acc: 22.36%\n",
      "Epoch [15/100], Step [90/313], Loss: 2.8232, Acc: 22.73%\n",
      "Epoch [15/100], Step [100/313], Loss: 2.9055, Acc: 22.80%\n",
      "Epoch [15/100], Step [110/313], Loss: 2.8158, Acc: 22.78%\n",
      "Epoch [15/100], Step [120/313], Loss: 2.8540, Acc: 22.76%\n",
      "Epoch [15/100], Step [130/313], Loss: 2.7293, Acc: 22.79%\n",
      "Epoch [15/100], Step [140/313], Loss: 2.8894, Acc: 23.02%\n",
      "Epoch [15/100], Step [150/313], Loss: 2.9629, Acc: 23.10%\n",
      "Epoch [15/100], Step [160/313], Loss: 2.5900, Acc: 23.25%\n",
      "Epoch [15/100], Step [170/313], Loss: 2.8436, Acc: 23.40%\n",
      "Epoch [15/100], Step [180/313], Loss: 2.7525, Acc: 23.36%\n",
      "Epoch [15/100], Step [190/313], Loss: 2.7040, Acc: 23.61%\n",
      "Epoch [15/100], Step [200/313], Loss: 2.6634, Acc: 23.81%\n",
      "Epoch [15/100], Step [210/313], Loss: 2.6001, Acc: 23.94%\n",
      "Epoch [15/100], Step [220/313], Loss: 2.5971, Acc: 24.01%\n",
      "Epoch [15/100], Step [230/313], Loss: 2.8826, Acc: 24.13%\n",
      "Epoch [15/100], Step [240/313], Loss: 2.7799, Acc: 24.20%\n",
      "Epoch [15/100], Step [250/313], Loss: 2.7614, Acc: 24.23%\n",
      "Epoch [15/100], Step [260/313], Loss: 2.5334, Acc: 24.35%\n",
      "Epoch [15/100], Step [270/313], Loss: 2.6893, Acc: 24.35%\n",
      "Epoch [15/100], Step [280/313], Loss: 2.5932, Acc: 24.36%\n",
      "Epoch [15/100], Step [290/313], Loss: 2.8106, Acc: 24.42%\n",
      "Epoch [15/100], Step [300/313], Loss: 2.8827, Acc: 24.49%\n",
      "Epoch [15/100], Step [310/313], Loss: 2.7628, Acc: 24.49%\n",
      "Epoch [16/100], Step [10/313], Loss: 2.7350, Acc: 26.64%\n",
      "Epoch [16/100], Step [20/313], Loss: 2.9159, Acc: 25.23%\n",
      "Epoch [16/100], Step [30/313], Loss: 2.8922, Acc: 25.21%\n",
      "Epoch [16/100], Step [40/313], Loss: 2.7796, Acc: 25.02%\n",
      "Epoch [16/100], Step [50/313], Loss: 2.8256, Acc: 25.17%\n",
      "Epoch [16/100], Step [60/313], Loss: 2.7566, Acc: 25.05%\n",
      "Epoch [16/100], Step [70/313], Loss: 2.7457, Acc: 25.07%\n",
      "Epoch [16/100], Step [80/313], Loss: 2.8492, Acc: 25.32%\n",
      "Epoch [16/100], Step [90/313], Loss: 2.7188, Acc: 25.47%\n",
      "Epoch [16/100], Step [100/313], Loss: 2.7202, Acc: 25.59%\n",
      "Epoch [16/100], Step [110/313], Loss: 2.7456, Acc: 25.42%\n",
      "Epoch [16/100], Step [120/313], Loss: 2.7924, Acc: 25.42%\n",
      "Epoch [16/100], Step [130/313], Loss: 2.6430, Acc: 25.51%\n",
      "Epoch [16/100], Step [140/313], Loss: 2.7560, Acc: 25.74%\n",
      "Epoch [16/100], Step [150/313], Loss: 2.8643, Acc: 25.71%\n",
      "Epoch [16/100], Step [160/313], Loss: 2.5700, Acc: 25.86%\n",
      "Epoch [16/100], Step [170/313], Loss: 2.6615, Acc: 25.88%\n",
      "Epoch [16/100], Step [180/313], Loss: 2.5933, Acc: 25.91%\n",
      "Epoch [16/100], Step [190/313], Loss: 2.6808, Acc: 26.21%\n",
      "Epoch [16/100], Step [200/313], Loss: 2.4993, Acc: 26.41%\n",
      "Epoch [16/100], Step [210/313], Loss: 2.4022, Acc: 26.57%\n",
      "Epoch [16/100], Step [220/313], Loss: 2.5247, Acc: 26.61%\n",
      "Epoch [16/100], Step [230/313], Loss: 2.6165, Acc: 26.77%\n",
      "Epoch [16/100], Step [240/313], Loss: 2.6616, Acc: 26.74%\n",
      "Epoch [16/100], Step [250/313], Loss: 2.7621, Acc: 26.82%\n",
      "Epoch [16/100], Step [260/313], Loss: 2.3716, Acc: 26.97%\n",
      "Epoch [16/100], Step [270/313], Loss: 2.6084, Acc: 26.98%\n",
      "Epoch [16/100], Step [280/313], Loss: 2.4017, Acc: 27.05%\n",
      "Epoch [16/100], Step [290/313], Loss: 2.5871, Acc: 27.15%\n",
      "Epoch [16/100], Step [300/313], Loss: 2.7230, Acc: 27.16%\n",
      "Epoch [16/100], Step [310/313], Loss: 2.7546, Acc: 27.16%\n",
      "Epoch [17/100], Step [10/313], Loss: 2.6824, Acc: 28.83%\n",
      "Epoch [17/100], Step [20/313], Loss: 2.7651, Acc: 27.66%\n",
      "Epoch [17/100], Step [30/313], Loss: 2.8684, Acc: 27.29%\n",
      "Epoch [17/100], Step [40/313], Loss: 2.6705, Acc: 27.42%\n",
      "Epoch [17/100], Step [50/313], Loss: 2.7276, Acc: 27.45%\n",
      "Epoch [17/100], Step [60/313], Loss: 2.6378, Acc: 27.50%\n",
      "Epoch [17/100], Step [70/313], Loss: 2.6170, Acc: 27.56%\n",
      "Epoch [17/100], Step [80/313], Loss: 2.7683, Acc: 27.73%\n",
      "Epoch [17/100], Step [90/313], Loss: 2.5338, Acc: 27.92%\n",
      "Epoch [17/100], Step [100/313], Loss: 2.6432, Acc: 28.11%\n",
      "Epoch [17/100], Step [110/313], Loss: 2.6153, Acc: 28.09%\n",
      "Epoch [17/100], Step [120/313], Loss: 2.7298, Acc: 28.14%\n",
      "Epoch [17/100], Step [130/313], Loss: 2.5288, Acc: 28.12%\n",
      "Epoch [17/100], Step [140/313], Loss: 2.7502, Acc: 28.09%\n",
      "Epoch [17/100], Step [150/313], Loss: 2.8204, Acc: 28.04%\n",
      "Epoch [17/100], Step [160/313], Loss: 2.4395, Acc: 28.23%\n",
      "Epoch [17/100], Step [170/313], Loss: 2.5479, Acc: 28.22%\n",
      "Epoch [17/100], Step [180/313], Loss: 2.3937, Acc: 28.34%\n",
      "Epoch [17/100], Step [190/313], Loss: 2.5410, Acc: 28.45%\n",
      "Epoch [17/100], Step [200/313], Loss: 2.4991, Acc: 28.56%\n",
      "Epoch [17/100], Step [210/313], Loss: 2.3163, Acc: 28.72%\n",
      "Epoch [17/100], Step [220/313], Loss: 2.3306, Acc: 28.81%\n",
      "Epoch [17/100], Step [230/313], Loss: 2.6224, Acc: 29.00%\n",
      "Epoch [17/100], Step [240/313], Loss: 2.5351, Acc: 29.05%\n",
      "Epoch [17/100], Step [250/313], Loss: 2.5174, Acc: 29.18%\n",
      "Epoch [17/100], Step [260/313], Loss: 2.3990, Acc: 29.31%\n",
      "Epoch [17/100], Step [270/313], Loss: 2.5303, Acc: 29.31%\n",
      "Epoch [17/100], Step [280/313], Loss: 2.3120, Acc: 29.40%\n",
      "Epoch [17/100], Step [290/313], Loss: 2.4332, Acc: 29.50%\n",
      "Epoch [17/100], Step [300/313], Loss: 2.5870, Acc: 29.61%\n",
      "Epoch [17/100], Step [310/313], Loss: 2.6948, Acc: 29.67%\n",
      "Epoch [18/100], Step [10/313], Loss: 2.5038, Acc: 32.58%\n",
      "Epoch [18/100], Step [20/313], Loss: 2.7466, Acc: 31.05%\n",
      "Epoch [18/100], Step [30/313], Loss: 2.6565, Acc: 30.91%\n",
      "Epoch [18/100], Step [40/313], Loss: 2.6751, Acc: 30.94%\n",
      "Epoch [18/100], Step [50/313], Loss: 2.6912, Acc: 31.08%\n",
      "Epoch [18/100], Step [60/313], Loss: 2.5182, Acc: 31.02%\n",
      "Epoch [18/100], Step [70/313], Loss: 2.4437, Acc: 31.27%\n",
      "Epoch [18/100], Step [80/313], Loss: 2.6665, Acc: 31.27%\n",
      "Epoch [18/100], Step [90/313], Loss: 2.4183, Acc: 31.55%\n",
      "Epoch [18/100], Step [100/313], Loss: 2.4994, Acc: 31.73%\n",
      "Epoch [18/100], Step [110/313], Loss: 2.4445, Acc: 31.62%\n",
      "Epoch [18/100], Step [120/313], Loss: 2.4903, Acc: 31.73%\n",
      "Epoch [18/100], Step [130/313], Loss: 2.3229, Acc: 31.86%\n",
      "Epoch [18/100], Step [140/313], Loss: 2.4713, Acc: 31.88%\n",
      "Epoch [18/100], Step [150/313], Loss: 2.6401, Acc: 31.79%\n",
      "Epoch [18/100], Step [160/313], Loss: 2.3561, Acc: 31.84%\n",
      "Epoch [18/100], Step [170/313], Loss: 2.4136, Acc: 31.84%\n",
      "Epoch [18/100], Step [180/313], Loss: 2.2260, Acc: 31.88%\n",
      "Epoch [18/100], Step [190/313], Loss: 2.3860, Acc: 32.04%\n",
      "Epoch [18/100], Step [200/313], Loss: 2.3524, Acc: 32.23%\n",
      "Epoch [18/100], Step [210/313], Loss: 2.1821, Acc: 32.37%\n",
      "Epoch [18/100], Step [220/313], Loss: 2.1564, Acc: 32.43%\n",
      "Epoch [18/100], Step [230/313], Loss: 2.4360, Acc: 32.61%\n",
      "Epoch [18/100], Step [240/313], Loss: 2.5049, Acc: 32.68%\n",
      "Epoch [18/100], Step [250/313], Loss: 2.3675, Acc: 32.75%\n",
      "Epoch [18/100], Step [260/313], Loss: 2.2296, Acc: 32.80%\n",
      "Epoch [18/100], Step [270/313], Loss: 2.5072, Acc: 32.81%\n",
      "Epoch [18/100], Step [280/313], Loss: 2.1551, Acc: 32.90%\n",
      "Epoch [18/100], Step [290/313], Loss: 2.4322, Acc: 32.93%\n",
      "Epoch [18/100], Step [300/313], Loss: 2.3998, Acc: 33.04%\n",
      "Epoch [18/100], Step [310/313], Loss: 2.5580, Acc: 33.06%\n",
      "Epoch [19/100], Step [10/313], Loss: 2.3629, Acc: 35.08%\n",
      "Epoch [19/100], Step [20/313], Loss: 2.6689, Acc: 33.55%\n",
      "Epoch [19/100], Step [30/313], Loss: 2.5720, Acc: 33.65%\n",
      "Epoch [19/100], Step [40/313], Loss: 2.6315, Acc: 33.93%\n",
      "Epoch [19/100], Step [50/313], Loss: 2.5837, Acc: 33.88%\n",
      "Epoch [19/100], Step [60/313], Loss: 2.4269, Acc: 33.76%\n",
      "Epoch [19/100], Step [70/313], Loss: 2.4034, Acc: 34.17%\n",
      "Epoch [19/100], Step [80/313], Loss: 2.5957, Acc: 34.25%\n",
      "Epoch [19/100], Step [90/313], Loss: 2.2495, Acc: 34.47%\n",
      "Epoch [19/100], Step [100/313], Loss: 2.4164, Acc: 34.55%\n",
      "Epoch [19/100], Step [110/313], Loss: 2.4476, Acc: 34.52%\n",
      "Epoch [19/100], Step [120/313], Loss: 2.4829, Acc: 34.66%\n",
      "Epoch [19/100], Step [130/313], Loss: 2.2323, Acc: 34.67%\n",
      "Epoch [19/100], Step [140/313], Loss: 2.4831, Acc: 34.72%\n",
      "Epoch [19/100], Step [150/313], Loss: 2.4956, Acc: 34.59%\n",
      "Epoch [19/100], Step [160/313], Loss: 2.2312, Acc: 34.63%\n",
      "Epoch [19/100], Step [170/313], Loss: 2.3558, Acc: 34.71%\n",
      "Epoch [19/100], Step [180/313], Loss: 2.2138, Acc: 34.66%\n",
      "Epoch [19/100], Step [190/313], Loss: 2.2588, Acc: 34.75%\n",
      "Epoch [19/100], Step [200/313], Loss: 2.2513, Acc: 34.81%\n",
      "Epoch [19/100], Step [210/313], Loss: 2.0523, Acc: 35.07%\n",
      "Epoch [19/100], Step [220/313], Loss: 2.1427, Acc: 35.18%\n",
      "Epoch [19/100], Step [230/313], Loss: 2.3277, Acc: 35.35%\n",
      "Epoch [19/100], Step [240/313], Loss: 2.3629, Acc: 35.46%\n",
      "Epoch [19/100], Step [250/313], Loss: 2.2666, Acc: 35.61%\n",
      "Epoch [19/100], Step [260/313], Loss: 2.1384, Acc: 35.62%\n",
      "Epoch [19/100], Step [270/313], Loss: 2.3155, Acc: 35.62%\n",
      "Epoch [19/100], Step [280/313], Loss: 2.0774, Acc: 35.68%\n",
      "Epoch [19/100], Step [290/313], Loss: 2.3718, Acc: 35.75%\n",
      "Epoch [19/100], Step [300/313], Loss: 2.3536, Acc: 35.82%\n",
      "Epoch [19/100], Step [310/313], Loss: 2.4471, Acc: 35.83%\n",
      "Epoch [20/100], Step [10/313], Loss: 2.3148, Acc: 37.34%\n",
      "Epoch [20/100], Step [20/313], Loss: 2.5329, Acc: 36.68%\n",
      "Epoch [20/100], Step [30/313], Loss: 2.4882, Acc: 36.17%\n",
      "Epoch [20/100], Step [40/313], Loss: 2.4482, Acc: 36.39%\n",
      "Epoch [20/100], Step [50/313], Loss: 2.4204, Acc: 36.28%\n",
      "Epoch [20/100], Step [60/313], Loss: 2.2610, Acc: 36.20%\n",
      "Epoch [20/100], Step [70/313], Loss: 2.2616, Acc: 36.66%\n",
      "Epoch [20/100], Step [80/313], Loss: 2.4475, Acc: 36.44%\n",
      "Epoch [20/100], Step [90/313], Loss: 2.3073, Acc: 36.59%\n",
      "Epoch [20/100], Step [100/313], Loss: 2.2304, Acc: 36.59%\n",
      "Epoch [20/100], Step [110/313], Loss: 2.3710, Acc: 36.58%\n",
      "Epoch [20/100], Step [120/313], Loss: 2.3687, Acc: 36.73%\n",
      "Epoch [20/100], Step [130/313], Loss: 2.1784, Acc: 36.73%\n",
      "Epoch [20/100], Step [140/313], Loss: 2.2474, Acc: 36.74%\n",
      "Epoch [20/100], Step [150/313], Loss: 2.3453, Acc: 36.67%\n",
      "Epoch [20/100], Step [160/313], Loss: 2.1514, Acc: 36.79%\n",
      "Epoch [20/100], Step [170/313], Loss: 2.2562, Acc: 36.77%\n",
      "Epoch [20/100], Step [180/313], Loss: 2.1446, Acc: 36.68%\n",
      "Epoch [20/100], Step [190/313], Loss: 2.1887, Acc: 36.78%\n",
      "Epoch [20/100], Step [200/313], Loss: 2.1315, Acc: 36.87%\n",
      "Epoch [20/100], Step [210/313], Loss: 1.9740, Acc: 36.98%\n",
      "Epoch [20/100], Step [220/313], Loss: 2.1560, Acc: 37.01%\n",
      "Epoch [20/100], Step [230/313], Loss: 2.2372, Acc: 37.09%\n",
      "Epoch [20/100], Step [240/313], Loss: 2.3183, Acc: 37.19%\n",
      "Epoch [20/100], Step [250/313], Loss: 2.1650, Acc: 37.25%\n",
      "Epoch [20/100], Step [260/313], Loss: 1.9909, Acc: 37.30%\n",
      "Epoch [20/100], Step [270/313], Loss: 2.2738, Acc: 37.28%\n",
      "Epoch [20/100], Step [280/313], Loss: 1.9993, Acc: 37.41%\n",
      "Epoch [20/100], Step [290/313], Loss: 2.1772, Acc: 37.50%\n",
      "Epoch [20/100], Step [300/313], Loss: 2.3301, Acc: 37.60%\n",
      "Epoch [20/100], Step [310/313], Loss: 2.3673, Acc: 37.67%\n",
      "Epoch [21/100], Step [10/313], Loss: 2.1346, Acc: 39.14%\n",
      "Epoch [21/100], Step [20/313], Loss: 2.3158, Acc: 38.67%\n",
      "Epoch [21/100], Step [30/313], Loss: 2.3246, Acc: 39.43%\n",
      "Epoch [21/100], Step [40/313], Loss: 2.2746, Acc: 39.39%\n",
      "Epoch [21/100], Step [50/313], Loss: 2.3342, Acc: 39.41%\n",
      "Epoch [21/100], Step [60/313], Loss: 2.1571, Acc: 39.36%\n",
      "Epoch [21/100], Step [70/313], Loss: 2.1824, Acc: 39.35%\n",
      "Epoch [21/100], Step [80/313], Loss: 2.4833, Acc: 39.16%\n",
      "Epoch [21/100], Step [90/313], Loss: 2.2197, Acc: 39.33%\n",
      "Epoch [21/100], Step [100/313], Loss: 2.1086, Acc: 39.39%\n",
      "Epoch [21/100], Step [110/313], Loss: 2.3351, Acc: 39.27%\n",
      "Epoch [21/100], Step [120/313], Loss: 2.2228, Acc: 39.43%\n",
      "Epoch [21/100], Step [130/313], Loss: 2.0941, Acc: 39.48%\n",
      "Epoch [21/100], Step [140/313], Loss: 2.1266, Acc: 39.54%\n",
      "Epoch [21/100], Step [150/313], Loss: 2.2977, Acc: 39.32%\n",
      "Epoch [21/100], Step [160/313], Loss: 2.0180, Acc: 39.49%\n",
      "Epoch [21/100], Step [170/313], Loss: 2.1513, Acc: 39.40%\n",
      "Epoch [21/100], Step [180/313], Loss: 1.9944, Acc: 39.33%\n",
      "Epoch [21/100], Step [190/313], Loss: 2.1303, Acc: 39.46%\n",
      "Epoch [21/100], Step [200/313], Loss: 2.1550, Acc: 39.54%\n",
      "Epoch [21/100], Step [210/313], Loss: 2.0329, Acc: 39.51%\n",
      "Epoch [21/100], Step [220/313], Loss: 2.1440, Acc: 39.46%\n",
      "Epoch [21/100], Step [230/313], Loss: 2.1420, Acc: 39.56%\n",
      "Epoch [21/100], Step [240/313], Loss: 2.2520, Acc: 39.53%\n",
      "Epoch [21/100], Step [250/313], Loss: 2.1446, Acc: 39.67%\n",
      "Epoch [21/100], Step [260/313], Loss: 2.0366, Acc: 39.58%\n",
      "Epoch [21/100], Step [270/313], Loss: 2.0873, Acc: 39.61%\n",
      "Epoch [21/100], Step [280/313], Loss: 1.9946, Acc: 39.69%\n",
      "Epoch [21/100], Step [290/313], Loss: 2.0746, Acc: 39.76%\n",
      "Epoch [21/100], Step [300/313], Loss: 2.3783, Acc: 39.81%\n",
      "Epoch [21/100], Step [310/313], Loss: 2.2311, Acc: 39.85%\n",
      "Epoch [22/100], Step [10/313], Loss: 2.0387, Acc: 40.78%\n",
      "Epoch [22/100], Step [20/313], Loss: 2.2579, Acc: 40.47%\n",
      "Epoch [22/100], Step [30/313], Loss: 2.2396, Acc: 40.70%\n",
      "Epoch [22/100], Step [40/313], Loss: 2.2021, Acc: 40.94%\n",
      "Epoch [22/100], Step [50/313], Loss: 2.3544, Acc: 40.72%\n",
      "Epoch [22/100], Step [60/313], Loss: 2.0070, Acc: 40.66%\n",
      "Epoch [22/100], Step [70/313], Loss: 2.0829, Acc: 41.03%\n",
      "Epoch [22/100], Step [80/313], Loss: 2.3661, Acc: 40.99%\n",
      "Epoch [22/100], Step [90/313], Loss: 2.0682, Acc: 41.23%\n",
      "Epoch [22/100], Step [100/313], Loss: 2.1042, Acc: 41.35%\n",
      "Epoch [22/100], Step [110/313], Loss: 2.2122, Acc: 41.40%\n",
      "Epoch [22/100], Step [120/313], Loss: 2.2401, Acc: 41.45%\n",
      "Epoch [22/100], Step [130/313], Loss: 2.1508, Acc: 41.46%\n",
      "Epoch [22/100], Step [140/313], Loss: 2.0744, Acc: 41.46%\n",
      "Epoch [22/100], Step [150/313], Loss: 2.1061, Acc: 41.28%\n",
      "Epoch [22/100], Step [160/313], Loss: 1.8952, Acc: 41.33%\n",
      "Epoch [22/100], Step [170/313], Loss: 2.1135, Acc: 41.26%\n",
      "Epoch [22/100], Step [180/313], Loss: 1.8821, Acc: 41.14%\n",
      "Epoch [22/100], Step [190/313], Loss: 2.0870, Acc: 41.31%\n",
      "Epoch [22/100], Step [200/313], Loss: 2.0724, Acc: 41.36%\n",
      "Epoch [22/100], Step [210/313], Loss: 1.8935, Acc: 41.35%\n",
      "Epoch [22/100], Step [220/313], Loss: 2.0457, Acc: 41.35%\n",
      "Epoch [22/100], Step [230/313], Loss: 2.0231, Acc: 41.48%\n",
      "Epoch [22/100], Step [240/313], Loss: 2.1412, Acc: 41.55%\n",
      "Epoch [22/100], Step [250/313], Loss: 2.1511, Acc: 41.68%\n",
      "Epoch [22/100], Step [260/313], Loss: 2.0046, Acc: 41.63%\n",
      "Epoch [22/100], Step [270/313], Loss: 2.0184, Acc: 41.57%\n",
      "Epoch [22/100], Step [280/313], Loss: 1.9022, Acc: 41.62%\n",
      "Epoch [22/100], Step [290/313], Loss: 2.1291, Acc: 41.69%\n",
      "Epoch [22/100], Step [300/313], Loss: 2.2242, Acc: 41.66%\n",
      "Epoch [22/100], Step [310/313], Loss: 2.1333, Acc: 41.60%\n",
      "Epoch [23/100], Step [10/313], Loss: 2.0542, Acc: 42.03%\n",
      "Epoch [23/100], Step [20/313], Loss: 2.2681, Acc: 41.68%\n",
      "Epoch [23/100], Step [30/313], Loss: 2.1323, Acc: 42.40%\n",
      "Epoch [23/100], Step [40/313], Loss: 2.1213, Acc: 42.42%\n",
      "Epoch [23/100], Step [50/313], Loss: 2.1759, Acc: 42.41%\n",
      "Epoch [23/100], Step [60/313], Loss: 1.9418, Acc: 42.42%\n",
      "Epoch [23/100], Step [70/313], Loss: 2.0081, Acc: 42.75%\n",
      "Epoch [23/100], Step [80/313], Loss: 2.2822, Acc: 42.65%\n",
      "Epoch [23/100], Step [90/313], Loss: 2.0310, Acc: 42.74%\n",
      "Epoch [23/100], Step [100/313], Loss: 2.0150, Acc: 42.98%\n",
      "Epoch [23/100], Step [110/313], Loss: 2.0655, Acc: 42.96%\n",
      "Epoch [23/100], Step [120/313], Loss: 2.1757, Acc: 43.09%\n",
      "Epoch [23/100], Step [130/313], Loss: 2.0132, Acc: 43.08%\n",
      "Epoch [23/100], Step [140/313], Loss: 2.0012, Acc: 43.20%\n",
      "Epoch [23/100], Step [150/313], Loss: 2.1638, Acc: 43.06%\n",
      "Epoch [23/100], Step [160/313], Loss: 1.7882, Acc: 43.12%\n",
      "Epoch [23/100], Step [170/313], Loss: 1.9905, Acc: 43.05%\n",
      "Epoch [23/100], Step [180/313], Loss: 1.8977, Acc: 43.00%\n",
      "Epoch [23/100], Step [190/313], Loss: 1.9897, Acc: 43.25%\n",
      "Epoch [23/100], Step [200/313], Loss: 1.9684, Acc: 43.33%\n",
      "Epoch [23/100], Step [210/313], Loss: 1.8729, Acc: 43.34%\n",
      "Epoch [23/100], Step [220/313], Loss: 1.9505, Acc: 43.35%\n",
      "Epoch [23/100], Step [230/313], Loss: 1.8692, Acc: 43.52%\n",
      "Epoch [23/100], Step [240/313], Loss: 1.9751, Acc: 43.53%\n",
      "Epoch [23/100], Step [250/313], Loss: 1.9354, Acc: 43.69%\n",
      "Epoch [23/100], Step [260/313], Loss: 1.9263, Acc: 43.73%\n",
      "Epoch [23/100], Step [270/313], Loss: 1.8166, Acc: 43.71%\n",
      "Epoch [23/100], Step [280/313], Loss: 1.7111, Acc: 43.70%\n",
      "Epoch [23/100], Step [290/313], Loss: 1.9416, Acc: 43.70%\n",
      "Epoch [23/100], Step [300/313], Loss: 2.2127, Acc: 43.79%\n",
      "Epoch [23/100], Step [310/313], Loss: 2.1366, Acc: 43.82%\n",
      "Epoch [24/100], Step [10/313], Loss: 1.9885, Acc: 42.66%\n",
      "Epoch [24/100], Step [20/313], Loss: 2.1779, Acc: 42.73%\n",
      "Epoch [24/100], Step [30/313], Loss: 1.9938, Acc: 43.67%\n",
      "Epoch [24/100], Step [40/313], Loss: 2.0228, Acc: 43.83%\n",
      "Epoch [24/100], Step [50/313], Loss: 2.1845, Acc: 43.88%\n",
      "Epoch [24/100], Step [60/313], Loss: 1.9620, Acc: 43.82%\n",
      "Epoch [24/100], Step [70/313], Loss: 1.9265, Acc: 44.00%\n",
      "Epoch [24/100], Step [80/313], Loss: 2.2543, Acc: 43.97%\n",
      "Epoch [24/100], Step [90/313], Loss: 1.9040, Acc: 44.33%\n",
      "Epoch [24/100], Step [100/313], Loss: 1.9167, Acc: 44.63%\n",
      "Epoch [24/100], Step [110/313], Loss: 1.9951, Acc: 44.79%\n",
      "Epoch [24/100], Step [120/313], Loss: 2.1472, Acc: 44.87%\n",
      "Epoch [24/100], Step [130/313], Loss: 2.0173, Acc: 44.92%\n",
      "Epoch [24/100], Step [140/313], Loss: 1.9463, Acc: 45.02%\n",
      "Epoch [24/100], Step [150/313], Loss: 1.9964, Acc: 44.89%\n",
      "Epoch [24/100], Step [160/313], Loss: 1.6936, Acc: 45.01%\n",
      "Epoch [24/100], Step [170/313], Loss: 1.8847, Acc: 44.98%\n",
      "Epoch [24/100], Step [180/313], Loss: 1.7116, Acc: 45.03%\n",
      "Epoch [24/100], Step [190/313], Loss: 1.9790, Acc: 45.19%\n",
      "Epoch [24/100], Step [200/313], Loss: 1.8632, Acc: 45.26%\n",
      "Epoch [24/100], Step [210/313], Loss: 1.8917, Acc: 45.17%\n",
      "Epoch [24/100], Step [220/313], Loss: 1.9696, Acc: 45.11%\n",
      "Epoch [24/100], Step [230/313], Loss: 1.8882, Acc: 45.29%\n",
      "Epoch [24/100], Step [240/313], Loss: 1.8680, Acc: 45.38%\n",
      "Epoch [24/100], Step [250/313], Loss: 1.8155, Acc: 45.47%\n",
      "Epoch [24/100], Step [260/313], Loss: 1.8694, Acc: 45.39%\n",
      "Epoch [24/100], Step [270/313], Loss: 1.8134, Acc: 45.30%\n",
      "Epoch [24/100], Step [280/313], Loss: 1.6907, Acc: 45.28%\n",
      "Epoch [24/100], Step [290/313], Loss: 1.8790, Acc: 45.30%\n",
      "Epoch [24/100], Step [300/313], Loss: 2.1561, Acc: 45.36%\n",
      "Epoch [24/100], Step [310/313], Loss: 2.1875, Acc: 45.37%\n",
      "Epoch [25/100], Step [10/313], Loss: 1.8926, Acc: 44.69%\n",
      "Epoch [25/100], Step [20/313], Loss: 2.0980, Acc: 44.02%\n",
      "Epoch [25/100], Step [30/313], Loss: 2.0688, Acc: 44.61%\n",
      "Epoch [25/100], Step [40/313], Loss: 1.9759, Acc: 44.63%\n",
      "Epoch [25/100], Step [50/313], Loss: 2.0756, Acc: 44.61%\n",
      "Epoch [25/100], Step [60/313], Loss: 1.9362, Acc: 44.77%\n",
      "Epoch [25/100], Step [70/313], Loss: 1.9043, Acc: 45.15%\n",
      "Epoch [25/100], Step [80/313], Loss: 2.1531, Acc: 45.31%\n",
      "Epoch [25/100], Step [90/313], Loss: 1.9620, Acc: 45.44%\n",
      "Epoch [25/100], Step [100/313], Loss: 1.9046, Acc: 45.69%\n",
      "Epoch [25/100], Step [110/313], Loss: 1.9460, Acc: 45.80%\n",
      "Epoch [25/100], Step [120/313], Loss: 2.1738, Acc: 45.82%\n",
      "Epoch [25/100], Step [130/313], Loss: 1.9264, Acc: 45.88%\n",
      "Epoch [25/100], Step [140/313], Loss: 1.8031, Acc: 45.94%\n",
      "Epoch [25/100], Step [150/313], Loss: 1.9365, Acc: 45.94%\n",
      "Epoch [25/100], Step [160/313], Loss: 1.7529, Acc: 45.96%\n",
      "Epoch [25/100], Step [170/313], Loss: 1.7622, Acc: 45.94%\n",
      "Epoch [25/100], Step [180/313], Loss: 1.5830, Acc: 45.92%\n",
      "Epoch [25/100], Step [190/313], Loss: 1.8480, Acc: 45.97%\n",
      "Epoch [25/100], Step [200/313], Loss: 1.9189, Acc: 46.05%\n",
      "Epoch [25/100], Step [210/313], Loss: 1.7431, Acc: 46.15%\n",
      "Epoch [25/100], Step [220/313], Loss: 1.8552, Acc: 46.17%\n",
      "Epoch [25/100], Step [230/313], Loss: 1.8989, Acc: 46.33%\n",
      "Epoch [25/100], Step [240/313], Loss: 1.7034, Acc: 46.46%\n",
      "Epoch [25/100], Step [250/313], Loss: 1.9192, Acc: 46.58%\n",
      "Epoch [25/100], Step [260/313], Loss: 1.8516, Acc: 46.57%\n",
      "Epoch [25/100], Step [270/313], Loss: 1.6764, Acc: 46.52%\n",
      "Epoch [25/100], Step [280/313], Loss: 1.6407, Acc: 46.53%\n",
      "Epoch [25/100], Step [290/313], Loss: 1.9168, Acc: 46.55%\n",
      "Epoch [25/100], Step [300/313], Loss: 1.9562, Acc: 46.61%\n",
      "Epoch [25/100], Step [310/313], Loss: 2.1200, Acc: 46.62%\n",
      "Epoch [26/100], Step [10/313], Loss: 1.9009, Acc: 46.17%\n",
      "Epoch [26/100], Step [20/313], Loss: 2.0319, Acc: 45.78%\n",
      "Epoch [26/100], Step [30/313], Loss: 2.0111, Acc: 45.83%\n",
      "Epoch [26/100], Step [40/313], Loss: 1.8925, Acc: 45.86%\n",
      "Epoch [26/100], Step [50/313], Loss: 2.0770, Acc: 46.19%\n",
      "Epoch [26/100], Step [60/313], Loss: 1.9004, Acc: 46.34%\n",
      "Epoch [26/100], Step [70/313], Loss: 1.8796, Acc: 46.53%\n",
      "Epoch [26/100], Step [80/313], Loss: 2.1707, Acc: 46.88%\n",
      "Epoch [26/100], Step [90/313], Loss: 1.9078, Acc: 47.08%\n",
      "Epoch [26/100], Step [100/313], Loss: 1.9289, Acc: 47.16%\n",
      "Epoch [26/100], Step [110/313], Loss: 1.9581, Acc: 47.02%\n",
      "Epoch [26/100], Step [120/313], Loss: 2.0303, Acc: 47.24%\n",
      "Epoch [26/100], Step [130/313], Loss: 1.7796, Acc: 47.24%\n",
      "Epoch [26/100], Step [140/313], Loss: 1.8931, Acc: 47.50%\n",
      "Epoch [26/100], Step [150/313], Loss: 1.7994, Acc: 47.38%\n",
      "Epoch [26/100], Step [160/313], Loss: 1.6844, Acc: 47.44%\n",
      "Epoch [26/100], Step [170/313], Loss: 1.6857, Acc: 47.39%\n",
      "Epoch [26/100], Step [180/313], Loss: 1.6707, Acc: 47.37%\n",
      "Epoch [26/100], Step [190/313], Loss: 1.7994, Acc: 47.50%\n",
      "Epoch [26/100], Step [200/313], Loss: 1.9282, Acc: 47.46%\n",
      "Epoch [26/100], Step [210/313], Loss: 1.7378, Acc: 47.45%\n",
      "Epoch [26/100], Step [220/313], Loss: 1.9444, Acc: 47.50%\n",
      "Epoch [26/100], Step [230/313], Loss: 1.7784, Acc: 47.62%\n",
      "Epoch [26/100], Step [240/313], Loss: 1.6588, Acc: 47.72%\n",
      "Epoch [26/100], Step [250/313], Loss: 1.6997, Acc: 47.80%\n",
      "Epoch [26/100], Step [260/313], Loss: 1.7344, Acc: 47.82%\n",
      "Epoch [26/100], Step [270/313], Loss: 1.6795, Acc: 47.87%\n",
      "Epoch [26/100], Step [280/313], Loss: 1.5171, Acc: 47.96%\n",
      "Epoch [26/100], Step [290/313], Loss: 1.8644, Acc: 47.97%\n",
      "Epoch [26/100], Step [300/313], Loss: 1.9492, Acc: 48.04%\n",
      "Epoch [26/100], Step [310/313], Loss: 2.0143, Acc: 48.11%\n",
      "Epoch [27/100], Step [10/313], Loss: 1.8045, Acc: 48.75%\n",
      "Epoch [27/100], Step [20/313], Loss: 2.1106, Acc: 47.19%\n",
      "Epoch [27/100], Step [30/313], Loss: 1.9476, Acc: 47.58%\n",
      "Epoch [27/100], Step [40/313], Loss: 1.8431, Acc: 47.56%\n",
      "Epoch [27/100], Step [50/313], Loss: 1.8276, Acc: 47.61%\n",
      "Epoch [27/100], Step [60/313], Loss: 1.7581, Acc: 47.68%\n",
      "Epoch [27/100], Step [70/313], Loss: 1.8827, Acc: 47.70%\n",
      "Epoch [27/100], Step [80/313], Loss: 2.0222, Acc: 48.02%\n",
      "Epoch [27/100], Step [90/313], Loss: 1.8018, Acc: 48.38%\n",
      "Epoch [27/100], Step [100/313], Loss: 1.8130, Acc: 48.61%\n",
      "Epoch [27/100], Step [110/313], Loss: 1.7933, Acc: 48.77%\n",
      "Epoch [27/100], Step [120/313], Loss: 1.8752, Acc: 49.15%\n",
      "Epoch [27/100], Step [130/313], Loss: 1.6188, Acc: 49.24%\n",
      "Epoch [27/100], Step [140/313], Loss: 1.7014, Acc: 49.46%\n",
      "Epoch [27/100], Step [150/313], Loss: 1.8048, Acc: 49.39%\n",
      "Epoch [27/100], Step [160/313], Loss: 1.5503, Acc: 49.55%\n",
      "Epoch [27/100], Step [170/313], Loss: 1.7293, Acc: 49.48%\n",
      "Epoch [27/100], Step [180/313], Loss: 1.6400, Acc: 49.41%\n",
      "Epoch [27/100], Step [190/313], Loss: 1.7180, Acc: 49.53%\n",
      "Epoch [27/100], Step [200/313], Loss: 1.8555, Acc: 49.50%\n",
      "Epoch [27/100], Step [210/313], Loss: 1.8010, Acc: 49.49%\n",
      "Epoch [27/100], Step [220/313], Loss: 1.8360, Acc: 49.53%\n",
      "Epoch [27/100], Step [230/313], Loss: 1.7632, Acc: 49.68%\n",
      "Epoch [27/100], Step [240/313], Loss: 1.6729, Acc: 49.79%\n",
      "Epoch [27/100], Step [250/313], Loss: 1.7466, Acc: 49.83%\n",
      "Epoch [27/100], Step [260/313], Loss: 1.6589, Acc: 49.84%\n",
      "Epoch [27/100], Step [270/313], Loss: 1.6371, Acc: 49.88%\n",
      "Epoch [27/100], Step [280/313], Loss: 1.5612, Acc: 49.91%\n",
      "Epoch [27/100], Step [290/313], Loss: 1.8301, Acc: 49.84%\n",
      "Epoch [27/100], Step [300/313], Loss: 1.8972, Acc: 49.89%\n",
      "Epoch [27/100], Step [310/313], Loss: 2.0245, Acc: 49.92%\n",
      "Epoch [28/100], Step [10/313], Loss: 1.6557, Acc: 50.55%\n",
      "Epoch [28/100], Step [20/313], Loss: 1.9432, Acc: 48.63%\n",
      "Epoch [28/100], Step [30/313], Loss: 1.8564, Acc: 49.14%\n",
      "Epoch [28/100], Step [40/313], Loss: 1.7444, Acc: 48.96%\n",
      "Epoch [28/100], Step [50/313], Loss: 1.9693, Acc: 49.28%\n",
      "Epoch [28/100], Step [60/313], Loss: 1.7173, Acc: 49.52%\n",
      "Epoch [28/100], Step [70/313], Loss: 1.7878, Acc: 49.62%\n",
      "Epoch [28/100], Step [80/313], Loss: 1.9109, Acc: 49.82%\n",
      "Epoch [28/100], Step [90/313], Loss: 1.7137, Acc: 50.32%\n",
      "Epoch [28/100], Step [100/313], Loss: 1.7122, Acc: 50.45%\n",
      "Epoch [28/100], Step [110/313], Loss: 1.8001, Acc: 50.50%\n",
      "Epoch [28/100], Step [120/313], Loss: 1.7542, Acc: 50.68%\n",
      "Epoch [28/100], Step [130/313], Loss: 1.6983, Acc: 50.81%\n",
      "Epoch [28/100], Step [140/313], Loss: 1.7994, Acc: 50.76%\n",
      "Epoch [28/100], Step [150/313], Loss: 1.7193, Acc: 50.62%\n",
      "Epoch [28/100], Step [160/313], Loss: 1.5628, Acc: 50.79%\n",
      "Epoch [28/100], Step [170/313], Loss: 1.6849, Acc: 50.65%\n",
      "Epoch [28/100], Step [180/313], Loss: 1.5421, Acc: 50.51%\n",
      "Epoch [28/100], Step [190/313], Loss: 1.7303, Acc: 50.63%\n",
      "Epoch [28/100], Step [200/313], Loss: 1.9035, Acc: 50.60%\n",
      "Epoch [28/100], Step [210/313], Loss: 1.6449, Acc: 50.65%\n",
      "Epoch [28/100], Step [220/313], Loss: 1.8331, Acc: 50.62%\n",
      "Epoch [28/100], Step [230/313], Loss: 1.6553, Acc: 50.81%\n",
      "Epoch [28/100], Step [240/313], Loss: 1.5208, Acc: 50.95%\n",
      "Epoch [28/100], Step [250/313], Loss: 1.6043, Acc: 51.01%\n",
      "Epoch [28/100], Step [260/313], Loss: 1.5738, Acc: 51.07%\n",
      "Epoch [28/100], Step [270/313], Loss: 1.6204, Acc: 51.04%\n",
      "Epoch [28/100], Step [280/313], Loss: 1.5244, Acc: 51.15%\n",
      "Epoch [28/100], Step [290/313], Loss: 1.8011, Acc: 51.16%\n",
      "Epoch [28/100], Step [300/313], Loss: 1.8658, Acc: 51.18%\n",
      "Epoch [28/100], Step [310/313], Loss: 1.7738, Acc: 51.20%\n",
      "Epoch [29/100], Step [10/313], Loss: 1.6621, Acc: 51.33%\n",
      "Epoch [29/100], Step [20/313], Loss: 1.9218, Acc: 51.25%\n",
      "Epoch [29/100], Step [30/313], Loss: 1.5937, Acc: 52.29%\n",
      "Epoch [29/100], Step [40/313], Loss: 1.5930, Acc: 52.27%\n",
      "Epoch [29/100], Step [50/313], Loss: 1.9414, Acc: 51.92%\n",
      "Epoch [29/100], Step [60/313], Loss: 1.8043, Acc: 51.88%\n",
      "Epoch [29/100], Step [70/313], Loss: 1.6860, Acc: 51.70%\n",
      "Epoch [29/100], Step [80/313], Loss: 1.8572, Acc: 51.73%\n",
      "Epoch [29/100], Step [90/313], Loss: 1.6573, Acc: 51.93%\n",
      "Epoch [29/100], Step [100/313], Loss: 1.5840, Acc: 52.27%\n",
      "Epoch [29/100], Step [110/313], Loss: 1.7595, Acc: 52.37%\n",
      "Epoch [29/100], Step [120/313], Loss: 1.8099, Acc: 52.25%\n",
      "Epoch [29/100], Step [130/313], Loss: 1.6839, Acc: 52.35%\n",
      "Epoch [29/100], Step [140/313], Loss: 1.6921, Acc: 52.36%\n",
      "Epoch [29/100], Step [150/313], Loss: 1.7705, Acc: 52.10%\n",
      "Epoch [29/100], Step [160/313], Loss: 1.4980, Acc: 52.28%\n",
      "Epoch [29/100], Step [170/313], Loss: 1.5869, Acc: 52.16%\n",
      "Epoch [29/100], Step [180/313], Loss: 1.5667, Acc: 52.12%\n",
      "Epoch [29/100], Step [190/313], Loss: 1.7149, Acc: 52.31%\n",
      "Epoch [29/100], Step [200/313], Loss: 1.7165, Acc: 52.24%\n",
      "Epoch [29/100], Step [210/313], Loss: 1.6689, Acc: 52.15%\n",
      "Epoch [29/100], Step [220/313], Loss: 1.6863, Acc: 52.20%\n",
      "Epoch [29/100], Step [230/313], Loss: 1.6278, Acc: 52.36%\n",
      "Epoch [29/100], Step [240/313], Loss: 1.5418, Acc: 52.42%\n",
      "Epoch [29/100], Step [250/313], Loss: 1.5914, Acc: 52.56%\n",
      "Epoch [29/100], Step [260/313], Loss: 1.4426, Acc: 52.54%\n",
      "Epoch [29/100], Step [270/313], Loss: 1.5481, Acc: 52.57%\n",
      "Epoch [29/100], Step [280/313], Loss: 1.4783, Acc: 52.59%\n",
      "Epoch [29/100], Step [290/313], Loss: 1.7274, Acc: 52.59%\n",
      "Epoch [29/100], Step [300/313], Loss: 1.9240, Acc: 52.62%\n",
      "Epoch [29/100], Step [310/313], Loss: 1.8846, Acc: 52.62%\n",
      "Epoch [30/100], Step [10/313], Loss: 1.4584, Acc: 51.56%\n",
      "Epoch [30/100], Step [20/313], Loss: 1.8016, Acc: 51.02%\n",
      "Epoch [30/100], Step [30/313], Loss: 1.5323, Acc: 52.37%\n",
      "Epoch [30/100], Step [40/313], Loss: 1.5103, Acc: 52.56%\n",
      "Epoch [30/100], Step [50/313], Loss: 1.8061, Acc: 52.70%\n",
      "Epoch [30/100], Step [60/313], Loss: 1.6597, Acc: 52.92%\n",
      "Epoch [30/100], Step [70/313], Loss: 1.6428, Acc: 52.72%\n",
      "Epoch [30/100], Step [80/313], Loss: 1.6983, Acc: 52.98%\n",
      "Epoch [30/100], Step [90/313], Loss: 1.5775, Acc: 53.19%\n",
      "Epoch [30/100], Step [100/313], Loss: 1.4535, Acc: 53.66%\n",
      "Epoch [30/100], Step [110/313], Loss: 1.7319, Acc: 53.70%\n",
      "Epoch [30/100], Step [120/313], Loss: 1.7269, Acc: 53.67%\n",
      "Epoch [30/100], Step [130/313], Loss: 1.6016, Acc: 53.71%\n",
      "Epoch [30/100], Step [140/313], Loss: 1.6283, Acc: 53.82%\n",
      "Epoch [30/100], Step [150/313], Loss: 1.5685, Acc: 53.65%\n",
      "Epoch [30/100], Step [160/313], Loss: 1.4763, Acc: 53.69%\n",
      "Epoch [30/100], Step [170/313], Loss: 1.5109, Acc: 53.58%\n",
      "Epoch [30/100], Step [180/313], Loss: 1.4755, Acc: 53.42%\n",
      "Epoch [30/100], Step [190/313], Loss: 1.6126, Acc: 53.48%\n",
      "Epoch [30/100], Step [200/313], Loss: 1.7469, Acc: 53.35%\n",
      "Epoch [30/100], Step [210/313], Loss: 1.7575, Acc: 53.15%\n",
      "Epoch [30/100], Step [220/313], Loss: 1.7443, Acc: 53.04%\n",
      "Epoch [30/100], Step [230/313], Loss: 1.4141, Acc: 53.21%\n",
      "Epoch [30/100], Step [240/313], Loss: 1.6008, Acc: 53.33%\n",
      "Epoch [30/100], Step [250/313], Loss: 1.6510, Acc: 53.42%\n",
      "Epoch [30/100], Step [260/313], Loss: 1.4510, Acc: 53.41%\n",
      "Epoch [30/100], Step [270/313], Loss: 1.4333, Acc: 53.32%\n",
      "Epoch [30/100], Step [280/313], Loss: 1.3733, Acc: 53.43%\n",
      "Epoch [30/100], Step [290/313], Loss: 1.6921, Acc: 53.42%\n",
      "Epoch [30/100], Step [300/313], Loss: 1.9184, Acc: 53.41%\n",
      "Epoch [30/100], Step [310/313], Loss: 1.7894, Acc: 53.37%\n",
      "Epoch [31/100], Step [10/313], Loss: 1.5353, Acc: 53.12%\n",
      "Epoch [31/100], Step [20/313], Loss: 1.7097, Acc: 53.01%\n",
      "Epoch [31/100], Step [30/313], Loss: 1.5911, Acc: 53.59%\n",
      "Epoch [31/100], Step [40/313], Loss: 1.5255, Acc: 53.48%\n",
      "Epoch [31/100], Step [50/313], Loss: 1.9104, Acc: 53.36%\n",
      "Epoch [31/100], Step [60/313], Loss: 1.7575, Acc: 53.40%\n",
      "Epoch [31/100], Step [70/313], Loss: 1.6885, Acc: 53.60%\n",
      "Epoch [31/100], Step [80/313], Loss: 1.6097, Acc: 53.66%\n",
      "Epoch [31/100], Step [90/313], Loss: 1.4520, Acc: 54.06%\n",
      "Epoch [31/100], Step [100/313], Loss: 1.4666, Acc: 54.43%\n",
      "Epoch [31/100], Step [110/313], Loss: 1.6023, Acc: 54.49%\n",
      "Epoch [31/100], Step [120/313], Loss: 1.6791, Acc: 54.53%\n",
      "Epoch [31/100], Step [130/313], Loss: 1.7028, Acc: 54.63%\n",
      "Epoch [31/100], Step [140/313], Loss: 1.6375, Acc: 54.77%\n",
      "Epoch [31/100], Step [150/313], Loss: 1.6991, Acc: 54.68%\n",
      "Epoch [31/100], Step [160/313], Loss: 1.4212, Acc: 54.82%\n",
      "Epoch [31/100], Step [170/313], Loss: 1.5776, Acc: 54.58%\n",
      "Epoch [31/100], Step [180/313], Loss: 1.4888, Acc: 54.53%\n",
      "Epoch [31/100], Step [190/313], Loss: 1.4113, Acc: 54.73%\n",
      "Epoch [31/100], Step [200/313], Loss: 1.6155, Acc: 54.67%\n",
      "Epoch [31/100], Step [210/313], Loss: 1.7542, Acc: 54.58%\n",
      "Epoch [31/100], Step [220/313], Loss: 1.7871, Acc: 54.49%\n",
      "Epoch [31/100], Step [230/313], Loss: 1.4803, Acc: 54.71%\n",
      "Epoch [31/100], Step [240/313], Loss: 1.5759, Acc: 54.81%\n",
      "Epoch [31/100], Step [250/313], Loss: 1.4269, Acc: 54.94%\n",
      "Epoch [31/100], Step [260/313], Loss: 1.3122, Acc: 54.92%\n",
      "Epoch [31/100], Step [270/313], Loss: 1.4065, Acc: 54.89%\n",
      "Epoch [31/100], Step [280/313], Loss: 1.4494, Acc: 54.92%\n",
      "Epoch [31/100], Step [290/313], Loss: 1.5832, Acc: 54.88%\n",
      "Epoch [31/100], Step [300/313], Loss: 1.8840, Acc: 54.87%\n",
      "Epoch [31/100], Step [310/313], Loss: 1.7830, Acc: 54.88%\n",
      "Epoch [32/100], Step [10/313], Loss: 1.3971, Acc: 53.83%\n",
      "Epoch [32/100], Step [20/313], Loss: 1.5650, Acc: 53.09%\n",
      "Epoch [32/100], Step [30/313], Loss: 1.5132, Acc: 53.46%\n",
      "Epoch [32/100], Step [40/313], Loss: 1.3788, Acc: 53.89%\n",
      "Epoch [32/100], Step [50/313], Loss: 1.8366, Acc: 53.95%\n",
      "Epoch [32/100], Step [60/313], Loss: 1.5733, Acc: 54.04%\n",
      "Epoch [32/100], Step [70/313], Loss: 1.4982, Acc: 54.12%\n",
      "Epoch [32/100], Step [80/313], Loss: 1.5590, Acc: 54.42%\n",
      "Epoch [32/100], Step [90/313], Loss: 1.4158, Acc: 54.90%\n",
      "Epoch [32/100], Step [100/313], Loss: 1.3788, Acc: 55.23%\n",
      "Epoch [32/100], Step [110/313], Loss: 1.6405, Acc: 55.38%\n",
      "Epoch [32/100], Step [120/313], Loss: 1.6311, Acc: 55.39%\n",
      "Epoch [32/100], Step [130/313], Loss: 1.5808, Acc: 55.30%\n",
      "Epoch [32/100], Step [140/313], Loss: 1.4422, Acc: 55.51%\n",
      "Epoch [32/100], Step [150/313], Loss: 1.6400, Acc: 55.41%\n",
      "Epoch [32/100], Step [160/313], Loss: 1.2673, Acc: 55.42%\n",
      "Epoch [32/100], Step [170/313], Loss: 1.4546, Acc: 55.31%\n",
      "Epoch [32/100], Step [180/313], Loss: 1.4013, Acc: 55.21%\n",
      "Epoch [32/100], Step [190/313], Loss: 1.4243, Acc: 55.37%\n",
      "Epoch [32/100], Step [200/313], Loss: 1.6100, Acc: 55.27%\n",
      "Epoch [32/100], Step [210/313], Loss: 1.7233, Acc: 55.24%\n",
      "Epoch [32/100], Step [220/313], Loss: 1.9069, Acc: 55.12%\n",
      "Epoch [32/100], Step [230/313], Loss: 1.3944, Acc: 55.15%\n",
      "Epoch [32/100], Step [240/313], Loss: 1.5922, Acc: 55.35%\n",
      "Epoch [32/100], Step [250/313], Loss: 1.4138, Acc: 55.46%\n",
      "Epoch [32/100], Step [260/313], Loss: 1.3803, Acc: 55.51%\n",
      "Epoch [32/100], Step [270/313], Loss: 1.5139, Acc: 55.45%\n",
      "Epoch [32/100], Step [280/313], Loss: 1.3588, Acc: 55.46%\n",
      "Epoch [32/100], Step [290/313], Loss: 1.5244, Acc: 55.48%\n",
      "Epoch [32/100], Step [300/313], Loss: 1.7585, Acc: 55.47%\n",
      "Epoch [32/100], Step [310/313], Loss: 1.6422, Acc: 55.45%\n",
      "Epoch [33/100], Step [10/313], Loss: 1.5038, Acc: 53.98%\n",
      "Epoch [33/100], Step [20/313], Loss: 1.6988, Acc: 53.32%\n",
      "Epoch [33/100], Step [30/313], Loss: 1.5856, Acc: 54.06%\n",
      "Epoch [33/100], Step [40/313], Loss: 1.4622, Acc: 54.63%\n",
      "Epoch [33/100], Step [50/313], Loss: 1.7031, Acc: 54.53%\n",
      "Epoch [33/100], Step [60/313], Loss: 1.5972, Acc: 54.66%\n",
      "Epoch [33/100], Step [70/313], Loss: 1.4703, Acc: 55.07%\n",
      "Epoch [33/100], Step [80/313], Loss: 1.6080, Acc: 55.45%\n",
      "Epoch [33/100], Step [90/313], Loss: 1.4097, Acc: 55.95%\n",
      "Epoch [33/100], Step [100/313], Loss: 1.4247, Acc: 55.99%\n",
      "Epoch [33/100], Step [110/313], Loss: 1.5951, Acc: 56.05%\n",
      "Epoch [33/100], Step [120/313], Loss: 1.5509, Acc: 56.10%\n",
      "Epoch [33/100], Step [130/313], Loss: 1.5892, Acc: 56.10%\n",
      "Epoch [33/100], Step [140/313], Loss: 1.5727, Acc: 56.33%\n",
      "Epoch [33/100], Step [150/313], Loss: 1.7040, Acc: 56.26%\n",
      "Epoch [33/100], Step [160/313], Loss: 1.2570, Acc: 56.47%\n",
      "Epoch [33/100], Step [170/313], Loss: 1.3705, Acc: 56.44%\n",
      "Epoch [33/100], Step [180/313], Loss: 1.4849, Acc: 56.36%\n",
      "Epoch [33/100], Step [190/313], Loss: 1.3213, Acc: 56.53%\n",
      "Epoch [33/100], Step [200/313], Loss: 1.5117, Acc: 56.38%\n",
      "Epoch [33/100], Step [210/313], Loss: 1.7135, Acc: 56.28%\n",
      "Epoch [33/100], Step [220/313], Loss: 1.8809, Acc: 56.20%\n",
      "Epoch [33/100], Step [230/313], Loss: 1.3636, Acc: 56.26%\n",
      "Epoch [33/100], Step [240/313], Loss: 1.3567, Acc: 56.47%\n",
      "Epoch [33/100], Step [250/313], Loss: 1.4011, Acc: 56.50%\n",
      "Epoch [33/100], Step [260/313], Loss: 1.4510, Acc: 56.46%\n",
      "Epoch [33/100], Step [270/313], Loss: 1.3813, Acc: 56.46%\n",
      "Epoch [33/100], Step [280/313], Loss: 1.4088, Acc: 56.46%\n",
      "Epoch [33/100], Step [290/313], Loss: 1.5900, Acc: 56.47%\n",
      "Epoch [33/100], Step [300/313], Loss: 1.6890, Acc: 56.43%\n",
      "Epoch [33/100], Step [310/313], Loss: 1.6266, Acc: 56.51%\n",
      "Epoch [34/100], Step [10/313], Loss: 1.3737, Acc: 56.56%\n",
      "Epoch [34/100], Step [20/313], Loss: 1.6011, Acc: 55.55%\n",
      "Epoch [34/100], Step [30/313], Loss: 1.4007, Acc: 56.85%\n",
      "Epoch [34/100], Step [40/313], Loss: 1.4426, Acc: 56.74%\n",
      "Epoch [34/100], Step [50/313], Loss: 1.7129, Acc: 56.81%\n",
      "Epoch [34/100], Step [60/313], Loss: 1.6145, Acc: 56.73%\n",
      "Epoch [34/100], Step [70/313], Loss: 1.5070, Acc: 56.61%\n",
      "Epoch [34/100], Step [80/313], Loss: 1.4258, Acc: 56.88%\n",
      "Epoch [34/100], Step [90/313], Loss: 1.3167, Acc: 57.19%\n",
      "Epoch [34/100], Step [100/313], Loss: 1.4016, Acc: 57.34%\n",
      "Epoch [34/100], Step [110/313], Loss: 1.4509, Acc: 57.41%\n",
      "Epoch [34/100], Step [120/313], Loss: 1.5648, Acc: 57.39%\n",
      "Epoch [34/100], Step [130/313], Loss: 1.4731, Acc: 57.33%\n",
      "Epoch [34/100], Step [140/313], Loss: 1.6078, Acc: 57.40%\n",
      "Epoch [34/100], Step [150/313], Loss: 1.6468, Acc: 57.22%\n",
      "Epoch [34/100], Step [160/313], Loss: 1.1426, Acc: 57.33%\n",
      "Epoch [34/100], Step [170/313], Loss: 1.3372, Acc: 57.27%\n",
      "Epoch [34/100], Step [180/313], Loss: 1.4004, Acc: 57.33%\n",
      "Epoch [34/100], Step [190/313], Loss: 1.3871, Acc: 57.47%\n",
      "Epoch [34/100], Step [200/313], Loss: 1.4712, Acc: 57.33%\n",
      "Epoch [34/100], Step [210/313], Loss: 1.6214, Acc: 57.31%\n",
      "Epoch [34/100], Step [220/313], Loss: 1.8144, Acc: 57.11%\n",
      "Epoch [34/100], Step [230/313], Loss: 1.2350, Acc: 57.08%\n",
      "Epoch [34/100], Step [240/313], Loss: 1.2454, Acc: 57.20%\n",
      "Epoch [34/100], Step [250/313], Loss: 1.3424, Acc: 57.33%\n",
      "Epoch [34/100], Step [260/313], Loss: 1.3393, Acc: 57.32%\n",
      "Epoch [34/100], Step [270/313], Loss: 1.3913, Acc: 57.34%\n",
      "Epoch [34/100], Step [280/313], Loss: 1.3770, Acc: 57.37%\n",
      "Epoch [34/100], Step [290/313], Loss: 1.6234, Acc: 57.36%\n",
      "Epoch [34/100], Step [300/313], Loss: 1.6479, Acc: 57.31%\n",
      "Epoch [34/100], Step [310/313], Loss: 1.5998, Acc: 57.23%\n",
      "Epoch [35/100], Step [10/313], Loss: 1.3999, Acc: 56.64%\n",
      "Epoch [35/100], Step [20/313], Loss: 1.5319, Acc: 56.80%\n",
      "Epoch [35/100], Step [30/313], Loss: 1.3953, Acc: 56.77%\n",
      "Epoch [35/100], Step [40/313], Loss: 1.5230, Acc: 56.89%\n",
      "Epoch [35/100], Step [50/313], Loss: 1.7017, Acc: 56.59%\n",
      "Epoch [35/100], Step [60/313], Loss: 1.5931, Acc: 56.54%\n",
      "Epoch [35/100], Step [70/313], Loss: 1.4520, Acc: 56.50%\n",
      "Epoch [35/100], Step [80/313], Loss: 1.4435, Acc: 56.52%\n",
      "Epoch [35/100], Step [90/313], Loss: 1.4219, Acc: 57.01%\n",
      "Epoch [35/100], Step [100/313], Loss: 1.3632, Acc: 57.17%\n",
      "Epoch [35/100], Step [110/313], Loss: 1.5698, Acc: 57.20%\n",
      "Epoch [35/100], Step [120/313], Loss: 1.6759, Acc: 57.23%\n",
      "Epoch [35/100], Step [130/313], Loss: 1.3950, Acc: 57.37%\n",
      "Epoch [35/100], Step [140/313], Loss: 1.3121, Acc: 57.54%\n",
      "Epoch [35/100], Step [150/313], Loss: 1.6150, Acc: 57.42%\n",
      "Epoch [35/100], Step [160/313], Loss: 1.1305, Acc: 57.64%\n",
      "Epoch [35/100], Step [170/313], Loss: 1.4119, Acc: 57.53%\n",
      "Epoch [35/100], Step [180/313], Loss: 1.3290, Acc: 57.50%\n",
      "Epoch [35/100], Step [190/313], Loss: 1.3721, Acc: 57.73%\n",
      "Epoch [35/100], Step [200/313], Loss: 1.5018, Acc: 57.70%\n",
      "Epoch [35/100], Step [210/313], Loss: 1.6236, Acc: 57.70%\n",
      "Epoch [35/100], Step [220/313], Loss: 1.7006, Acc: 57.56%\n",
      "Epoch [35/100], Step [230/313], Loss: 1.3138, Acc: 57.43%\n",
      "Epoch [35/100], Step [240/313], Loss: 1.4557, Acc: 57.48%\n",
      "Epoch [35/100], Step [250/313], Loss: 1.2923, Acc: 57.51%\n",
      "Epoch [35/100], Step [260/313], Loss: 1.2863, Acc: 57.51%\n",
      "Epoch [35/100], Step [270/313], Loss: 1.4087, Acc: 57.48%\n",
      "Epoch [35/100], Step [280/313], Loss: 1.2674, Acc: 57.44%\n",
      "Epoch [35/100], Step [290/313], Loss: 1.4228, Acc: 57.52%\n",
      "Epoch [35/100], Step [300/313], Loss: 1.7240, Acc: 57.48%\n",
      "Epoch [35/100], Step [310/313], Loss: 1.4310, Acc: 57.53%\n",
      "Epoch [36/100], Step [10/313], Loss: 1.3291, Acc: 57.19%\n",
      "Epoch [36/100], Step [20/313], Loss: 1.5721, Acc: 57.42%\n",
      "Epoch [36/100], Step [30/313], Loss: 1.2781, Acc: 57.94%\n",
      "Epoch [36/100], Step [40/313], Loss: 1.4121, Acc: 57.83%\n",
      "Epoch [36/100], Step [50/313], Loss: 1.5446, Acc: 57.95%\n",
      "Epoch [36/100], Step [60/313], Loss: 1.5141, Acc: 58.01%\n",
      "Epoch [36/100], Step [70/313], Loss: 1.4482, Acc: 57.98%\n",
      "Epoch [36/100], Step [80/313], Loss: 1.4090, Acc: 58.38%\n",
      "Epoch [36/100], Step [90/313], Loss: 1.3350, Acc: 58.55%\n",
      "Epoch [36/100], Step [100/313], Loss: 1.2856, Acc: 58.73%\n",
      "Epoch [36/100], Step [110/313], Loss: 1.5151, Acc: 58.84%\n",
      "Epoch [36/100], Step [120/313], Loss: 1.3960, Acc: 59.04%\n",
      "Epoch [36/100], Step [130/313], Loss: 1.4557, Acc: 59.04%\n",
      "Epoch [36/100], Step [140/313], Loss: 1.1716, Acc: 59.27%\n",
      "Epoch [36/100], Step [150/313], Loss: 1.5202, Acc: 59.09%\n",
      "Epoch [36/100], Step [160/313], Loss: 1.2299, Acc: 59.23%\n",
      "Epoch [36/100], Step [170/313], Loss: 1.3044, Acc: 59.10%\n",
      "Epoch [36/100], Step [180/313], Loss: 1.4229, Acc: 59.17%\n",
      "Epoch [36/100], Step [190/313], Loss: 1.2526, Acc: 59.33%\n",
      "Epoch [36/100], Step [200/313], Loss: 1.4580, Acc: 59.27%\n",
      "Epoch [36/100], Step [210/313], Loss: 1.2993, Acc: 59.32%\n",
      "Epoch [36/100], Step [220/313], Loss: 1.4789, Acc: 59.27%\n",
      "Epoch [36/100], Step [230/313], Loss: 1.2861, Acc: 59.27%\n",
      "Epoch [36/100], Step [240/313], Loss: 1.3991, Acc: 59.26%\n",
      "Epoch [36/100], Step [250/313], Loss: 1.2708, Acc: 59.26%\n",
      "Epoch [36/100], Step [260/313], Loss: 1.2124, Acc: 59.27%\n",
      "Epoch [36/100], Step [270/313], Loss: 1.3115, Acc: 59.32%\n",
      "Epoch [36/100], Step [280/313], Loss: 1.1980, Acc: 59.35%\n",
      "Epoch [36/100], Step [290/313], Loss: 1.3665, Acc: 59.38%\n",
      "Epoch [36/100], Step [300/313], Loss: 1.5358, Acc: 59.36%\n",
      "Epoch [36/100], Step [310/313], Loss: 1.4517, Acc: 59.39%\n",
      "Epoch [37/100], Step [10/313], Loss: 1.2649, Acc: 59.06%\n",
      "Epoch [37/100], Step [20/313], Loss: 1.4706, Acc: 58.55%\n",
      "Epoch [37/100], Step [30/313], Loss: 1.2520, Acc: 59.35%\n",
      "Epoch [37/100], Step [40/313], Loss: 1.3286, Acc: 59.43%\n",
      "Epoch [37/100], Step [50/313], Loss: 1.5280, Acc: 59.53%\n",
      "Epoch [37/100], Step [60/313], Loss: 1.4769, Acc: 59.60%\n",
      "Epoch [37/100], Step [70/313], Loss: 1.3884, Acc: 59.84%\n",
      "Epoch [37/100], Step [80/313], Loss: 1.3786, Acc: 60.14%\n",
      "Epoch [37/100], Step [90/313], Loss: 1.3046, Acc: 60.41%\n",
      "Epoch [37/100], Step [100/313], Loss: 1.3226, Acc: 60.68%\n",
      "Epoch [37/100], Step [110/313], Loss: 1.4630, Acc: 60.60%\n",
      "Epoch [37/100], Step [120/313], Loss: 1.4964, Acc: 60.62%\n",
      "Epoch [37/100], Step [130/313], Loss: 1.2702, Acc: 60.60%\n",
      "Epoch [37/100], Step [140/313], Loss: 1.2427, Acc: 60.81%\n",
      "Epoch [37/100], Step [150/313], Loss: 1.5193, Acc: 60.65%\n",
      "Epoch [37/100], Step [160/313], Loss: 1.1603, Acc: 60.69%\n",
      "Epoch [37/100], Step [170/313], Loss: 1.2778, Acc: 60.54%\n",
      "Epoch [37/100], Step [180/313], Loss: 1.3255, Acc: 60.49%\n",
      "Epoch [37/100], Step [190/313], Loss: 1.2164, Acc: 60.60%\n",
      "Epoch [37/100], Step [200/313], Loss: 1.3838, Acc: 60.63%\n",
      "Epoch [37/100], Step [210/313], Loss: 1.5100, Acc: 60.65%\n",
      "Epoch [37/100], Step [220/313], Loss: 1.4948, Acc: 60.58%\n",
      "Epoch [37/100], Step [230/313], Loss: 1.2673, Acc: 60.54%\n",
      "Epoch [37/100], Step [240/313], Loss: 1.3794, Acc: 60.53%\n",
      "Epoch [37/100], Step [250/313], Loss: 1.2147, Acc: 60.61%\n",
      "Epoch [37/100], Step [260/313], Loss: 1.2712, Acc: 60.60%\n",
      "Epoch [37/100], Step [270/313], Loss: 1.2769, Acc: 60.56%\n",
      "Epoch [37/100], Step [280/313], Loss: 1.1435, Acc: 60.63%\n",
      "Epoch [37/100], Step [290/313], Loss: 1.4934, Acc: 60.58%\n",
      "Epoch [37/100], Step [300/313], Loss: 1.5735, Acc: 60.56%\n",
      "Epoch [37/100], Step [310/313], Loss: 1.3961, Acc: 60.57%\n",
      "Epoch [38/100], Step [10/313], Loss: 1.2996, Acc: 57.58%\n",
      "Epoch [38/100], Step [20/313], Loss: 1.6316, Acc: 58.20%\n",
      "Epoch [38/100], Step [30/313], Loss: 1.3073, Acc: 58.52%\n",
      "Epoch [38/100], Step [40/313], Loss: 1.2869, Acc: 58.67%\n",
      "Epoch [38/100], Step [50/313], Loss: 1.6402, Acc: 58.66%\n",
      "Epoch [38/100], Step [60/313], Loss: 1.4927, Acc: 58.98%\n",
      "Epoch [38/100], Step [70/313], Loss: 1.4103, Acc: 59.06%\n",
      "Epoch [38/100], Step [80/313], Loss: 1.3094, Acc: 59.38%\n",
      "Epoch [38/100], Step [90/313], Loss: 1.2843, Acc: 59.80%\n",
      "Epoch [38/100], Step [100/313], Loss: 1.1969, Acc: 60.10%\n",
      "Epoch [38/100], Step [110/313], Loss: 1.3310, Acc: 60.33%\n",
      "Epoch [38/100], Step [120/313], Loss: 1.3453, Acc: 60.45%\n",
      "Epoch [38/100], Step [130/313], Loss: 1.2546, Acc: 60.38%\n",
      "Epoch [38/100], Step [140/313], Loss: 1.1777, Acc: 60.55%\n",
      "Epoch [38/100], Step [150/313], Loss: 1.6023, Acc: 60.48%\n",
      "Epoch [38/100], Step [160/313], Loss: 1.1959, Acc: 60.52%\n",
      "Epoch [38/100], Step [170/313], Loss: 1.3396, Acc: 60.45%\n",
      "Epoch [38/100], Step [180/313], Loss: 1.2222, Acc: 60.43%\n",
      "Epoch [38/100], Step [190/313], Loss: 1.2708, Acc: 60.65%\n",
      "Epoch [38/100], Step [200/313], Loss: 1.5295, Acc: 60.63%\n",
      "Epoch [38/100], Step [210/313], Loss: 1.3843, Acc: 60.62%\n",
      "Epoch [38/100], Step [220/313], Loss: 1.5854, Acc: 60.51%\n",
      "Epoch [38/100], Step [230/313], Loss: 1.3883, Acc: 60.48%\n",
      "Epoch [38/100], Step [240/313], Loss: 1.2281, Acc: 60.53%\n",
      "Epoch [38/100], Step [250/313], Loss: 1.1785, Acc: 60.56%\n",
      "Epoch [38/100], Step [260/313], Loss: 1.1086, Acc: 60.54%\n",
      "Epoch [38/100], Step [270/313], Loss: 1.3545, Acc: 60.56%\n",
      "Epoch [38/100], Step [280/313], Loss: 1.3109, Acc: 60.56%\n",
      "Epoch [38/100], Step [290/313], Loss: 1.3748, Acc: 60.52%\n",
      "Epoch [38/100], Step [300/313], Loss: 1.4789, Acc: 60.51%\n",
      "Epoch [38/100], Step [310/313], Loss: 1.5332, Acc: 60.50%\n",
      "Epoch [39/100], Step [10/313], Loss: 1.3938, Acc: 60.23%\n",
      "Epoch [39/100], Step [20/313], Loss: 1.6132, Acc: 58.71%\n",
      "Epoch [39/100], Step [30/313], Loss: 1.2192, Acc: 59.71%\n",
      "Epoch [39/100], Step [40/313], Loss: 1.2955, Acc: 59.59%\n",
      "Epoch [39/100], Step [50/313], Loss: 1.4939, Acc: 59.72%\n",
      "Epoch [39/100], Step [60/313], Loss: 1.4394, Acc: 59.73%\n",
      "Epoch [39/100], Step [70/313], Loss: 1.2691, Acc: 59.63%\n",
      "Epoch [39/100], Step [80/313], Loss: 1.3780, Acc: 59.97%\n",
      "Epoch [39/100], Step [90/313], Loss: 1.2982, Acc: 60.20%\n",
      "Epoch [39/100], Step [100/313], Loss: 1.3674, Acc: 60.42%\n",
      "Epoch [39/100], Step [110/313], Loss: 1.4353, Acc: 60.43%\n",
      "Epoch [39/100], Step [120/313], Loss: 1.3956, Acc: 60.48%\n",
      "Epoch [39/100], Step [130/313], Loss: 1.2142, Acc: 60.67%\n",
      "Epoch [39/100], Step [140/313], Loss: 1.2240, Acc: 60.76%\n",
      "Epoch [39/100], Step [150/313], Loss: 1.4658, Acc: 60.60%\n",
      "Epoch [39/100], Step [160/313], Loss: 1.1288, Acc: 60.72%\n",
      "Epoch [39/100], Step [170/313], Loss: 1.2986, Acc: 60.62%\n",
      "Epoch [39/100], Step [180/313], Loss: 1.2264, Acc: 60.61%\n",
      "Epoch [39/100], Step [190/313], Loss: 1.3119, Acc: 60.80%\n",
      "Epoch [39/100], Step [200/313], Loss: 1.2897, Acc: 60.91%\n",
      "Epoch [39/100], Step [210/313], Loss: 1.2357, Acc: 61.05%\n",
      "Epoch [39/100], Step [220/313], Loss: 1.4285, Acc: 61.06%\n",
      "Epoch [39/100], Step [230/313], Loss: 1.2057, Acc: 61.08%\n",
      "Epoch [39/100], Step [240/313], Loss: 1.2375, Acc: 61.05%\n",
      "Epoch [39/100], Step [250/313], Loss: 1.1751, Acc: 61.15%\n",
      "Epoch [39/100], Step [260/313], Loss: 1.1379, Acc: 61.13%\n",
      "Epoch [39/100], Step [270/313], Loss: 1.0779, Acc: 61.20%\n",
      "Epoch [39/100], Step [280/313], Loss: 1.0904, Acc: 61.22%\n",
      "Epoch [39/100], Step [290/313], Loss: 1.4124, Acc: 61.24%\n",
      "Epoch [39/100], Step [300/313], Loss: 1.5121, Acc: 61.18%\n",
      "Epoch [39/100], Step [310/313], Loss: 1.4356, Acc: 61.23%\n",
      "Epoch [40/100], Step [10/313], Loss: 1.2460, Acc: 61.02%\n",
      "Epoch [40/100], Step [20/313], Loss: 1.4530, Acc: 60.55%\n",
      "Epoch [40/100], Step [30/313], Loss: 1.2145, Acc: 60.73%\n",
      "Epoch [40/100], Step [40/313], Loss: 1.2196, Acc: 60.84%\n",
      "Epoch [40/100], Step [50/313], Loss: 1.5141, Acc: 61.17%\n",
      "Epoch [40/100], Step [60/313], Loss: 1.3573, Acc: 61.16%\n",
      "Epoch [40/100], Step [70/313], Loss: 1.3353, Acc: 61.18%\n",
      "Epoch [40/100], Step [80/313], Loss: 1.3285, Acc: 61.50%\n",
      "Epoch [40/100], Step [90/313], Loss: 1.3199, Acc: 61.90%\n",
      "Epoch [40/100], Step [100/313], Loss: 1.1208, Acc: 62.14%\n",
      "Epoch [40/100], Step [110/313], Loss: 1.3138, Acc: 62.14%\n",
      "Epoch [40/100], Step [120/313], Loss: 1.3521, Acc: 62.04%\n",
      "Epoch [40/100], Step [130/313], Loss: 1.1402, Acc: 62.03%\n",
      "Epoch [40/100], Step [140/313], Loss: 1.2391, Acc: 62.06%\n",
      "Epoch [40/100], Step [150/313], Loss: 1.6050, Acc: 61.96%\n",
      "Epoch [40/100], Step [160/313], Loss: 1.0534, Acc: 62.10%\n",
      "Epoch [40/100], Step [170/313], Loss: 1.3096, Acc: 61.98%\n",
      "Epoch [40/100], Step [180/313], Loss: 1.3625, Acc: 61.95%\n",
      "Epoch [40/100], Step [190/313], Loss: 1.3702, Acc: 62.05%\n",
      "Epoch [40/100], Step [200/313], Loss: 1.2946, Acc: 62.12%\n",
      "Epoch [40/100], Step [210/313], Loss: 1.2956, Acc: 62.24%\n",
      "Epoch [40/100], Step [220/313], Loss: 1.3092, Acc: 62.32%\n",
      "Epoch [40/100], Step [230/313], Loss: 1.1397, Acc: 62.37%\n",
      "Epoch [40/100], Step [240/313], Loss: 1.3269, Acc: 62.37%\n",
      "Epoch [40/100], Step [250/313], Loss: 1.1189, Acc: 62.43%\n",
      "Epoch [40/100], Step [260/313], Loss: 1.0558, Acc: 62.44%\n",
      "Epoch [40/100], Step [270/313], Loss: 1.1206, Acc: 62.47%\n",
      "Epoch [40/100], Step [280/313], Loss: 1.1590, Acc: 62.52%\n",
      "Epoch [40/100], Step [290/313], Loss: 1.2691, Acc: 62.48%\n",
      "Epoch [40/100], Step [300/313], Loss: 1.5082, Acc: 62.41%\n",
      "Epoch [40/100], Step [310/313], Loss: 1.4092, Acc: 62.37%\n",
      "Epoch [41/100], Step [10/313], Loss: 1.1918, Acc: 62.50%\n",
      "Epoch [41/100], Step [20/313], Loss: 1.5837, Acc: 61.88%\n",
      "Epoch [41/100], Step [30/313], Loss: 1.2060, Acc: 63.33%\n",
      "Epoch [41/100], Step [40/313], Loss: 1.0543, Acc: 63.44%\n",
      "Epoch [41/100], Step [50/313], Loss: 1.4490, Acc: 63.70%\n",
      "Epoch [41/100], Step [60/313], Loss: 1.2740, Acc: 63.68%\n",
      "Epoch [41/100], Step [70/313], Loss: 1.2081, Acc: 63.55%\n",
      "Epoch [41/100], Step [80/313], Loss: 1.3279, Acc: 63.71%\n",
      "Epoch [41/100], Step [90/313], Loss: 1.1656, Acc: 63.79%\n",
      "Epoch [41/100], Step [100/313], Loss: 1.1397, Acc: 63.84%\n",
      "Epoch [41/100], Step [110/313], Loss: 1.2777, Acc: 63.77%\n",
      "Epoch [41/100], Step [120/313], Loss: 1.2483, Acc: 63.87%\n",
      "Epoch [41/100], Step [130/313], Loss: 1.2363, Acc: 63.87%\n",
      "Epoch [41/100], Step [140/313], Loss: 1.3713, Acc: 63.94%\n",
      "Epoch [41/100], Step [150/313], Loss: 1.4298, Acc: 63.92%\n",
      "Epoch [41/100], Step [160/313], Loss: 1.0808, Acc: 63.94%\n",
      "Epoch [41/100], Step [170/313], Loss: 1.1981, Acc: 63.77%\n",
      "Epoch [41/100], Step [180/313], Loss: 1.1347, Acc: 63.61%\n",
      "Epoch [41/100], Step [190/313], Loss: 1.2705, Acc: 63.66%\n",
      "Epoch [41/100], Step [200/313], Loss: 1.1520, Acc: 63.57%\n",
      "Epoch [41/100], Step [210/313], Loss: 1.2047, Acc: 63.65%\n",
      "Epoch [41/100], Step [220/313], Loss: 1.3668, Acc: 63.63%\n",
      "Epoch [41/100], Step [230/313], Loss: 1.0390, Acc: 63.73%\n",
      "Epoch [41/100], Step [240/313], Loss: 1.2053, Acc: 63.72%\n",
      "Epoch [41/100], Step [250/313], Loss: 1.1581, Acc: 63.79%\n",
      "Epoch [41/100], Step [260/313], Loss: 1.0053, Acc: 63.80%\n",
      "Epoch [41/100], Step [270/313], Loss: 1.0765, Acc: 63.86%\n",
      "Epoch [41/100], Step [280/313], Loss: 1.0207, Acc: 63.88%\n",
      "Epoch [41/100], Step [290/313], Loss: 1.2266, Acc: 63.85%\n",
      "Epoch [41/100], Step [300/313], Loss: 1.3366, Acc: 63.87%\n",
      "Epoch [41/100], Step [310/313], Loss: 1.3644, Acc: 63.83%\n",
      "Epoch [42/100], Step [10/313], Loss: 0.9593, Acc: 66.02%\n",
      "Epoch [42/100], Step [20/313], Loss: 1.3965, Acc: 65.86%\n",
      "Epoch [42/100], Step [30/313], Loss: 0.9767, Acc: 65.70%\n",
      "Epoch [42/100], Step [40/313], Loss: 1.1430, Acc: 65.55%\n",
      "Epoch [42/100], Step [50/313], Loss: 1.3615, Acc: 65.25%\n",
      "Epoch [42/100], Step [60/313], Loss: 1.3781, Acc: 64.87%\n",
      "Epoch [42/100], Step [70/313], Loss: 1.1546, Acc: 64.42%\n",
      "Epoch [42/100], Step [80/313], Loss: 1.3090, Acc: 64.56%\n",
      "Epoch [42/100], Step [90/313], Loss: 1.2050, Acc: 64.49%\n",
      "Epoch [42/100], Step [100/313], Loss: 1.0888, Acc: 64.52%\n",
      "Epoch [42/100], Step [110/313], Loss: 1.3031, Acc: 64.62%\n",
      "Epoch [42/100], Step [120/313], Loss: 1.3313, Acc: 64.57%\n",
      "Epoch [42/100], Step [130/313], Loss: 1.1421, Acc: 64.39%\n",
      "Epoch [42/100], Step [140/313], Loss: 1.0910, Acc: 64.36%\n",
      "Epoch [42/100], Step [150/313], Loss: 1.4278, Acc: 64.20%\n",
      "Epoch [42/100], Step [160/313], Loss: 1.2407, Acc: 64.11%\n",
      "Epoch [42/100], Step [170/313], Loss: 1.1928, Acc: 63.98%\n",
      "Epoch [42/100], Step [180/313], Loss: 1.1044, Acc: 63.95%\n",
      "Epoch [42/100], Step [190/313], Loss: 1.2544, Acc: 63.96%\n",
      "Epoch [42/100], Step [200/313], Loss: 1.2155, Acc: 63.96%\n",
      "Epoch [42/100], Step [210/313], Loss: 1.1190, Acc: 64.03%\n",
      "Epoch [42/100], Step [220/313], Loss: 1.3934, Acc: 64.03%\n",
      "Epoch [42/100], Step [230/313], Loss: 1.1159, Acc: 64.06%\n",
      "Epoch [42/100], Step [240/313], Loss: 1.2217, Acc: 64.11%\n",
      "Epoch [42/100], Step [250/313], Loss: 1.0007, Acc: 64.12%\n",
      "Epoch [42/100], Step [260/313], Loss: 1.0511, Acc: 64.14%\n",
      "Epoch [42/100], Step [270/313], Loss: 1.1258, Acc: 64.19%\n",
      "Epoch [42/100], Step [280/313], Loss: 1.0564, Acc: 64.24%\n",
      "Epoch [42/100], Step [290/313], Loss: 1.1478, Acc: 64.19%\n",
      "Epoch [42/100], Step [300/313], Loss: 1.3668, Acc: 64.15%\n",
      "Epoch [42/100], Step [310/313], Loss: 1.3042, Acc: 64.22%\n",
      "Epoch [43/100], Step [10/313], Loss: 0.9124, Acc: 63.75%\n",
      "Epoch [43/100], Step [20/313], Loss: 1.3556, Acc: 63.63%\n",
      "Epoch [43/100], Step [30/313], Loss: 1.0987, Acc: 64.77%\n",
      "Epoch [43/100], Step [40/313], Loss: 1.0842, Acc: 64.47%\n",
      "Epoch [43/100], Step [50/313], Loss: 1.4900, Acc: 64.19%\n",
      "Epoch [43/100], Step [60/313], Loss: 1.2435, Acc: 64.00%\n",
      "Epoch [43/100], Step [70/313], Loss: 1.1617, Acc: 64.01%\n",
      "Epoch [43/100], Step [80/313], Loss: 1.2755, Acc: 64.18%\n",
      "Epoch [43/100], Step [90/313], Loss: 1.1009, Acc: 64.46%\n",
      "Epoch [43/100], Step [100/313], Loss: 1.1718, Acc: 64.71%\n",
      "Epoch [43/100], Step [110/313], Loss: 1.2123, Acc: 64.68%\n",
      "Epoch [43/100], Step [120/313], Loss: 1.4352, Acc: 64.62%\n",
      "Epoch [43/100], Step [130/313], Loss: 0.9933, Acc: 64.62%\n",
      "Epoch [43/100], Step [140/313], Loss: 1.2513, Acc: 64.71%\n",
      "Epoch [43/100], Step [150/313], Loss: 1.2949, Acc: 64.57%\n",
      "Epoch [43/100], Step [160/313], Loss: 0.9464, Acc: 64.59%\n",
      "Epoch [43/100], Step [170/313], Loss: 1.1547, Acc: 64.55%\n",
      "Epoch [43/100], Step [180/313], Loss: 1.0474, Acc: 64.53%\n",
      "Epoch [43/100], Step [190/313], Loss: 1.2723, Acc: 64.62%\n",
      "Epoch [43/100], Step [200/313], Loss: 1.2065, Acc: 64.52%\n",
      "Epoch [43/100], Step [210/313], Loss: 1.1151, Acc: 64.51%\n",
      "Epoch [43/100], Step [220/313], Loss: 1.3084, Acc: 64.47%\n",
      "Epoch [43/100], Step [230/313], Loss: 1.3065, Acc: 64.52%\n",
      "Epoch [43/100], Step [240/313], Loss: 1.1155, Acc: 64.52%\n",
      "Epoch [43/100], Step [250/313], Loss: 1.1339, Acc: 64.51%\n",
      "Epoch [43/100], Step [260/313], Loss: 1.0331, Acc: 64.52%\n",
      "Epoch [43/100], Step [270/313], Loss: 1.1746, Acc: 64.49%\n",
      "Epoch [43/100], Step [280/313], Loss: 0.9954, Acc: 64.55%\n",
      "Epoch [43/100], Step [290/313], Loss: 1.1459, Acc: 64.45%\n",
      "Epoch [43/100], Step [300/313], Loss: 1.3384, Acc: 64.40%\n",
      "Epoch [43/100], Step [310/313], Loss: 1.1885, Acc: 64.41%\n",
      "Epoch [44/100], Step [10/313], Loss: 0.9908, Acc: 65.62%\n",
      "Epoch [44/100], Step [20/313], Loss: 1.3094, Acc: 65.31%\n",
      "Epoch [44/100], Step [30/313], Loss: 0.9684, Acc: 65.78%\n",
      "Epoch [44/100], Step [40/313], Loss: 1.0275, Acc: 65.23%\n",
      "Epoch [44/100], Step [50/313], Loss: 1.4715, Acc: 65.08%\n",
      "Epoch [44/100], Step [60/313], Loss: 1.2595, Acc: 64.90%\n",
      "Epoch [44/100], Step [70/313], Loss: 1.2007, Acc: 64.35%\n",
      "Epoch [44/100], Step [80/313], Loss: 1.4545, Acc: 64.21%\n",
      "Epoch [44/100], Step [90/313], Loss: 1.1432, Acc: 64.36%\n",
      "Epoch [44/100], Step [100/313], Loss: 1.0263, Acc: 64.49%\n",
      "Epoch [44/100], Step [110/313], Loss: 1.2410, Acc: 64.66%\n",
      "Epoch [44/100], Step [120/313], Loss: 1.2471, Acc: 64.76%\n",
      "Epoch [44/100], Step [130/313], Loss: 1.1486, Acc: 64.51%\n",
      "Epoch [44/100], Step [140/313], Loss: 1.1726, Acc: 64.63%\n",
      "Epoch [44/100], Step [150/313], Loss: 1.2744, Acc: 64.52%\n",
      "Epoch [44/100], Step [160/313], Loss: 1.0993, Acc: 64.52%\n",
      "Epoch [44/100], Step [170/313], Loss: 1.1998, Acc: 64.43%\n",
      "Epoch [44/100], Step [180/313], Loss: 1.1097, Acc: 64.39%\n",
      "Epoch [44/100], Step [190/313], Loss: 1.1619, Acc: 64.54%\n",
      "Epoch [44/100], Step [200/313], Loss: 1.2431, Acc: 64.41%\n",
      "Epoch [44/100], Step [210/313], Loss: 1.0788, Acc: 64.49%\n",
      "Epoch [44/100], Step [220/313], Loss: 1.4135, Acc: 64.54%\n",
      "Epoch [44/100], Step [230/313], Loss: 0.9361, Acc: 64.67%\n",
      "Epoch [44/100], Step [240/313], Loss: 1.1686, Acc: 64.70%\n",
      "Epoch [44/100], Step [250/313], Loss: 1.1419, Acc: 64.70%\n",
      "Epoch [44/100], Step [260/313], Loss: 1.0623, Acc: 64.63%\n",
      "Epoch [44/100], Step [270/313], Loss: 1.0688, Acc: 64.68%\n",
      "Epoch [44/100], Step [280/313], Loss: 1.0817, Acc: 64.74%\n",
      "Epoch [44/100], Step [290/313], Loss: 1.1156, Acc: 64.71%\n",
      "Epoch [44/100], Step [300/313], Loss: 1.3833, Acc: 64.69%\n",
      "Epoch [44/100], Step [310/313], Loss: 1.3048, Acc: 64.73%\n",
      "Epoch [45/100], Step [10/313], Loss: 0.9117, Acc: 66.17%\n",
      "Epoch [45/100], Step [20/313], Loss: 1.3685, Acc: 66.45%\n",
      "Epoch [45/100], Step [30/313], Loss: 1.0416, Acc: 66.15%\n",
      "Epoch [45/100], Step [40/313], Loss: 1.1231, Acc: 65.78%\n",
      "Epoch [45/100], Step [50/313], Loss: 1.3988, Acc: 65.70%\n",
      "Epoch [45/100], Step [60/313], Loss: 1.1930, Acc: 65.70%\n",
      "Epoch [45/100], Step [70/313], Loss: 0.9917, Acc: 65.48%\n",
      "Epoch [45/100], Step [80/313], Loss: 1.3724, Acc: 65.37%\n",
      "Epoch [45/100], Step [90/313], Loss: 1.0621, Acc: 65.61%\n",
      "Epoch [45/100], Step [100/313], Loss: 1.0329, Acc: 65.70%\n",
      "Epoch [45/100], Step [110/313], Loss: 1.2329, Acc: 65.59%\n",
      "Epoch [45/100], Step [120/313], Loss: 1.2098, Acc: 65.61%\n",
      "Epoch [45/100], Step [130/313], Loss: 1.2494, Acc: 65.38%\n",
      "Epoch [45/100], Step [140/313], Loss: 1.1220, Acc: 65.45%\n",
      "Epoch [45/100], Step [150/313], Loss: 1.2520, Acc: 65.49%\n",
      "Epoch [45/100], Step [160/313], Loss: 1.0236, Acc: 65.58%\n",
      "Epoch [45/100], Step [170/313], Loss: 1.1402, Acc: 65.44%\n",
      "Epoch [45/100], Step [180/313], Loss: 1.0548, Acc: 65.34%\n",
      "Epoch [45/100], Step [190/313], Loss: 1.1730, Acc: 65.50%\n",
      "Epoch [45/100], Step [200/313], Loss: 1.0352, Acc: 65.38%\n",
      "Epoch [45/100], Step [210/313], Loss: 1.0761, Acc: 65.35%\n",
      "Epoch [45/100], Step [220/313], Loss: 1.2273, Acc: 65.35%\n",
      "Epoch [45/100], Step [230/313], Loss: 1.2487, Acc: 65.39%\n",
      "Epoch [45/100], Step [240/313], Loss: 1.2043, Acc: 65.45%\n",
      "Epoch [45/100], Step [250/313], Loss: 0.9873, Acc: 65.49%\n",
      "Epoch [45/100], Step [260/313], Loss: 0.9856, Acc: 65.49%\n",
      "Epoch [45/100], Step [270/313], Loss: 1.0137, Acc: 65.56%\n",
      "Epoch [45/100], Step [280/313], Loss: 1.0477, Acc: 65.62%\n",
      "Epoch [45/100], Step [290/313], Loss: 1.1868, Acc: 65.52%\n",
      "Epoch [45/100], Step [300/313], Loss: 1.4088, Acc: 65.51%\n",
      "Epoch [45/100], Step [310/313], Loss: 1.1633, Acc: 65.58%\n",
      "Epoch [46/100], Step [10/313], Loss: 1.0037, Acc: 68.05%\n",
      "Epoch [46/100], Step [20/313], Loss: 1.2513, Acc: 66.91%\n",
      "Epoch [46/100], Step [30/313], Loss: 0.8910, Acc: 67.55%\n",
      "Epoch [46/100], Step [40/313], Loss: 0.9361, Acc: 67.58%\n",
      "Epoch [46/100], Step [50/313], Loss: 1.3603, Acc: 67.36%\n",
      "Epoch [46/100], Step [60/313], Loss: 1.1302, Acc: 67.38%\n",
      "Epoch [46/100], Step [70/313], Loss: 1.0460, Acc: 66.79%\n",
      "Epoch [46/100], Step [80/313], Loss: 1.3514, Acc: 66.85%\n",
      "Epoch [46/100], Step [90/313], Loss: 1.1182, Acc: 66.96%\n",
      "Epoch [46/100], Step [100/313], Loss: 0.9622, Acc: 67.07%\n",
      "Epoch [46/100], Step [110/313], Loss: 1.2718, Acc: 67.14%\n",
      "Epoch [46/100], Step [120/313], Loss: 1.2889, Acc: 66.89%\n",
      "Epoch [46/100], Step [130/313], Loss: 1.1394, Acc: 66.73%\n",
      "Epoch [46/100], Step [140/313], Loss: 1.1560, Acc: 66.81%\n",
      "Epoch [46/100], Step [150/313], Loss: 1.3966, Acc: 66.58%\n",
      "Epoch [46/100], Step [160/313], Loss: 1.0111, Acc: 66.62%\n",
      "Epoch [46/100], Step [170/313], Loss: 1.0410, Acc: 66.61%\n",
      "Epoch [46/100], Step [180/313], Loss: 0.9109, Acc: 66.51%\n",
      "Epoch [46/100], Step [190/313], Loss: 1.1790, Acc: 66.66%\n",
      "Epoch [46/100], Step [200/313], Loss: 1.0669, Acc: 66.58%\n",
      "Epoch [46/100], Step [210/313], Loss: 1.0303, Acc: 66.66%\n",
      "Epoch [46/100], Step [220/313], Loss: 1.3249, Acc: 66.52%\n",
      "Epoch [46/100], Step [230/313], Loss: 1.1384, Acc: 66.55%\n",
      "Epoch [46/100], Step [240/313], Loss: 1.2054, Acc: 66.53%\n",
      "Epoch [46/100], Step [250/313], Loss: 1.0743, Acc: 66.50%\n",
      "Epoch [46/100], Step [260/313], Loss: 1.0363, Acc: 66.47%\n",
      "Epoch [46/100], Step [270/313], Loss: 1.0180, Acc: 66.48%\n",
      "Epoch [46/100], Step [280/313], Loss: 0.9165, Acc: 66.52%\n",
      "Epoch [46/100], Step [290/313], Loss: 1.1138, Acc: 66.45%\n",
      "Epoch [46/100], Step [300/313], Loss: 1.2757, Acc: 66.40%\n",
      "Epoch [46/100], Step [310/313], Loss: 1.3603, Acc: 66.40%\n",
      "Epoch [47/100], Step [10/313], Loss: 0.8754, Acc: 67.58%\n",
      "Epoch [47/100], Step [20/313], Loss: 1.1977, Acc: 68.20%\n",
      "Epoch [47/100], Step [30/313], Loss: 1.0787, Acc: 67.89%\n",
      "Epoch [47/100], Step [40/313], Loss: 1.0213, Acc: 67.36%\n",
      "Epoch [47/100], Step [50/313], Loss: 1.3941, Acc: 67.62%\n",
      "Epoch [47/100], Step [60/313], Loss: 1.1856, Acc: 67.25%\n",
      "Epoch [47/100], Step [70/313], Loss: 1.0849, Acc: 67.01%\n",
      "Epoch [47/100], Step [80/313], Loss: 1.2180, Acc: 67.14%\n",
      "Epoch [47/100], Step [90/313], Loss: 0.9967, Acc: 66.90%\n",
      "Epoch [47/100], Step [100/313], Loss: 0.9670, Acc: 66.91%\n",
      "Epoch [47/100], Step [110/313], Loss: 1.1294, Acc: 66.81%\n",
      "Epoch [47/100], Step [120/313], Loss: 1.2186, Acc: 66.90%\n",
      "Epoch [47/100], Step [130/313], Loss: 1.0548, Acc: 66.69%\n",
      "Epoch [47/100], Step [140/313], Loss: 1.2358, Acc: 66.60%\n",
      "Epoch [47/100], Step [150/313], Loss: 1.2228, Acc: 66.52%\n",
      "Epoch [47/100], Step [160/313], Loss: 1.0702, Acc: 66.57%\n",
      "Epoch [47/100], Step [170/313], Loss: 1.0507, Acc: 66.46%\n",
      "Epoch [47/100], Step [180/313], Loss: 1.0158, Acc: 66.40%\n",
      "Epoch [47/100], Step [190/313], Loss: 1.0712, Acc: 66.56%\n",
      "Epoch [47/100], Step [200/313], Loss: 1.0966, Acc: 66.47%\n",
      "Epoch [47/100], Step [210/313], Loss: 1.1055, Acc: 66.45%\n",
      "Epoch [47/100], Step [220/313], Loss: 1.1729, Acc: 66.35%\n",
      "Epoch [47/100], Step [230/313], Loss: 1.0940, Acc: 66.42%\n",
      "Epoch [47/100], Step [240/313], Loss: 1.0576, Acc: 66.51%\n",
      "Epoch [47/100], Step [250/313], Loss: 1.0408, Acc: 66.53%\n",
      "Epoch [47/100], Step [260/313], Loss: 0.9238, Acc: 66.53%\n",
      "Epoch [47/100], Step [270/313], Loss: 1.0187, Acc: 66.52%\n",
      "Epoch [47/100], Step [280/313], Loss: 0.9204, Acc: 66.58%\n",
      "Epoch [47/100], Step [290/313], Loss: 0.9852, Acc: 66.58%\n",
      "Epoch [47/100], Step [300/313], Loss: 1.2343, Acc: 66.56%\n",
      "Epoch [47/100], Step [310/313], Loss: 1.2314, Acc: 66.56%\n",
      "Epoch [48/100], Step [10/313], Loss: 0.9467, Acc: 66.41%\n",
      "Epoch [48/100], Step [20/313], Loss: 1.2531, Acc: 66.91%\n",
      "Epoch [48/100], Step [30/313], Loss: 0.9551, Acc: 67.63%\n",
      "Epoch [48/100], Step [40/313], Loss: 1.0636, Acc: 67.66%\n",
      "Epoch [48/100], Step [50/313], Loss: 1.3169, Acc: 67.75%\n",
      "Epoch [48/100], Step [60/313], Loss: 1.2820, Acc: 67.64%\n",
      "Epoch [48/100], Step [70/313], Loss: 1.1158, Acc: 67.08%\n",
      "Epoch [48/100], Step [80/313], Loss: 1.2543, Acc: 67.33%\n",
      "Epoch [48/100], Step [90/313], Loss: 0.9495, Acc: 67.50%\n",
      "Epoch [48/100], Step [100/313], Loss: 0.9076, Acc: 67.43%\n",
      "Epoch [48/100], Step [110/313], Loss: 1.1294, Acc: 67.30%\n",
      "Epoch [48/100], Step [120/313], Loss: 1.1895, Acc: 67.25%\n",
      "Epoch [48/100], Step [130/313], Loss: 1.0799, Acc: 67.15%\n",
      "Epoch [48/100], Step [140/313], Loss: 1.0783, Acc: 67.10%\n",
      "Epoch [48/100], Step [150/313], Loss: 1.2425, Acc: 66.96%\n",
      "Epoch [48/100], Step [160/313], Loss: 0.9063, Acc: 67.00%\n",
      "Epoch [48/100], Step [170/313], Loss: 0.9892, Acc: 66.96%\n",
      "Epoch [48/100], Step [180/313], Loss: 1.0321, Acc: 66.81%\n",
      "Epoch [48/100], Step [190/313], Loss: 0.9774, Acc: 67.04%\n",
      "Epoch [48/100], Step [200/313], Loss: 1.0491, Acc: 67.07%\n",
      "Epoch [48/100], Step [210/313], Loss: 0.9570, Acc: 67.05%\n",
      "Epoch [48/100], Step [220/313], Loss: 1.4336, Acc: 67.03%\n",
      "Epoch [48/100], Step [230/313], Loss: 0.9677, Acc: 67.09%\n",
      "Epoch [48/100], Step [240/313], Loss: 0.9935, Acc: 67.15%\n",
      "Epoch [48/100], Step [250/313], Loss: 0.9595, Acc: 67.25%\n",
      "Epoch [48/100], Step [260/313], Loss: 1.0276, Acc: 67.22%\n",
      "Epoch [48/100], Step [270/313], Loss: 1.0637, Acc: 67.20%\n",
      "Epoch [48/100], Step [280/313], Loss: 0.9307, Acc: 67.23%\n",
      "Epoch [48/100], Step [290/313], Loss: 1.0710, Acc: 67.16%\n",
      "Epoch [48/100], Step [300/313], Loss: 1.2932, Acc: 67.18%\n",
      "Epoch [48/100], Step [310/313], Loss: 1.0971, Acc: 67.18%\n",
      "Epoch [49/100], Step [10/313], Loss: 1.0016, Acc: 68.28%\n",
      "Epoch [49/100], Step [20/313], Loss: 1.3285, Acc: 67.23%\n",
      "Epoch [49/100], Step [30/313], Loss: 0.9587, Acc: 68.70%\n",
      "Epoch [49/100], Step [40/313], Loss: 0.9117, Acc: 68.57%\n",
      "Epoch [49/100], Step [50/313], Loss: 1.2949, Acc: 68.92%\n",
      "Epoch [49/100], Step [60/313], Loss: 1.2072, Acc: 68.74%\n",
      "Epoch [49/100], Step [70/313], Loss: 1.0702, Acc: 68.40%\n",
      "Epoch [49/100], Step [80/313], Loss: 1.2065, Acc: 68.58%\n",
      "Epoch [49/100], Step [90/313], Loss: 0.9083, Acc: 68.71%\n",
      "Epoch [49/100], Step [100/313], Loss: 0.9981, Acc: 68.45%\n",
      "Epoch [49/100], Step [110/313], Loss: 1.0501, Acc: 68.41%\n",
      "Epoch [49/100], Step [120/313], Loss: 1.2073, Acc: 68.33%\n",
      "Epoch [49/100], Step [130/313], Loss: 0.9856, Acc: 68.23%\n",
      "Epoch [49/100], Step [140/313], Loss: 1.0932, Acc: 68.17%\n",
      "Epoch [49/100], Step [150/313], Loss: 1.1246, Acc: 68.15%\n",
      "Epoch [49/100], Step [160/313], Loss: 0.8554, Acc: 68.15%\n",
      "Epoch [49/100], Step [170/313], Loss: 1.0705, Acc: 68.04%\n",
      "Epoch [49/100], Step [180/313], Loss: 1.0121, Acc: 67.86%\n",
      "Epoch [49/100], Step [190/313], Loss: 1.0476, Acc: 68.01%\n",
      "Epoch [49/100], Step [200/313], Loss: 0.9574, Acc: 68.00%\n",
      "Epoch [49/100], Step [210/313], Loss: 0.9434, Acc: 68.04%\n",
      "Epoch [49/100], Step [220/313], Loss: 1.3299, Acc: 67.97%\n",
      "Epoch [49/100], Step [230/313], Loss: 0.8629, Acc: 67.98%\n",
      "Epoch [49/100], Step [240/313], Loss: 1.1365, Acc: 67.93%\n",
      "Epoch [49/100], Step [250/313], Loss: 1.1030, Acc: 67.95%\n",
      "Epoch [49/100], Step [260/313], Loss: 1.1115, Acc: 67.97%\n",
      "Epoch [49/100], Step [270/313], Loss: 1.1672, Acc: 67.97%\n",
      "Epoch [49/100], Step [280/313], Loss: 0.8713, Acc: 68.05%\n",
      "Epoch [49/100], Step [290/313], Loss: 0.9379, Acc: 68.05%\n",
      "Epoch [49/100], Step [300/313], Loss: 1.2907, Acc: 68.13%\n",
      "Epoch [49/100], Step [310/313], Loss: 1.1233, Acc: 68.18%\n",
      "Epoch [50/100], Step [10/313], Loss: 0.8887, Acc: 69.84%\n",
      "Epoch [50/100], Step [20/313], Loss: 1.3083, Acc: 69.61%\n",
      "Epoch [50/100], Step [30/313], Loss: 0.9352, Acc: 69.51%\n",
      "Epoch [50/100], Step [40/313], Loss: 1.0098, Acc: 69.04%\n",
      "Epoch [50/100], Step [50/313], Loss: 1.4685, Acc: 68.81%\n",
      "Epoch [50/100], Step [60/313], Loss: 1.1579, Acc: 68.78%\n",
      "Epoch [50/100], Step [70/313], Loss: 1.0190, Acc: 68.62%\n",
      "Epoch [50/100], Step [80/313], Loss: 1.3034, Acc: 68.61%\n",
      "Epoch [50/100], Step [90/313], Loss: 1.0661, Acc: 68.39%\n",
      "Epoch [50/100], Step [100/313], Loss: 0.9599, Acc: 68.36%\n",
      "Epoch [50/100], Step [110/313], Loss: 1.0547, Acc: 68.54%\n",
      "Epoch [50/100], Step [120/313], Loss: 1.1849, Acc: 68.63%\n",
      "Epoch [50/100], Step [130/313], Loss: 0.9856, Acc: 68.65%\n",
      "Epoch [50/100], Step [140/313], Loss: 0.9918, Acc: 68.71%\n",
      "Epoch [50/100], Step [150/313], Loss: 1.0200, Acc: 68.74%\n",
      "Epoch [50/100], Step [160/313], Loss: 0.8056, Acc: 68.80%\n",
      "Epoch [50/100], Step [170/313], Loss: 1.0064, Acc: 68.72%\n",
      "Epoch [50/100], Step [180/313], Loss: 0.9398, Acc: 68.73%\n",
      "Epoch [50/100], Step [190/313], Loss: 0.9416, Acc: 68.82%\n",
      "Epoch [50/100], Step [200/313], Loss: 0.9827, Acc: 68.81%\n",
      "Epoch [50/100], Step [210/313], Loss: 0.8658, Acc: 68.89%\n",
      "Epoch [50/100], Step [220/313], Loss: 1.0092, Acc: 68.87%\n",
      "Epoch [50/100], Step [230/313], Loss: 1.0771, Acc: 68.87%\n",
      "Epoch [50/100], Step [240/313], Loss: 0.9751, Acc: 68.93%\n",
      "Epoch [50/100], Step [250/313], Loss: 1.0215, Acc: 69.03%\n",
      "Epoch [50/100], Step [260/313], Loss: 0.9259, Acc: 69.02%\n",
      "Epoch [50/100], Step [270/313], Loss: 0.8877, Acc: 69.02%\n",
      "Epoch [50/100], Step [280/313], Loss: 0.9191, Acc: 69.06%\n",
      "Epoch [50/100], Step [290/313], Loss: 1.0435, Acc: 69.08%\n",
      "Epoch [50/100], Step [300/313], Loss: 1.3606, Acc: 69.01%\n",
      "Epoch [50/100], Step [310/313], Loss: 1.2683, Acc: 68.99%\n",
      "Epoch [51/100], Step [10/313], Loss: 0.8422, Acc: 70.70%\n",
      "Epoch [51/100], Step [20/313], Loss: 1.2312, Acc: 70.43%\n",
      "Epoch [51/100], Step [30/313], Loss: 0.8372, Acc: 70.78%\n",
      "Epoch [51/100], Step [40/313], Loss: 0.9813, Acc: 70.31%\n",
      "Epoch [51/100], Step [50/313], Loss: 1.2666, Acc: 69.72%\n",
      "Epoch [51/100], Step [60/313], Loss: 1.1024, Acc: 69.83%\n",
      "Epoch [51/100], Step [70/313], Loss: 1.0429, Acc: 69.35%\n",
      "Epoch [51/100], Step [80/313], Loss: 1.2462, Acc: 69.41%\n",
      "Epoch [51/100], Step [90/313], Loss: 0.9509, Acc: 69.64%\n",
      "Epoch [51/100], Step [100/313], Loss: 1.0346, Acc: 69.55%\n",
      "Epoch [51/100], Step [110/313], Loss: 1.0170, Acc: 69.61%\n",
      "Epoch [51/100], Step [120/313], Loss: 1.0021, Acc: 69.67%\n",
      "Epoch [51/100], Step [130/313], Loss: 0.9282, Acc: 69.60%\n",
      "Epoch [51/100], Step [140/313], Loss: 1.0416, Acc: 69.48%\n",
      "Epoch [51/100], Step [150/313], Loss: 1.1700, Acc: 69.27%\n",
      "Epoch [51/100], Step [160/313], Loss: 0.8201, Acc: 69.29%\n",
      "Epoch [51/100], Step [170/313], Loss: 0.8724, Acc: 69.30%\n",
      "Epoch [51/100], Step [180/313], Loss: 0.9221, Acc: 69.24%\n",
      "Epoch [51/100], Step [190/313], Loss: 1.1194, Acc: 69.29%\n",
      "Epoch [51/100], Step [200/313], Loss: 0.9268, Acc: 69.23%\n",
      "Epoch [51/100], Step [210/313], Loss: 1.1145, Acc: 69.21%\n",
      "Epoch [51/100], Step [220/313], Loss: 1.1273, Acc: 69.12%\n",
      "Epoch [51/100], Step [230/313], Loss: 1.0252, Acc: 69.09%\n",
      "Epoch [51/100], Step [240/313], Loss: 1.0503, Acc: 69.14%\n",
      "Epoch [51/100], Step [250/313], Loss: 1.0797, Acc: 69.21%\n",
      "Epoch [51/100], Step [260/313], Loss: 0.9446, Acc: 69.18%\n",
      "Epoch [51/100], Step [270/313], Loss: 0.9309, Acc: 69.14%\n",
      "Epoch [51/100], Step [280/313], Loss: 0.8686, Acc: 69.19%\n",
      "Epoch [51/100], Step [290/313], Loss: 0.8984, Acc: 69.15%\n",
      "Epoch [51/100], Step [300/313], Loss: 1.2269, Acc: 69.16%\n",
      "Epoch [51/100], Step [310/313], Loss: 1.1723, Acc: 69.12%\n",
      "Epoch [52/100], Step [10/313], Loss: 0.9395, Acc: 69.92%\n",
      "Epoch [52/100], Step [20/313], Loss: 1.1269, Acc: 68.98%\n",
      "Epoch [52/100], Step [30/313], Loss: 0.9020, Acc: 69.77%\n",
      "Epoch [52/100], Step [40/313], Loss: 1.0408, Acc: 69.59%\n",
      "Epoch [52/100], Step [50/313], Loss: 1.2484, Acc: 69.41%\n",
      "Epoch [52/100], Step [60/313], Loss: 1.0546, Acc: 69.31%\n",
      "Epoch [52/100], Step [70/313], Loss: 1.0120, Acc: 69.39%\n",
      "Epoch [52/100], Step [80/313], Loss: 1.0526, Acc: 69.65%\n",
      "Epoch [52/100], Step [90/313], Loss: 0.8656, Acc: 69.99%\n",
      "Epoch [52/100], Step [100/313], Loss: 0.9256, Acc: 69.87%\n",
      "Epoch [52/100], Step [110/313], Loss: 1.0892, Acc: 69.81%\n",
      "Epoch [52/100], Step [120/313], Loss: 1.0994, Acc: 69.89%\n",
      "Epoch [52/100], Step [130/313], Loss: 0.9649, Acc: 69.76%\n",
      "Epoch [52/100], Step [140/313], Loss: 1.0039, Acc: 69.81%\n",
      "Epoch [52/100], Step [150/313], Loss: 1.1916, Acc: 69.66%\n",
      "Epoch [52/100], Step [160/313], Loss: 0.8827, Acc: 69.70%\n",
      "Epoch [52/100], Step [170/313], Loss: 1.0388, Acc: 69.62%\n",
      "Epoch [52/100], Step [180/313], Loss: 0.9449, Acc: 69.55%\n",
      "Epoch [52/100], Step [190/313], Loss: 0.9232, Acc: 69.69%\n",
      "Epoch [52/100], Step [200/313], Loss: 0.8664, Acc: 69.58%\n",
      "Epoch [52/100], Step [210/313], Loss: 0.9532, Acc: 69.52%\n",
      "Epoch [52/100], Step [220/313], Loss: 1.2530, Acc: 69.51%\n",
      "Epoch [52/100], Step [230/313], Loss: 0.9706, Acc: 69.43%\n",
      "Epoch [52/100], Step [240/313], Loss: 1.0822, Acc: 69.46%\n",
      "Epoch [52/100], Step [250/313], Loss: 1.0356, Acc: 69.50%\n",
      "Epoch [52/100], Step [260/313], Loss: 1.0057, Acc: 69.49%\n",
      "Epoch [52/100], Step [270/313], Loss: 1.0403, Acc: 69.43%\n",
      "Epoch [52/100], Step [280/313], Loss: 0.7728, Acc: 69.48%\n",
      "Epoch [52/100], Step [290/313], Loss: 0.9352, Acc: 69.50%\n",
      "Epoch [52/100], Step [300/313], Loss: 1.2063, Acc: 69.45%\n",
      "Epoch [52/100], Step [310/313], Loss: 1.2086, Acc: 69.46%\n",
      "Epoch [53/100], Step [10/313], Loss: 0.9891, Acc: 71.25%\n",
      "Epoch [53/100], Step [20/313], Loss: 1.1852, Acc: 71.09%\n",
      "Epoch [53/100], Step [30/313], Loss: 0.7968, Acc: 71.09%\n",
      "Epoch [53/100], Step [40/313], Loss: 1.0014, Acc: 71.31%\n",
      "Epoch [53/100], Step [50/313], Loss: 1.3359, Acc: 70.89%\n",
      "Epoch [53/100], Step [60/313], Loss: 1.0903, Acc: 70.48%\n",
      "Epoch [53/100], Step [70/313], Loss: 0.9105, Acc: 69.96%\n",
      "Epoch [53/100], Step [80/313], Loss: 1.0996, Acc: 70.12%\n",
      "Epoch [53/100], Step [90/313], Loss: 0.9479, Acc: 70.26%\n",
      "Epoch [53/100], Step [100/313], Loss: 0.9370, Acc: 70.34%\n",
      "Epoch [53/100], Step [110/313], Loss: 1.1740, Acc: 70.37%\n",
      "Epoch [53/100], Step [120/313], Loss: 1.1181, Acc: 70.22%\n",
      "Epoch [53/100], Step [130/313], Loss: 1.0444, Acc: 70.20%\n",
      "Epoch [53/100], Step [140/313], Loss: 0.9866, Acc: 70.20%\n",
      "Epoch [53/100], Step [150/313], Loss: 1.0063, Acc: 70.15%\n",
      "Epoch [53/100], Step [160/313], Loss: 0.7441, Acc: 70.24%\n",
      "Epoch [53/100], Step [170/313], Loss: 0.9053, Acc: 70.20%\n",
      "Epoch [53/100], Step [180/313], Loss: 0.9345, Acc: 70.24%\n",
      "Epoch [53/100], Step [190/313], Loss: 0.9074, Acc: 70.40%\n",
      "Epoch [53/100], Step [200/313], Loss: 1.0792, Acc: 70.29%\n",
      "Epoch [53/100], Step [210/313], Loss: 0.9289, Acc: 70.38%\n",
      "Epoch [53/100], Step [220/313], Loss: 1.0435, Acc: 70.34%\n",
      "Epoch [53/100], Step [230/313], Loss: 0.8013, Acc: 70.40%\n",
      "Epoch [53/100], Step [240/313], Loss: 1.1121, Acc: 70.41%\n",
      "Epoch [53/100], Step [250/313], Loss: 0.9970, Acc: 70.46%\n",
      "Epoch [53/100], Step [260/313], Loss: 0.9745, Acc: 70.41%\n",
      "Epoch [53/100], Step [270/313], Loss: 0.9362, Acc: 70.36%\n",
      "Epoch [53/100], Step [280/313], Loss: 1.0011, Acc: 70.41%\n",
      "Epoch [53/100], Step [290/313], Loss: 0.9732, Acc: 70.36%\n",
      "Epoch [53/100], Step [300/313], Loss: 1.1981, Acc: 70.35%\n",
      "Epoch [53/100], Step [310/313], Loss: 1.1070, Acc: 70.33%\n",
      "Epoch [54/100], Step [10/313], Loss: 0.9668, Acc: 71.09%\n",
      "Epoch [54/100], Step [20/313], Loss: 1.1642, Acc: 71.45%\n",
      "Epoch [54/100], Step [30/313], Loss: 0.8835, Acc: 71.56%\n",
      "Epoch [54/100], Step [40/313], Loss: 1.0155, Acc: 71.31%\n",
      "Epoch [54/100], Step [50/313], Loss: 1.1440, Acc: 71.20%\n",
      "Epoch [54/100], Step [60/313], Loss: 1.0427, Acc: 71.16%\n",
      "Epoch [54/100], Step [70/313], Loss: 0.9225, Acc: 70.83%\n",
      "Epoch [54/100], Step [80/313], Loss: 1.0011, Acc: 70.78%\n",
      "Epoch [54/100], Step [90/313], Loss: 0.9080, Acc: 70.84%\n",
      "Epoch [54/100], Step [100/313], Loss: 0.9103, Acc: 70.77%\n",
      "Epoch [54/100], Step [110/313], Loss: 0.9518, Acc: 70.68%\n",
      "Epoch [54/100], Step [120/313], Loss: 1.0985, Acc: 70.62%\n",
      "Epoch [54/100], Step [130/313], Loss: 0.9078, Acc: 70.59%\n",
      "Epoch [54/100], Step [140/313], Loss: 0.9200, Acc: 70.69%\n",
      "Epoch [54/100], Step [150/313], Loss: 1.0788, Acc: 70.55%\n",
      "Epoch [54/100], Step [160/313], Loss: 0.7929, Acc: 70.79%\n",
      "Epoch [54/100], Step [170/313], Loss: 0.8931, Acc: 70.85%\n",
      "Epoch [54/100], Step [180/313], Loss: 0.8833, Acc: 70.90%\n",
      "Epoch [54/100], Step [190/313], Loss: 0.9351, Acc: 71.04%\n",
      "Epoch [54/100], Step [200/313], Loss: 0.8893, Acc: 71.00%\n",
      "Epoch [54/100], Step [210/313], Loss: 0.8661, Acc: 71.04%\n",
      "Epoch [54/100], Step [220/313], Loss: 1.0992, Acc: 71.05%\n",
      "Epoch [54/100], Step [230/313], Loss: 0.8112, Acc: 71.11%\n",
      "Epoch [54/100], Step [240/313], Loss: 0.9877, Acc: 71.19%\n",
      "Epoch [54/100], Step [250/313], Loss: 1.0144, Acc: 71.18%\n",
      "Epoch [54/100], Step [260/313], Loss: 0.9237, Acc: 71.12%\n",
      "Epoch [54/100], Step [270/313], Loss: 0.8949, Acc: 71.09%\n",
      "Epoch [54/100], Step [280/313], Loss: 1.0483, Acc: 71.03%\n",
      "Epoch [54/100], Step [290/313], Loss: 0.8457, Acc: 71.01%\n",
      "Epoch [54/100], Step [300/313], Loss: 1.1400, Acc: 70.99%\n",
      "Epoch [54/100], Step [310/313], Loss: 1.0248, Acc: 70.99%\n",
      "Epoch [55/100], Step [10/313], Loss: 0.9100, Acc: 71.64%\n",
      "Epoch [55/100], Step [20/313], Loss: 1.1302, Acc: 71.33%\n",
      "Epoch [55/100], Step [30/313], Loss: 0.7967, Acc: 71.80%\n",
      "Epoch [55/100], Step [40/313], Loss: 0.9627, Acc: 71.54%\n",
      "Epoch [55/100], Step [50/313], Loss: 1.1358, Acc: 71.62%\n",
      "Epoch [55/100], Step [60/313], Loss: 0.9774, Acc: 71.46%\n",
      "Epoch [55/100], Step [70/313], Loss: 0.9398, Acc: 71.12%\n",
      "Epoch [55/100], Step [80/313], Loss: 1.2829, Acc: 71.27%\n",
      "Epoch [55/100], Step [90/313], Loss: 0.8780, Acc: 71.27%\n",
      "Epoch [55/100], Step [100/313], Loss: 0.9017, Acc: 71.41%\n",
      "Epoch [55/100], Step [110/313], Loss: 1.0997, Acc: 71.23%\n",
      "Epoch [55/100], Step [120/313], Loss: 1.1349, Acc: 71.19%\n",
      "Epoch [55/100], Step [130/313], Loss: 0.8698, Acc: 71.07%\n",
      "Epoch [55/100], Step [140/313], Loss: 0.8665, Acc: 71.22%\n",
      "Epoch [55/100], Step [150/313], Loss: 1.1384, Acc: 71.07%\n",
      "Epoch [55/100], Step [160/313], Loss: 0.7958, Acc: 71.04%\n",
      "Epoch [55/100], Step [170/313], Loss: 0.8261, Acc: 71.01%\n",
      "Epoch [55/100], Step [180/313], Loss: 0.9398, Acc: 70.96%\n",
      "Epoch [55/100], Step [190/313], Loss: 0.8319, Acc: 71.04%\n",
      "Epoch [55/100], Step [200/313], Loss: 1.0358, Acc: 70.92%\n",
      "Epoch [55/100], Step [210/313], Loss: 0.9866, Acc: 70.84%\n",
      "Epoch [55/100], Step [220/313], Loss: 1.1625, Acc: 70.72%\n",
      "Epoch [55/100], Step [230/313], Loss: 0.9023, Acc: 70.77%\n",
      "Epoch [55/100], Step [240/313], Loss: 0.9766, Acc: 70.75%\n",
      "Epoch [55/100], Step [250/313], Loss: 0.9388, Acc: 70.80%\n",
      "Epoch [55/100], Step [260/313], Loss: 0.8409, Acc: 70.83%\n",
      "Epoch [55/100], Step [270/313], Loss: 0.8516, Acc: 70.80%\n",
      "Epoch [55/100], Step [280/313], Loss: 0.7674, Acc: 70.81%\n",
      "Epoch [55/100], Step [290/313], Loss: 0.9142, Acc: 70.78%\n",
      "Epoch [55/100], Step [300/313], Loss: 1.1505, Acc: 70.75%\n",
      "Epoch [55/100], Step [310/313], Loss: 1.2926, Acc: 70.71%\n",
      "Epoch [56/100], Step [10/313], Loss: 0.9313, Acc: 70.23%\n",
      "Epoch [56/100], Step [20/313], Loss: 1.1325, Acc: 69.49%\n",
      "Epoch [56/100], Step [30/313], Loss: 0.8477, Acc: 69.92%\n",
      "Epoch [56/100], Step [40/313], Loss: 0.9495, Acc: 70.08%\n",
      "Epoch [56/100], Step [50/313], Loss: 1.1613, Acc: 70.14%\n",
      "Epoch [56/100], Step [60/313], Loss: 0.9792, Acc: 70.29%\n",
      "Epoch [56/100], Step [70/313], Loss: 0.9593, Acc: 69.91%\n",
      "Epoch [56/100], Step [80/313], Loss: 1.0783, Acc: 70.27%\n",
      "Epoch [56/100], Step [90/313], Loss: 0.9334, Acc: 70.41%\n",
      "Epoch [56/100], Step [100/313], Loss: 0.9127, Acc: 70.53%\n",
      "Epoch [56/100], Step [110/313], Loss: 0.8409, Acc: 70.65%\n",
      "Epoch [56/100], Step [120/313], Loss: 1.1556, Acc: 70.74%\n",
      "Epoch [56/100], Step [130/313], Loss: 0.8691, Acc: 70.87%\n",
      "Epoch [56/100], Step [140/313], Loss: 1.0360, Acc: 70.94%\n",
      "Epoch [56/100], Step [150/313], Loss: 1.1349, Acc: 70.81%\n",
      "Epoch [56/100], Step [160/313], Loss: 0.6878, Acc: 70.82%\n",
      "Epoch [56/100], Step [170/313], Loss: 0.8760, Acc: 70.82%\n",
      "Epoch [56/100], Step [180/313], Loss: 0.8730, Acc: 70.79%\n",
      "Epoch [56/100], Step [190/313], Loss: 0.8960, Acc: 70.95%\n",
      "Epoch [56/100], Step [200/313], Loss: 0.9620, Acc: 70.89%\n",
      "Epoch [56/100], Step [210/313], Loss: 0.9486, Acc: 70.95%\n",
      "Epoch [56/100], Step [220/313], Loss: 1.0742, Acc: 71.00%\n",
      "Epoch [56/100], Step [230/313], Loss: 0.8127, Acc: 70.98%\n",
      "Epoch [56/100], Step [240/313], Loss: 0.9742, Acc: 71.04%\n",
      "Epoch [56/100], Step [250/313], Loss: 0.8673, Acc: 71.05%\n",
      "Epoch [56/100], Step [260/313], Loss: 0.9050, Acc: 71.03%\n",
      "Epoch [56/100], Step [270/313], Loss: 0.9023, Acc: 71.02%\n",
      "Epoch [56/100], Step [280/313], Loss: 0.8170, Acc: 71.05%\n",
      "Epoch [56/100], Step [290/313], Loss: 0.9287, Acc: 71.03%\n",
      "Epoch [56/100], Step [300/313], Loss: 1.0255, Acc: 71.03%\n",
      "Epoch [56/100], Step [310/313], Loss: 1.0889, Acc: 71.06%\n",
      "Epoch [57/100], Step [10/313], Loss: 0.8653, Acc: 70.94%\n",
      "Epoch [57/100], Step [20/313], Loss: 1.1984, Acc: 70.78%\n",
      "Epoch [57/100], Step [30/313], Loss: 0.7384, Acc: 71.30%\n",
      "Epoch [57/100], Step [40/313], Loss: 0.8330, Acc: 71.82%\n",
      "Epoch [57/100], Step [50/313], Loss: 1.0787, Acc: 71.84%\n",
      "Epoch [57/100], Step [60/313], Loss: 0.9094, Acc: 72.21%\n",
      "Epoch [57/100], Step [70/313], Loss: 0.9331, Acc: 72.05%\n",
      "Epoch [57/100], Step [80/313], Loss: 1.0190, Acc: 71.93%\n",
      "Epoch [57/100], Step [90/313], Loss: 0.7702, Acc: 71.86%\n",
      "Epoch [57/100], Step [100/313], Loss: 0.8698, Acc: 72.00%\n",
      "Epoch [57/100], Step [110/313], Loss: 0.9448, Acc: 72.10%\n",
      "Epoch [57/100], Step [120/313], Loss: 1.0588, Acc: 72.01%\n",
      "Epoch [57/100], Step [130/313], Loss: 0.8476, Acc: 71.94%\n",
      "Epoch [57/100], Step [140/313], Loss: 0.8775, Acc: 72.06%\n",
      "Epoch [57/100], Step [150/313], Loss: 1.1004, Acc: 71.98%\n",
      "Epoch [57/100], Step [160/313], Loss: 0.7581, Acc: 72.08%\n",
      "Epoch [57/100], Step [170/313], Loss: 0.8724, Acc: 72.01%\n",
      "Epoch [57/100], Step [180/313], Loss: 0.9927, Acc: 71.90%\n",
      "Epoch [57/100], Step [190/313], Loss: 0.7592, Acc: 72.06%\n",
      "Epoch [57/100], Step [200/313], Loss: 0.8117, Acc: 72.04%\n",
      "Epoch [57/100], Step [210/313], Loss: 1.0714, Acc: 71.96%\n",
      "Epoch [57/100], Step [220/313], Loss: 1.0634, Acc: 71.85%\n",
      "Epoch [57/100], Step [230/313], Loss: 0.8824, Acc: 71.83%\n",
      "Epoch [57/100], Step [240/313], Loss: 1.0388, Acc: 71.88%\n",
      "Epoch [57/100], Step [250/313], Loss: 0.9895, Acc: 71.88%\n",
      "Epoch [57/100], Step [260/313], Loss: 0.8236, Acc: 71.81%\n",
      "Epoch [57/100], Step [270/313], Loss: 0.8556, Acc: 71.77%\n",
      "Epoch [57/100], Step [280/313], Loss: 0.9551, Acc: 71.81%\n",
      "Epoch [57/100], Step [290/313], Loss: 0.8640, Acc: 71.81%\n",
      "Epoch [57/100], Step [300/313], Loss: 1.1201, Acc: 71.79%\n",
      "Epoch [57/100], Step [310/313], Loss: 1.0079, Acc: 71.78%\n",
      "Epoch [58/100], Step [10/313], Loss: 0.8929, Acc: 72.34%\n",
      "Epoch [58/100], Step [20/313], Loss: 1.1135, Acc: 72.46%\n",
      "Epoch [58/100], Step [30/313], Loss: 0.7253, Acc: 72.45%\n",
      "Epoch [58/100], Step [40/313], Loss: 0.9199, Acc: 72.30%\n",
      "Epoch [58/100], Step [50/313], Loss: 1.0308, Acc: 72.91%\n",
      "Epoch [58/100], Step [60/313], Loss: 0.8927, Acc: 72.72%\n",
      "Epoch [58/100], Step [70/313], Loss: 0.8196, Acc: 72.42%\n",
      "Epoch [58/100], Step [80/313], Loss: 1.1028, Acc: 72.30%\n",
      "Epoch [58/100], Step [90/313], Loss: 0.7638, Acc: 72.47%\n",
      "Epoch [58/100], Step [100/313], Loss: 0.8837, Acc: 72.43%\n",
      "Epoch [58/100], Step [110/313], Loss: 0.9167, Acc: 72.30%\n",
      "Epoch [58/100], Step [120/313], Loss: 1.0714, Acc: 72.10%\n",
      "Epoch [58/100], Step [130/313], Loss: 0.9726, Acc: 71.98%\n",
      "Epoch [58/100], Step [140/313], Loss: 0.9318, Acc: 71.98%\n",
      "Epoch [58/100], Step [150/313], Loss: 0.9398, Acc: 71.86%\n",
      "Epoch [58/100], Step [160/313], Loss: 0.8477, Acc: 71.81%\n",
      "Epoch [58/100], Step [170/313], Loss: 0.8755, Acc: 71.76%\n",
      "Epoch [58/100], Step [180/313], Loss: 0.9300, Acc: 71.78%\n",
      "Epoch [58/100], Step [190/313], Loss: 0.8848, Acc: 71.88%\n",
      "Epoch [58/100], Step [200/313], Loss: 0.8918, Acc: 71.75%\n",
      "Epoch [58/100], Step [210/313], Loss: 0.8413, Acc: 71.91%\n",
      "Epoch [58/100], Step [220/313], Loss: 1.0558, Acc: 71.76%\n",
      "Epoch [58/100], Step [230/313], Loss: 0.8119, Acc: 71.74%\n",
      "Epoch [58/100], Step [240/313], Loss: 1.2110, Acc: 71.73%\n",
      "Epoch [58/100], Step [250/313], Loss: 0.9018, Acc: 71.82%\n",
      "Epoch [58/100], Step [260/313], Loss: 0.8200, Acc: 71.66%\n",
      "Epoch [58/100], Step [270/313], Loss: 0.8562, Acc: 71.60%\n",
      "Epoch [58/100], Step [280/313], Loss: 0.6902, Acc: 71.61%\n",
      "Epoch [58/100], Step [290/313], Loss: 0.7393, Acc: 71.65%\n",
      "Epoch [58/100], Step [300/313], Loss: 1.0812, Acc: 71.63%\n",
      "Epoch [58/100], Step [310/313], Loss: 1.0657, Acc: 71.56%\n",
      "Epoch [59/100], Step [10/313], Loss: 0.8763, Acc: 71.25%\n",
      "Epoch [59/100], Step [20/313], Loss: 1.0485, Acc: 71.09%\n",
      "Epoch [59/100], Step [30/313], Loss: 0.9244, Acc: 72.24%\n",
      "Epoch [59/100], Step [40/313], Loss: 0.8090, Acc: 72.07%\n",
      "Epoch [59/100], Step [50/313], Loss: 1.0777, Acc: 72.33%\n",
      "Epoch [59/100], Step [60/313], Loss: 0.9375, Acc: 72.50%\n",
      "Epoch [59/100], Step [70/313], Loss: 0.9619, Acc: 72.25%\n",
      "Epoch [59/100], Step [80/313], Loss: 1.1265, Acc: 72.32%\n",
      "Epoch [59/100], Step [90/313], Loss: 0.7595, Acc: 72.50%\n",
      "Epoch [59/100], Step [100/313], Loss: 0.8443, Acc: 72.52%\n",
      "Epoch [59/100], Step [110/313], Loss: 0.9340, Acc: 72.71%\n",
      "Epoch [59/100], Step [120/313], Loss: 1.0020, Acc: 72.81%\n",
      "Epoch [59/100], Step [130/313], Loss: 0.9019, Acc: 72.77%\n",
      "Epoch [59/100], Step [140/313], Loss: 0.9430, Acc: 72.78%\n",
      "Epoch [59/100], Step [150/313], Loss: 1.0639, Acc: 72.67%\n",
      "Epoch [59/100], Step [160/313], Loss: 0.6714, Acc: 72.65%\n",
      "Epoch [59/100], Step [170/313], Loss: 0.9053, Acc: 72.52%\n",
      "Epoch [59/100], Step [180/313], Loss: 0.8828, Acc: 72.46%\n",
      "Epoch [59/100], Step [190/313], Loss: 0.7744, Acc: 72.50%\n",
      "Epoch [59/100], Step [200/313], Loss: 0.8170, Acc: 72.40%\n",
      "Epoch [59/100], Step [210/313], Loss: 0.8753, Acc: 72.52%\n",
      "Epoch [59/100], Step [220/313], Loss: 1.0604, Acc: 72.46%\n",
      "Epoch [59/100], Step [230/313], Loss: 0.6823, Acc: 72.47%\n",
      "Epoch [59/100], Step [240/313], Loss: 1.0641, Acc: 72.48%\n",
      "Epoch [59/100], Step [250/313], Loss: 0.7716, Acc: 72.50%\n",
      "Epoch [59/100], Step [260/313], Loss: 0.8229, Acc: 72.37%\n",
      "Epoch [59/100], Step [270/313], Loss: 0.8967, Acc: 72.33%\n",
      "Epoch [59/100], Step [280/313], Loss: 0.9289, Acc: 72.31%\n",
      "Epoch [59/100], Step [290/313], Loss: 0.6835, Acc: 72.30%\n",
      "Epoch [59/100], Step [300/313], Loss: 0.9235, Acc: 72.34%\n",
      "Epoch [59/100], Step [310/313], Loss: 1.0424, Acc: 72.34%\n",
      "Epoch [60/100], Step [10/313], Loss: 0.7745, Acc: 73.44%\n",
      "Epoch [60/100], Step [20/313], Loss: 1.0745, Acc: 71.60%\n",
      "Epoch [60/100], Step [30/313], Loss: 0.8498, Acc: 72.29%\n",
      "Epoch [60/100], Step [40/313], Loss: 0.8303, Acc: 72.19%\n",
      "Epoch [60/100], Step [50/313], Loss: 1.1154, Acc: 72.23%\n",
      "Epoch [60/100], Step [60/313], Loss: 0.9023, Acc: 72.67%\n",
      "Epoch [60/100], Step [70/313], Loss: 0.8684, Acc: 72.52%\n",
      "Epoch [60/100], Step [80/313], Loss: 1.0282, Acc: 72.49%\n",
      "Epoch [60/100], Step [90/313], Loss: 0.6914, Acc: 72.78%\n",
      "Epoch [60/100], Step [100/313], Loss: 0.8370, Acc: 72.90%\n",
      "Epoch [60/100], Step [110/313], Loss: 0.8507, Acc: 73.24%\n",
      "Epoch [60/100], Step [120/313], Loss: 1.0194, Acc: 73.12%\n",
      "Epoch [60/100], Step [130/313], Loss: 0.8633, Acc: 73.12%\n",
      "Epoch [60/100], Step [140/313], Loss: 0.8561, Acc: 73.16%\n",
      "Epoch [60/100], Step [150/313], Loss: 1.0413, Acc: 73.16%\n",
      "Epoch [60/100], Step [160/313], Loss: 0.7476, Acc: 73.16%\n",
      "Epoch [60/100], Step [170/313], Loss: 0.8704, Acc: 73.14%\n",
      "Epoch [60/100], Step [180/313], Loss: 0.9293, Acc: 73.15%\n",
      "Epoch [60/100], Step [190/313], Loss: 0.7905, Acc: 73.24%\n",
      "Epoch [60/100], Step [200/313], Loss: 0.7779, Acc: 73.29%\n",
      "Epoch [60/100], Step [210/313], Loss: 0.8060, Acc: 73.31%\n",
      "Epoch [60/100], Step [220/313], Loss: 0.8999, Acc: 73.25%\n",
      "Epoch [60/100], Step [230/313], Loss: 0.7808, Acc: 73.20%\n",
      "Epoch [60/100], Step [240/313], Loss: 0.9029, Acc: 73.31%\n",
      "Epoch [60/100], Step [250/313], Loss: 0.8841, Acc: 73.33%\n",
      "Epoch [60/100], Step [260/313], Loss: 0.8969, Acc: 73.27%\n",
      "Epoch [60/100], Step [270/313], Loss: 0.9228, Acc: 73.17%\n",
      "Epoch [60/100], Step [280/313], Loss: 0.8509, Acc: 73.10%\n",
      "Epoch [60/100], Step [290/313], Loss: 0.8665, Acc: 73.03%\n",
      "Epoch [60/100], Step [300/313], Loss: 0.9090, Acc: 72.98%\n",
      "Epoch [60/100], Step [310/313], Loss: 1.1037, Acc: 72.93%\n",
      "Epoch [61/100], Step [10/313], Loss: 0.8918, Acc: 70.86%\n",
      "Epoch [61/100], Step [20/313], Loss: 1.0798, Acc: 71.64%\n",
      "Epoch [61/100], Step [30/313], Loss: 0.8261, Acc: 72.53%\n",
      "Epoch [61/100], Step [40/313], Loss: 0.7924, Acc: 72.48%\n",
      "Epoch [61/100], Step [50/313], Loss: 0.9410, Acc: 72.50%\n",
      "Epoch [61/100], Step [60/313], Loss: 0.9177, Acc: 72.73%\n",
      "Epoch [61/100], Step [70/313], Loss: 0.7868, Acc: 72.72%\n",
      "Epoch [61/100], Step [80/313], Loss: 1.0113, Acc: 72.88%\n",
      "Epoch [61/100], Step [90/313], Loss: 0.7196, Acc: 72.94%\n",
      "Epoch [61/100], Step [100/313], Loss: 0.7918, Acc: 73.04%\n",
      "Epoch [61/100], Step [110/313], Loss: 0.8312, Acc: 72.87%\n",
      "Epoch [61/100], Step [120/313], Loss: 1.0919, Acc: 72.78%\n",
      "Epoch [61/100], Step [130/313], Loss: 0.8343, Acc: 72.70%\n",
      "Epoch [61/100], Step [140/313], Loss: 0.7785, Acc: 72.76%\n",
      "Epoch [61/100], Step [150/313], Loss: 1.0124, Acc: 72.61%\n",
      "Epoch [61/100], Step [160/313], Loss: 0.9001, Acc: 72.66%\n",
      "Epoch [61/100], Step [170/313], Loss: 0.8217, Acc: 72.56%\n",
      "Epoch [61/100], Step [180/313], Loss: 0.8654, Acc: 72.50%\n",
      "Epoch [61/100], Step [190/313], Loss: 0.9258, Acc: 72.63%\n",
      "Epoch [61/100], Step [200/313], Loss: 0.9636, Acc: 72.59%\n",
      "Epoch [61/100], Step [210/313], Loss: 0.8828, Acc: 72.62%\n",
      "Epoch [61/100], Step [220/313], Loss: 0.9866, Acc: 72.60%\n",
      "Epoch [61/100], Step [230/313], Loss: 0.8166, Acc: 72.46%\n",
      "Epoch [61/100], Step [240/313], Loss: 0.9383, Acc: 72.47%\n",
      "Epoch [61/100], Step [250/313], Loss: 0.8132, Acc: 72.66%\n",
      "Epoch [61/100], Step [260/313], Loss: 0.7727, Acc: 72.65%\n",
      "Epoch [61/100], Step [270/313], Loss: 0.8269, Acc: 72.58%\n",
      "Epoch [61/100], Step [280/313], Loss: 0.7874, Acc: 72.54%\n",
      "Epoch [61/100], Step [290/313], Loss: 0.8864, Acc: 72.52%\n",
      "Epoch [61/100], Step [300/313], Loss: 1.1723, Acc: 72.46%\n",
      "Epoch [61/100], Step [310/313], Loss: 1.1083, Acc: 72.47%\n",
      "Epoch [62/100], Step [10/313], Loss: 0.9120, Acc: 71.33%\n",
      "Epoch [62/100], Step [20/313], Loss: 1.0266, Acc: 70.59%\n",
      "Epoch [62/100], Step [30/313], Loss: 0.7228, Acc: 72.01%\n",
      "Epoch [62/100], Step [40/313], Loss: 0.9343, Acc: 72.01%\n",
      "Epoch [62/100], Step [50/313], Loss: 1.0896, Acc: 71.92%\n",
      "Epoch [62/100], Step [60/313], Loss: 0.7958, Acc: 72.36%\n",
      "Epoch [62/100], Step [70/313], Loss: 0.8658, Acc: 72.30%\n",
      "Epoch [62/100], Step [80/313], Loss: 1.0850, Acc: 72.30%\n",
      "Epoch [62/100], Step [90/313], Loss: 0.7325, Acc: 72.54%\n",
      "Epoch [62/100], Step [100/313], Loss: 0.8563, Acc: 72.47%\n",
      "Epoch [62/100], Step [110/313], Loss: 0.9987, Acc: 72.43%\n",
      "Epoch [62/100], Step [120/313], Loss: 0.8904, Acc: 72.39%\n",
      "Epoch [62/100], Step [130/313], Loss: 0.8880, Acc: 72.43%\n",
      "Epoch [62/100], Step [140/313], Loss: 0.8635, Acc: 72.49%\n",
      "Epoch [62/100], Step [150/313], Loss: 1.0278, Acc: 72.39%\n",
      "Epoch [62/100], Step [160/313], Loss: 0.6722, Acc: 72.43%\n",
      "Epoch [62/100], Step [170/313], Loss: 0.8689, Acc: 72.31%\n",
      "Epoch [62/100], Step [180/313], Loss: 0.8819, Acc: 72.27%\n",
      "Epoch [62/100], Step [190/313], Loss: 0.6590, Acc: 72.51%\n",
      "Epoch [62/100], Step [200/313], Loss: 0.7351, Acc: 72.49%\n",
      "Epoch [62/100], Step [210/313], Loss: 0.9284, Acc: 72.54%\n",
      "Epoch [62/100], Step [220/313], Loss: 1.0811, Acc: 72.44%\n",
      "Epoch [62/100], Step [230/313], Loss: 0.8654, Acc: 72.45%\n",
      "Epoch [62/100], Step [240/313], Loss: 0.9370, Acc: 72.49%\n",
      "Epoch [62/100], Step [250/313], Loss: 0.8308, Acc: 72.63%\n",
      "Epoch [62/100], Step [260/313], Loss: 0.6630, Acc: 72.70%\n",
      "Epoch [62/100], Step [270/313], Loss: 0.7459, Acc: 72.71%\n",
      "Epoch [62/100], Step [280/313], Loss: 0.8743, Acc: 72.73%\n",
      "Epoch [62/100], Step [290/313], Loss: 0.7205, Acc: 72.74%\n",
      "Epoch [62/100], Step [300/313], Loss: 0.9463, Acc: 72.74%\n",
      "Epoch [62/100], Step [310/313], Loss: 1.1531, Acc: 72.71%\n",
      "Epoch [63/100], Step [10/313], Loss: 0.9145, Acc: 72.19%\n",
      "Epoch [63/100], Step [20/313], Loss: 1.1882, Acc: 72.30%\n",
      "Epoch [63/100], Step [30/313], Loss: 0.7554, Acc: 72.79%\n",
      "Epoch [63/100], Step [40/313], Loss: 0.8423, Acc: 72.77%\n",
      "Epoch [63/100], Step [50/313], Loss: 1.1784, Acc: 72.72%\n",
      "Epoch [63/100], Step [60/313], Loss: 0.9890, Acc: 72.67%\n",
      "Epoch [63/100], Step [70/313], Loss: 0.8361, Acc: 72.44%\n",
      "Epoch [63/100], Step [80/313], Loss: 1.0607, Acc: 72.46%\n",
      "Epoch [63/100], Step [90/313], Loss: 0.6711, Acc: 72.67%\n",
      "Epoch [63/100], Step [100/313], Loss: 0.9684, Acc: 72.68%\n",
      "Epoch [63/100], Step [110/313], Loss: 0.8786, Acc: 72.82%\n",
      "Epoch [63/100], Step [120/313], Loss: 0.9922, Acc: 72.71%\n",
      "Epoch [63/100], Step [130/313], Loss: 0.7641, Acc: 72.69%\n",
      "Epoch [63/100], Step [140/313], Loss: 0.7737, Acc: 72.69%\n",
      "Epoch [63/100], Step [150/313], Loss: 1.0089, Acc: 72.72%\n",
      "Epoch [63/100], Step [160/313], Loss: 0.7057, Acc: 72.83%\n",
      "Epoch [63/100], Step [170/313], Loss: 0.7128, Acc: 72.88%\n",
      "Epoch [63/100], Step [180/313], Loss: 0.8567, Acc: 72.73%\n",
      "Epoch [63/100], Step [190/313], Loss: 0.6991, Acc: 72.86%\n",
      "Epoch [63/100], Step [200/313], Loss: 0.7937, Acc: 72.75%\n",
      "Epoch [63/100], Step [210/313], Loss: 0.8195, Acc: 72.82%\n",
      "Epoch [63/100], Step [220/313], Loss: 0.9217, Acc: 72.74%\n",
      "Epoch [63/100], Step [230/313], Loss: 0.7051, Acc: 72.73%\n",
      "Epoch [63/100], Step [240/313], Loss: 0.9868, Acc: 72.72%\n",
      "Epoch [63/100], Step [250/313], Loss: 0.6835, Acc: 72.81%\n",
      "Epoch [63/100], Step [260/313], Loss: 0.7856, Acc: 72.83%\n",
      "Epoch [63/100], Step [270/313], Loss: 0.7729, Acc: 72.83%\n",
      "Epoch [63/100], Step [280/313], Loss: 0.9288, Acc: 72.93%\n",
      "Epoch [63/100], Step [290/313], Loss: 0.8128, Acc: 72.90%\n",
      "Epoch [63/100], Step [300/313], Loss: 1.0834, Acc: 72.90%\n",
      "Epoch [63/100], Step [310/313], Loss: 1.1339, Acc: 72.95%\n",
      "Epoch [64/100], Step [10/313], Loss: 0.8742, Acc: 73.20%\n",
      "Epoch [64/100], Step [20/313], Loss: 1.0263, Acc: 73.48%\n",
      "Epoch [64/100], Step [30/313], Loss: 0.8302, Acc: 74.17%\n",
      "Epoch [64/100], Step [40/313], Loss: 0.7957, Acc: 74.43%\n",
      "Epoch [64/100], Step [50/313], Loss: 0.9275, Acc: 74.78%\n",
      "Epoch [64/100], Step [60/313], Loss: 0.8677, Acc: 74.88%\n",
      "Epoch [64/100], Step [70/313], Loss: 0.8136, Acc: 74.71%\n",
      "Epoch [64/100], Step [80/313], Loss: 0.9743, Acc: 74.67%\n",
      "Epoch [64/100], Step [90/313], Loss: 0.6772, Acc: 74.63%\n",
      "Epoch [64/100], Step [100/313], Loss: 0.7881, Acc: 74.80%\n",
      "Epoch [64/100], Step [110/313], Loss: 0.9876, Acc: 74.79%\n",
      "Epoch [64/100], Step [120/313], Loss: 0.9859, Acc: 74.82%\n",
      "Epoch [64/100], Step [130/313], Loss: 0.8732, Acc: 74.86%\n",
      "Epoch [64/100], Step [140/313], Loss: 0.8500, Acc: 74.92%\n",
      "Epoch [64/100], Step [150/313], Loss: 1.0010, Acc: 74.72%\n",
      "Epoch [64/100], Step [160/313], Loss: 0.7929, Acc: 74.68%\n",
      "Epoch [64/100], Step [170/313], Loss: 0.8881, Acc: 74.54%\n",
      "Epoch [64/100], Step [180/313], Loss: 0.7619, Acc: 74.49%\n",
      "Epoch [64/100], Step [190/313], Loss: 0.7206, Acc: 74.58%\n",
      "Epoch [64/100], Step [200/313], Loss: 0.7553, Acc: 74.60%\n",
      "Epoch [64/100], Step [210/313], Loss: 0.7440, Acc: 74.71%\n",
      "Epoch [64/100], Step [220/313], Loss: 0.8810, Acc: 74.68%\n",
      "Epoch [64/100], Step [230/313], Loss: 0.9111, Acc: 74.56%\n",
      "Epoch [64/100], Step [240/313], Loss: 1.0143, Acc: 74.55%\n",
      "Epoch [64/100], Step [250/313], Loss: 0.6647, Acc: 74.59%\n",
      "Epoch [64/100], Step [260/313], Loss: 0.9186, Acc: 74.51%\n",
      "Epoch [64/100], Step [270/313], Loss: 0.8899, Acc: 74.48%\n",
      "Epoch [64/100], Step [280/313], Loss: 0.9103, Acc: 74.43%\n",
      "Epoch [64/100], Step [290/313], Loss: 0.7620, Acc: 74.42%\n",
      "Epoch [64/100], Step [300/313], Loss: 1.0349, Acc: 74.41%\n",
      "Epoch [64/100], Step [310/313], Loss: 1.0186, Acc: 74.39%\n",
      "Epoch [65/100], Step [10/313], Loss: 0.7393, Acc: 72.89%\n",
      "Epoch [65/100], Step [20/313], Loss: 0.9437, Acc: 74.30%\n",
      "Epoch [65/100], Step [30/313], Loss: 0.7630, Acc: 74.14%\n",
      "Epoch [65/100], Step [40/313], Loss: 0.9149, Acc: 73.46%\n",
      "Epoch [65/100], Step [50/313], Loss: 1.1239, Acc: 73.73%\n",
      "Epoch [65/100], Step [60/313], Loss: 0.8365, Acc: 73.85%\n",
      "Epoch [65/100], Step [70/313], Loss: 0.8363, Acc: 73.68%\n",
      "Epoch [65/100], Step [80/313], Loss: 0.9891, Acc: 73.88%\n",
      "Epoch [65/100], Step [90/313], Loss: 0.6345, Acc: 73.91%\n",
      "Epoch [65/100], Step [100/313], Loss: 1.0489, Acc: 73.82%\n",
      "Epoch [65/100], Step [110/313], Loss: 0.9323, Acc: 73.75%\n",
      "Epoch [65/100], Step [120/313], Loss: 0.9114, Acc: 73.82%\n",
      "Epoch [65/100], Step [130/313], Loss: 0.7757, Acc: 73.75%\n",
      "Epoch [65/100], Step [140/313], Loss: 0.8623, Acc: 73.89%\n",
      "Epoch [65/100], Step [150/313], Loss: 0.9427, Acc: 73.73%\n",
      "Epoch [65/100], Step [160/313], Loss: 0.6977, Acc: 73.84%\n",
      "Epoch [65/100], Step [170/313], Loss: 0.8348, Acc: 73.90%\n",
      "Epoch [65/100], Step [180/313], Loss: 0.8770, Acc: 73.79%\n",
      "Epoch [65/100], Step [190/313], Loss: 0.6772, Acc: 73.95%\n",
      "Epoch [65/100], Step [200/313], Loss: 0.7727, Acc: 73.93%\n",
      "Epoch [65/100], Step [210/313], Loss: 0.8726, Acc: 73.95%\n",
      "Epoch [65/100], Step [220/313], Loss: 0.9393, Acc: 73.91%\n",
      "Epoch [65/100], Step [230/313], Loss: 0.7266, Acc: 73.87%\n",
      "Epoch [65/100], Step [240/313], Loss: 0.9955, Acc: 73.94%\n",
      "Epoch [65/100], Step [250/313], Loss: 0.6881, Acc: 73.98%\n",
      "Epoch [65/100], Step [260/313], Loss: 0.8088, Acc: 73.96%\n",
      "Epoch [65/100], Step [270/313], Loss: 0.8174, Acc: 73.91%\n",
      "Epoch [65/100], Step [280/313], Loss: 0.8945, Acc: 73.96%\n",
      "Epoch [65/100], Step [290/313], Loss: 0.7724, Acc: 73.93%\n",
      "Epoch [65/100], Step [300/313], Loss: 0.8931, Acc: 73.95%\n",
      "Epoch [65/100], Step [310/313], Loss: 0.9303, Acc: 73.92%\n",
      "Epoch [66/100], Step [10/313], Loss: 0.7627, Acc: 74.77%\n",
      "Epoch [66/100], Step [20/313], Loss: 0.9781, Acc: 74.73%\n",
      "Epoch [66/100], Step [30/313], Loss: 0.7835, Acc: 75.13%\n",
      "Epoch [66/100], Step [40/313], Loss: 0.8905, Acc: 75.21%\n",
      "Epoch [66/100], Step [50/313], Loss: 1.1470, Acc: 74.98%\n",
      "Epoch [66/100], Step [60/313], Loss: 0.8561, Acc: 75.10%\n",
      "Epoch [66/100], Step [70/313], Loss: 0.7662, Acc: 74.96%\n",
      "Epoch [66/100], Step [80/313], Loss: 0.8989, Acc: 74.88%\n",
      "Epoch [66/100], Step [90/313], Loss: 0.7271, Acc: 74.98%\n",
      "Epoch [66/100], Step [100/313], Loss: 0.7656, Acc: 74.91%\n",
      "Epoch [66/100], Step [110/313], Loss: 0.8432, Acc: 74.90%\n",
      "Epoch [66/100], Step [120/313], Loss: 0.7089, Acc: 74.95%\n",
      "Epoch [66/100], Step [130/313], Loss: 0.7318, Acc: 74.89%\n",
      "Epoch [66/100], Step [140/313], Loss: 0.7234, Acc: 75.06%\n",
      "Epoch [66/100], Step [150/313], Loss: 0.8023, Acc: 75.02%\n",
      "Epoch [66/100], Step [160/313], Loss: 0.6237, Acc: 75.08%\n",
      "Epoch [66/100], Step [170/313], Loss: 0.7456, Acc: 74.93%\n",
      "Epoch [66/100], Step [180/313], Loss: 0.7911, Acc: 74.80%\n",
      "Epoch [66/100], Step [190/313], Loss: 0.7059, Acc: 74.97%\n",
      "Epoch [66/100], Step [200/313], Loss: 0.7412, Acc: 74.93%\n",
      "Epoch [66/100], Step [210/313], Loss: 0.7206, Acc: 75.04%\n",
      "Epoch [66/100], Step [220/313], Loss: 0.7358, Acc: 75.07%\n",
      "Epoch [66/100], Step [230/313], Loss: 0.8988, Acc: 75.06%\n",
      "Epoch [66/100], Step [240/313], Loss: 0.8936, Acc: 75.03%\n",
      "Epoch [66/100], Step [250/313], Loss: 0.7300, Acc: 75.11%\n",
      "Epoch [66/100], Step [260/313], Loss: 0.8095, Acc: 75.06%\n",
      "Epoch [66/100], Step [270/313], Loss: 0.7754, Acc: 75.00%\n",
      "Epoch [66/100], Step [280/313], Loss: 0.8234, Acc: 74.98%\n",
      "Epoch [66/100], Step [290/313], Loss: 0.7741, Acc: 74.96%\n",
      "Epoch [66/100], Step [300/313], Loss: 0.9009, Acc: 74.92%\n",
      "Epoch [66/100], Step [310/313], Loss: 1.1055, Acc: 74.90%\n",
      "Epoch [67/100], Step [10/313], Loss: 0.8141, Acc: 74.45%\n",
      "Epoch [67/100], Step [20/313], Loss: 0.9936, Acc: 74.30%\n",
      "Epoch [67/100], Step [30/313], Loss: 0.7593, Acc: 74.38%\n",
      "Epoch [67/100], Step [40/313], Loss: 0.7975, Acc: 74.38%\n",
      "Epoch [67/100], Step [50/313], Loss: 1.0366, Acc: 74.72%\n",
      "Epoch [67/100], Step [60/313], Loss: 0.9979, Acc: 74.77%\n",
      "Epoch [67/100], Step [70/313], Loss: 0.7444, Acc: 74.71%\n",
      "Epoch [67/100], Step [80/313], Loss: 0.9569, Acc: 74.78%\n",
      "Epoch [67/100], Step [90/313], Loss: 0.8446, Acc: 74.73%\n",
      "Epoch [67/100], Step [100/313], Loss: 0.8383, Acc: 74.83%\n",
      "Epoch [67/100], Step [110/313], Loss: 0.8407, Acc: 74.77%\n",
      "Epoch [67/100], Step [120/313], Loss: 1.0241, Acc: 74.73%\n",
      "Epoch [67/100], Step [130/313], Loss: 0.8082, Acc: 74.47%\n",
      "Epoch [67/100], Step [140/313], Loss: 0.8872, Acc: 74.61%\n",
      "Epoch [67/100], Step [150/313], Loss: 0.9948, Acc: 74.60%\n",
      "Epoch [67/100], Step [160/313], Loss: 0.5319, Acc: 74.69%\n",
      "Epoch [67/100], Step [170/313], Loss: 0.6677, Acc: 74.63%\n",
      "Epoch [67/100], Step [180/313], Loss: 0.6492, Acc: 74.65%\n",
      "Epoch [67/100], Step [190/313], Loss: 0.6710, Acc: 74.87%\n",
      "Epoch [67/100], Step [200/313], Loss: 0.7395, Acc: 74.95%\n",
      "Epoch [67/100], Step [210/313], Loss: 0.7666, Acc: 74.98%\n",
      "Epoch [67/100], Step [220/313], Loss: 0.7832, Acc: 74.97%\n",
      "Epoch [67/100], Step [230/313], Loss: 0.8289, Acc: 74.98%\n",
      "Epoch [67/100], Step [240/313], Loss: 0.9410, Acc: 75.00%\n",
      "Epoch [67/100], Step [250/313], Loss: 0.6263, Acc: 75.03%\n",
      "Epoch [67/100], Step [260/313], Loss: 0.6581, Acc: 75.06%\n",
      "Epoch [67/100], Step [270/313], Loss: 0.6936, Acc: 75.03%\n",
      "Epoch [67/100], Step [280/313], Loss: 0.7667, Acc: 74.99%\n",
      "Epoch [67/100], Step [290/313], Loss: 0.6563, Acc: 74.95%\n",
      "Epoch [67/100], Step [300/313], Loss: 0.9778, Acc: 74.93%\n",
      "Epoch [67/100], Step [310/313], Loss: 0.9135, Acc: 74.95%\n",
      "Epoch [68/100], Step [10/313], Loss: 0.7931, Acc: 75.47%\n",
      "Epoch [68/100], Step [20/313], Loss: 0.8071, Acc: 75.86%\n",
      "Epoch [68/100], Step [30/313], Loss: 0.7914, Acc: 75.86%\n",
      "Epoch [68/100], Step [40/313], Loss: 0.7709, Acc: 76.09%\n",
      "Epoch [68/100], Step [50/313], Loss: 0.9384, Acc: 76.34%\n",
      "Epoch [68/100], Step [60/313], Loss: 0.6966, Acc: 76.26%\n",
      "Epoch [68/100], Step [70/313], Loss: 0.9503, Acc: 75.65%\n",
      "Epoch [68/100], Step [80/313], Loss: 0.9611, Acc: 75.58%\n",
      "Epoch [68/100], Step [90/313], Loss: 0.5973, Acc: 75.86%\n",
      "Epoch [68/100], Step [100/313], Loss: 0.7049, Acc: 75.80%\n",
      "Epoch [68/100], Step [110/313], Loss: 0.8167, Acc: 75.83%\n",
      "Epoch [68/100], Step [120/313], Loss: 0.9379, Acc: 75.70%\n",
      "Epoch [68/100], Step [130/313], Loss: 0.6848, Acc: 75.69%\n",
      "Epoch [68/100], Step [140/313], Loss: 0.8610, Acc: 75.61%\n",
      "Epoch [68/100], Step [150/313], Loss: 0.8985, Acc: 75.68%\n",
      "Epoch [68/100], Step [160/313], Loss: 0.7734, Acc: 75.65%\n",
      "Epoch [68/100], Step [170/313], Loss: 0.6842, Acc: 75.64%\n",
      "Epoch [68/100], Step [180/313], Loss: 0.6948, Acc: 75.63%\n",
      "Epoch [68/100], Step [190/313], Loss: 0.8264, Acc: 75.75%\n",
      "Epoch [68/100], Step [200/313], Loss: 0.7564, Acc: 75.64%\n",
      "Epoch [68/100], Step [210/313], Loss: 0.8007, Acc: 75.60%\n",
      "Epoch [68/100], Step [220/313], Loss: 0.9317, Acc: 75.55%\n",
      "Epoch [68/100], Step [230/313], Loss: 0.6462, Acc: 75.56%\n",
      "Epoch [68/100], Step [240/313], Loss: 0.9820, Acc: 75.54%\n",
      "Epoch [68/100], Step [250/313], Loss: 0.6718, Acc: 75.56%\n",
      "Epoch [68/100], Step [260/313], Loss: 0.7785, Acc: 75.55%\n",
      "Epoch [68/100], Step [270/313], Loss: 0.6693, Acc: 75.52%\n",
      "Epoch [68/100], Step [280/313], Loss: 0.6927, Acc: 75.54%\n",
      "Epoch [68/100], Step [290/313], Loss: 0.7883, Acc: 75.46%\n",
      "Epoch [68/100], Step [300/313], Loss: 0.9337, Acc: 75.44%\n",
      "Epoch [68/100], Step [310/313], Loss: 1.0674, Acc: 75.41%\n",
      "Epoch [69/100], Step [10/313], Loss: 0.8875, Acc: 74.14%\n",
      "Epoch [69/100], Step [20/313], Loss: 1.0204, Acc: 74.45%\n",
      "Epoch [69/100], Step [30/313], Loss: 0.8227, Acc: 74.74%\n",
      "Epoch [69/100], Step [40/313], Loss: 0.8487, Acc: 75.04%\n",
      "Epoch [69/100], Step [50/313], Loss: 0.9959, Acc: 74.78%\n",
      "Epoch [69/100], Step [60/313], Loss: 0.7935, Acc: 74.92%\n",
      "Epoch [69/100], Step [70/313], Loss: 0.6835, Acc: 75.03%\n",
      "Epoch [69/100], Step [80/313], Loss: 0.7145, Acc: 75.00%\n",
      "Epoch [69/100], Step [90/313], Loss: 0.7136, Acc: 75.06%\n",
      "Epoch [69/100], Step [100/313], Loss: 0.7917, Acc: 75.23%\n",
      "Epoch [69/100], Step [110/313], Loss: 0.7543, Acc: 75.34%\n",
      "Epoch [69/100], Step [120/313], Loss: 0.8745, Acc: 75.20%\n",
      "Epoch [69/100], Step [130/313], Loss: 0.6932, Acc: 75.13%\n",
      "Epoch [69/100], Step [140/313], Loss: 1.0998, Acc: 75.20%\n",
      "Epoch [69/100], Step [150/313], Loss: 0.8421, Acc: 75.06%\n",
      "Epoch [69/100], Step [160/313], Loss: 0.6387, Acc: 75.15%\n",
      "Epoch [69/100], Step [170/313], Loss: 0.7494, Acc: 75.13%\n",
      "Epoch [69/100], Step [180/313], Loss: 0.7984, Acc: 75.13%\n",
      "Epoch [69/100], Step [190/313], Loss: 0.7568, Acc: 75.27%\n",
      "Epoch [69/100], Step [200/313], Loss: 0.7117, Acc: 75.27%\n",
      "Epoch [69/100], Step [210/313], Loss: 0.7800, Acc: 75.32%\n",
      "Epoch [69/100], Step [220/313], Loss: 1.0622, Acc: 75.21%\n",
      "Epoch [69/100], Step [230/313], Loss: 0.7335, Acc: 75.20%\n",
      "Epoch [69/100], Step [240/313], Loss: 0.9260, Acc: 75.20%\n",
      "Epoch [69/100], Step [250/313], Loss: 0.7091, Acc: 75.21%\n",
      "Epoch [69/100], Step [260/313], Loss: 0.8501, Acc: 75.12%\n",
      "Epoch [69/100], Step [270/313], Loss: 0.7127, Acc: 75.11%\n",
      "Epoch [69/100], Step [280/313], Loss: 0.7296, Acc: 75.12%\n",
      "Epoch [69/100], Step [290/313], Loss: 0.7748, Acc: 75.09%\n",
      "Epoch [69/100], Step [300/313], Loss: 0.9352, Acc: 75.07%\n",
      "Epoch [69/100], Step [310/313], Loss: 1.1741, Acc: 75.02%\n",
      "Epoch [70/100], Step [10/313], Loss: 0.7529, Acc: 74.92%\n",
      "Epoch [70/100], Step [20/313], Loss: 0.9503, Acc: 75.43%\n",
      "Epoch [70/100], Step [30/313], Loss: 0.7998, Acc: 75.47%\n",
      "Epoch [70/100], Step [40/313], Loss: 0.7575, Acc: 75.59%\n",
      "Epoch [70/100], Step [50/313], Loss: 1.0672, Acc: 75.30%\n",
      "Epoch [70/100], Step [60/313], Loss: 0.8405, Acc: 75.29%\n",
      "Epoch [70/100], Step [70/313], Loss: 0.7587, Acc: 74.97%\n",
      "Epoch [70/100], Step [80/313], Loss: 0.8634, Acc: 75.16%\n",
      "Epoch [70/100], Step [90/313], Loss: 0.7156, Acc: 75.34%\n",
      "Epoch [70/100], Step [100/313], Loss: 0.8153, Acc: 75.32%\n",
      "Epoch [70/100], Step [110/313], Loss: 0.7568, Acc: 75.53%\n",
      "Epoch [70/100], Step [120/313], Loss: 1.0149, Acc: 75.40%\n",
      "Epoch [70/100], Step [130/313], Loss: 0.7310, Acc: 75.27%\n",
      "Epoch [70/100], Step [140/313], Loss: 0.9047, Acc: 75.35%\n",
      "Epoch [70/100], Step [150/313], Loss: 1.0632, Acc: 75.16%\n",
      "Epoch [70/100], Step [160/313], Loss: 0.6739, Acc: 75.07%\n",
      "Epoch [70/100], Step [170/313], Loss: 0.6764, Acc: 75.00%\n",
      "Epoch [70/100], Step [180/313], Loss: 0.7688, Acc: 74.93%\n",
      "Epoch [70/100], Step [190/313], Loss: 0.7214, Acc: 75.01%\n",
      "Epoch [70/100], Step [200/313], Loss: 0.7631, Acc: 75.01%\n",
      "Epoch [70/100], Step [210/313], Loss: 0.6695, Acc: 75.05%\n",
      "Epoch [70/100], Step [220/313], Loss: 0.7369, Acc: 75.04%\n",
      "Epoch [70/100], Step [230/313], Loss: 0.6628, Acc: 75.06%\n",
      "Epoch [70/100], Step [240/313], Loss: 0.7785, Acc: 75.14%\n",
      "Epoch [70/100], Step [250/313], Loss: 0.7060, Acc: 75.23%\n",
      "Epoch [70/100], Step [260/313], Loss: 0.7207, Acc: 75.14%\n",
      "Epoch [70/100], Step [270/313], Loss: 0.9340, Acc: 75.06%\n",
      "Epoch [70/100], Step [280/313], Loss: 0.7302, Acc: 75.10%\n",
      "Epoch [70/100], Step [290/313], Loss: 0.7246, Acc: 75.06%\n",
      "Epoch [70/100], Step [300/313], Loss: 0.9210, Acc: 75.04%\n",
      "Epoch [70/100], Step [310/313], Loss: 0.9845, Acc: 75.10%\n",
      "Epoch [71/100], Step [10/313], Loss: 0.7571, Acc: 74.06%\n",
      "Epoch [71/100], Step [20/313], Loss: 1.0793, Acc: 74.96%\n",
      "Epoch [71/100], Step [30/313], Loss: 0.7618, Acc: 75.78%\n",
      "Epoch [71/100], Step [40/313], Loss: 0.7159, Acc: 75.74%\n",
      "Epoch [71/100], Step [50/313], Loss: 0.9951, Acc: 75.70%\n",
      "Epoch [71/100], Step [60/313], Loss: 0.9206, Acc: 75.83%\n",
      "Epoch [71/100], Step [70/313], Loss: 0.8130, Acc: 75.35%\n",
      "Epoch [71/100], Step [80/313], Loss: 0.8623, Acc: 75.26%\n",
      "Epoch [71/100], Step [90/313], Loss: 0.6934, Acc: 75.31%\n",
      "Epoch [71/100], Step [100/313], Loss: 0.7520, Acc: 75.35%\n",
      "Epoch [71/100], Step [110/313], Loss: 0.7849, Acc: 75.45%\n",
      "Epoch [71/100], Step [120/313], Loss: 0.9985, Acc: 75.29%\n",
      "Epoch [71/100], Step [130/313], Loss: 0.7280, Acc: 75.18%\n",
      "Epoch [71/100], Step [140/313], Loss: 0.8820, Acc: 75.32%\n",
      "Epoch [71/100], Step [150/313], Loss: 0.8714, Acc: 75.28%\n",
      "Epoch [71/100], Step [160/313], Loss: 0.6825, Acc: 75.22%\n",
      "Epoch [71/100], Step [170/313], Loss: 0.8089, Acc: 75.15%\n",
      "Epoch [71/100], Step [180/313], Loss: 0.7697, Acc: 75.05%\n",
      "Epoch [71/100], Step [190/313], Loss: 0.6769, Acc: 75.14%\n",
      "Epoch [71/100], Step [200/313], Loss: 0.6630, Acc: 75.04%\n",
      "Epoch [71/100], Step [210/313], Loss: 0.7706, Acc: 75.04%\n",
      "Epoch [71/100], Step [220/313], Loss: 0.9569, Acc: 75.05%\n",
      "Epoch [71/100], Step [230/313], Loss: 0.6689, Acc: 75.15%\n",
      "Epoch [71/100], Step [240/313], Loss: 0.7900, Acc: 75.24%\n",
      "Epoch [71/100], Step [250/313], Loss: 0.6395, Acc: 75.34%\n",
      "Epoch [71/100], Step [260/313], Loss: 0.7651, Acc: 75.25%\n",
      "Epoch [71/100], Step [270/313], Loss: 0.7822, Acc: 75.12%\n",
      "Epoch [71/100], Step [280/313], Loss: 0.6186, Acc: 75.17%\n",
      "Epoch [71/100], Step [290/313], Loss: 0.7489, Acc: 75.10%\n",
      "Epoch [71/100], Step [300/313], Loss: 0.9526, Acc: 75.15%\n",
      "Epoch [71/100], Step [310/313], Loss: 1.0607, Acc: 75.13%\n",
      "Epoch [72/100], Step [10/313], Loss: 0.8044, Acc: 76.72%\n",
      "Epoch [72/100], Step [20/313], Loss: 1.0789, Acc: 75.62%\n",
      "Epoch [72/100], Step [30/313], Loss: 0.6491, Acc: 76.07%\n",
      "Epoch [72/100], Step [40/313], Loss: 0.8246, Acc: 75.94%\n",
      "Epoch [72/100], Step [50/313], Loss: 0.9775, Acc: 75.97%\n",
      "Epoch [72/100], Step [60/313], Loss: 0.7770, Acc: 76.32%\n",
      "Epoch [72/100], Step [70/313], Loss: 0.6871, Acc: 76.22%\n",
      "Epoch [72/100], Step [80/313], Loss: 0.7705, Acc: 76.23%\n",
      "Epoch [72/100], Step [90/313], Loss: 0.7379, Acc: 76.35%\n",
      "Epoch [72/100], Step [100/313], Loss: 0.8073, Acc: 76.40%\n",
      "Epoch [72/100], Step [110/313], Loss: 0.7192, Acc: 76.45%\n",
      "Epoch [72/100], Step [120/313], Loss: 0.8942, Acc: 76.45%\n",
      "Epoch [72/100], Step [130/313], Loss: 0.8588, Acc: 76.30%\n",
      "Epoch [72/100], Step [140/313], Loss: 0.8547, Acc: 76.34%\n",
      "Epoch [72/100], Step [150/313], Loss: 0.9184, Acc: 76.15%\n",
      "Epoch [72/100], Step [160/313], Loss: 0.6238, Acc: 76.09%\n",
      "Epoch [72/100], Step [170/313], Loss: 0.7080, Acc: 75.97%\n",
      "Epoch [72/100], Step [180/313], Loss: 0.8114, Acc: 75.99%\n",
      "Epoch [72/100], Step [190/313], Loss: 0.7291, Acc: 76.13%\n",
      "Epoch [72/100], Step [200/313], Loss: 0.6927, Acc: 76.09%\n",
      "Epoch [72/100], Step [210/313], Loss: 0.6373, Acc: 76.23%\n",
      "Epoch [72/100], Step [220/313], Loss: 1.0143, Acc: 76.18%\n",
      "Epoch [72/100], Step [230/313], Loss: 0.6478, Acc: 76.18%\n",
      "Epoch [72/100], Step [240/313], Loss: 0.8737, Acc: 76.20%\n",
      "Epoch [72/100], Step [250/313], Loss: 0.7036, Acc: 76.26%\n",
      "Epoch [72/100], Step [260/313], Loss: 0.7511, Acc: 76.26%\n",
      "Epoch [72/100], Step [270/313], Loss: 0.6717, Acc: 76.20%\n",
      "Epoch [72/100], Step [280/313], Loss: 0.8736, Acc: 76.12%\n",
      "Epoch [72/100], Step [290/313], Loss: 0.7705, Acc: 76.05%\n",
      "Epoch [72/100], Step [300/313], Loss: 0.8716, Acc: 76.02%\n",
      "Epoch [72/100], Step [310/313], Loss: 0.8682, Acc: 76.03%\n",
      "Epoch [73/100], Step [10/313], Loss: 0.8446, Acc: 77.42%\n",
      "Epoch [73/100], Step [20/313], Loss: 0.9317, Acc: 76.84%\n",
      "Epoch [73/100], Step [30/313], Loss: 0.6558, Acc: 76.46%\n",
      "Epoch [73/100], Step [40/313], Loss: 0.7609, Acc: 76.45%\n",
      "Epoch [73/100], Step [50/313], Loss: 1.1608, Acc: 76.66%\n",
      "Epoch [73/100], Step [60/313], Loss: 0.7891, Acc: 76.72%\n",
      "Epoch [73/100], Step [70/313], Loss: 0.7397, Acc: 76.61%\n",
      "Epoch [73/100], Step [80/313], Loss: 0.9030, Acc: 76.70%\n",
      "Epoch [73/100], Step [90/313], Loss: 0.7426, Acc: 76.64%\n",
      "Epoch [73/100], Step [100/313], Loss: 0.7029, Acc: 76.49%\n",
      "Epoch [73/100], Step [110/313], Loss: 0.8247, Acc: 76.72%\n",
      "Epoch [73/100], Step [120/313], Loss: 0.8050, Acc: 76.58%\n",
      "Epoch [73/100], Step [130/313], Loss: 0.6725, Acc: 76.44%\n",
      "Epoch [73/100], Step [140/313], Loss: 1.0091, Acc: 76.50%\n",
      "Epoch [73/100], Step [150/313], Loss: 0.9842, Acc: 76.32%\n",
      "Epoch [73/100], Step [160/313], Loss: 0.5901, Acc: 76.36%\n",
      "Epoch [73/100], Step [170/313], Loss: 0.7129, Acc: 76.19%\n",
      "Epoch [73/100], Step [180/313], Loss: 0.9207, Acc: 76.12%\n",
      "Epoch [73/100], Step [190/313], Loss: 0.8928, Acc: 76.19%\n",
      "Epoch [73/100], Step [200/313], Loss: 0.7210, Acc: 76.08%\n",
      "Epoch [73/100], Step [210/313], Loss: 0.7204, Acc: 76.03%\n",
      "Epoch [73/100], Step [220/313], Loss: 0.9057, Acc: 75.98%\n",
      "Epoch [73/100], Step [230/313], Loss: 0.6371, Acc: 75.99%\n",
      "Epoch [73/100], Step [240/313], Loss: 0.8699, Acc: 76.03%\n",
      "Epoch [73/100], Step [250/313], Loss: 0.6973, Acc: 76.13%\n",
      "Epoch [73/100], Step [260/313], Loss: 0.7059, Acc: 76.07%\n",
      "Epoch [73/100], Step [270/313], Loss: 0.5669, Acc: 75.97%\n",
      "Epoch [73/100], Step [280/313], Loss: 0.6178, Acc: 76.02%\n",
      "Epoch [73/100], Step [290/313], Loss: 0.7068, Acc: 75.93%\n",
      "Epoch [73/100], Step [300/313], Loss: 0.8817, Acc: 75.91%\n",
      "Epoch [73/100], Step [310/313], Loss: 1.0808, Acc: 75.88%\n",
      "Epoch [74/100], Step [10/313], Loss: 0.8185, Acc: 76.17%\n",
      "Epoch [74/100], Step [20/313], Loss: 0.9738, Acc: 76.33%\n",
      "Epoch [74/100], Step [30/313], Loss: 0.8126, Acc: 75.94%\n",
      "Epoch [74/100], Step [40/313], Loss: 0.6894, Acc: 75.94%\n",
      "Epoch [74/100], Step [50/313], Loss: 0.9321, Acc: 75.84%\n",
      "Epoch [74/100], Step [60/313], Loss: 0.7437, Acc: 76.13%\n",
      "Epoch [74/100], Step [70/313], Loss: 0.7641, Acc: 75.84%\n",
      "Epoch [74/100], Step [80/313], Loss: 0.8277, Acc: 75.91%\n",
      "Epoch [74/100], Step [90/313], Loss: 0.6220, Acc: 75.89%\n",
      "Epoch [74/100], Step [100/313], Loss: 0.7833, Acc: 75.92%\n",
      "Epoch [74/100], Step [110/313], Loss: 0.7491, Acc: 75.91%\n",
      "Epoch [74/100], Step [120/313], Loss: 0.9057, Acc: 75.77%\n",
      "Epoch [74/100], Step [130/313], Loss: 0.6968, Acc: 75.63%\n",
      "Epoch [74/100], Step [140/313], Loss: 0.9035, Acc: 75.77%\n",
      "Epoch [74/100], Step [150/313], Loss: 0.8391, Acc: 75.57%\n",
      "Epoch [74/100], Step [160/313], Loss: 0.6899, Acc: 75.58%\n",
      "Epoch [74/100], Step [170/313], Loss: 0.6407, Acc: 75.59%\n",
      "Epoch [74/100], Step [180/313], Loss: 0.7708, Acc: 75.60%\n",
      "Epoch [74/100], Step [190/313], Loss: 0.7526, Acc: 75.62%\n",
      "Epoch [74/100], Step [200/313], Loss: 0.6508, Acc: 75.64%\n",
      "Epoch [74/100], Step [210/313], Loss: 0.6880, Acc: 75.77%\n",
      "Epoch [74/100], Step [220/313], Loss: 0.7908, Acc: 75.74%\n",
      "Epoch [74/100], Step [230/313], Loss: 0.7576, Acc: 75.72%\n",
      "Epoch [74/100], Step [240/313], Loss: 0.7386, Acc: 75.74%\n",
      "Epoch [74/100], Step [250/313], Loss: 0.6753, Acc: 75.77%\n",
      "Epoch [74/100], Step [260/313], Loss: 0.6321, Acc: 75.77%\n",
      "Epoch [74/100], Step [270/313], Loss: 0.6987, Acc: 75.69%\n",
      "Epoch [74/100], Step [280/313], Loss: 0.8433, Acc: 75.66%\n",
      "Epoch [74/100], Step [290/313], Loss: 0.7587, Acc: 75.57%\n",
      "Epoch [74/100], Step [300/313], Loss: 0.8857, Acc: 75.65%\n",
      "Epoch [74/100], Step [310/313], Loss: 1.0924, Acc: 75.66%\n",
      "Epoch [75/100], Step [10/313], Loss: 0.8474, Acc: 77.27%\n",
      "Epoch [75/100], Step [20/313], Loss: 1.0116, Acc: 76.09%\n",
      "Epoch [75/100], Step [30/313], Loss: 0.7332, Acc: 76.43%\n",
      "Epoch [75/100], Step [40/313], Loss: 0.7950, Acc: 76.41%\n",
      "Epoch [75/100], Step [50/313], Loss: 1.1157, Acc: 76.41%\n",
      "Epoch [75/100], Step [60/313], Loss: 0.6700, Acc: 76.24%\n",
      "Epoch [75/100], Step [70/313], Loss: 0.6610, Acc: 76.00%\n",
      "Epoch [75/100], Step [80/313], Loss: 0.7518, Acc: 75.84%\n",
      "Epoch [75/100], Step [90/313], Loss: 0.8324, Acc: 76.02%\n",
      "Epoch [75/100], Step [100/313], Loss: 0.7669, Acc: 75.98%\n",
      "Epoch [75/100], Step [110/313], Loss: 0.7298, Acc: 76.04%\n",
      "Epoch [75/100], Step [120/313], Loss: 0.8642, Acc: 76.12%\n",
      "Epoch [75/100], Step [130/313], Loss: 0.6830, Acc: 76.15%\n",
      "Epoch [75/100], Step [140/313], Loss: 0.8248, Acc: 75.99%\n",
      "Epoch [75/100], Step [150/313], Loss: 0.9375, Acc: 75.82%\n",
      "Epoch [75/100], Step [160/313], Loss: 0.5851, Acc: 75.84%\n",
      "Epoch [75/100], Step [170/313], Loss: 0.7395, Acc: 75.81%\n",
      "Epoch [75/100], Step [180/313], Loss: 0.7743, Acc: 75.76%\n",
      "Epoch [75/100], Step [190/313], Loss: 0.6978, Acc: 75.88%\n",
      "Epoch [75/100], Step [200/313], Loss: 0.8042, Acc: 75.88%\n",
      "Epoch [75/100], Step [210/313], Loss: 0.7714, Acc: 75.97%\n",
      "Epoch [75/100], Step [220/313], Loss: 0.8928, Acc: 75.98%\n",
      "Epoch [75/100], Step [230/313], Loss: 0.6377, Acc: 76.04%\n",
      "Epoch [75/100], Step [240/313], Loss: 0.8111, Acc: 76.17%\n",
      "Epoch [75/100], Step [250/313], Loss: 0.6319, Acc: 76.24%\n",
      "Epoch [75/100], Step [260/313], Loss: 0.6705, Acc: 76.28%\n",
      "Epoch [75/100], Step [270/313], Loss: 0.7377, Acc: 76.30%\n",
      "Epoch [75/100], Step [280/313], Loss: 0.6971, Acc: 76.28%\n",
      "Epoch [75/100], Step [290/313], Loss: 0.6922, Acc: 76.21%\n",
      "Epoch [75/100], Step [300/313], Loss: 0.8538, Acc: 76.20%\n",
      "Epoch [75/100], Step [310/313], Loss: 1.0706, Acc: 76.20%\n",
      "Epoch [76/100], Step [10/313], Loss: 0.7096, Acc: 75.70%\n",
      "Epoch [76/100], Step [20/313], Loss: 0.9881, Acc: 75.90%\n",
      "Epoch [76/100], Step [30/313], Loss: 0.6394, Acc: 76.09%\n",
      "Epoch [76/100], Step [40/313], Loss: 0.7809, Acc: 76.19%\n",
      "Epoch [76/100], Step [50/313], Loss: 0.9619, Acc: 76.25%\n",
      "Epoch [76/100], Step [60/313], Loss: 0.7183, Acc: 76.51%\n",
      "Epoch [76/100], Step [70/313], Loss: 0.7675, Acc: 76.31%\n",
      "Epoch [76/100], Step [80/313], Loss: 0.8956, Acc: 76.44%\n",
      "Epoch [76/100], Step [90/313], Loss: 0.8066, Acc: 76.49%\n",
      "Epoch [76/100], Step [100/313], Loss: 0.7050, Acc: 76.45%\n",
      "Epoch [76/100], Step [110/313], Loss: 0.7924, Acc: 76.56%\n",
      "Epoch [76/100], Step [120/313], Loss: 0.7435, Acc: 76.46%\n",
      "Epoch [76/100], Step [130/313], Loss: 0.7287, Acc: 76.42%\n",
      "Epoch [76/100], Step [140/313], Loss: 0.8689, Acc: 76.50%\n",
      "Epoch [76/100], Step [150/313], Loss: 1.0554, Acc: 76.43%\n",
      "Epoch [76/100], Step [160/313], Loss: 0.6081, Acc: 76.43%\n",
      "Epoch [76/100], Step [170/313], Loss: 0.7182, Acc: 76.42%\n",
      "Epoch [76/100], Step [180/313], Loss: 0.7653, Acc: 76.36%\n",
      "Epoch [76/100], Step [190/313], Loss: 0.6372, Acc: 76.49%\n",
      "Epoch [76/100], Step [200/313], Loss: 0.8425, Acc: 76.48%\n",
      "Epoch [76/100], Step [210/313], Loss: 0.8706, Acc: 76.52%\n",
      "Epoch [76/100], Step [220/313], Loss: 0.8440, Acc: 76.53%\n",
      "Epoch [76/100], Step [230/313], Loss: 0.6558, Acc: 76.51%\n",
      "Epoch [76/100], Step [240/313], Loss: 0.8052, Acc: 76.57%\n",
      "Epoch [76/100], Step [250/313], Loss: 0.6615, Acc: 76.60%\n",
      "Epoch [76/100], Step [260/313], Loss: 0.6697, Acc: 76.63%\n",
      "Epoch [76/100], Step [270/313], Loss: 0.6442, Acc: 76.60%\n",
      "Epoch [76/100], Step [280/313], Loss: 0.8574, Acc: 76.56%\n",
      "Epoch [76/100], Step [290/313], Loss: 0.7466, Acc: 76.52%\n",
      "Epoch [76/100], Step [300/313], Loss: 0.8157, Acc: 76.48%\n",
      "Epoch [76/100], Step [310/313], Loss: 0.9017, Acc: 76.47%\n",
      "Epoch [77/100], Step [10/313], Loss: 0.8773, Acc: 77.66%\n",
      "Epoch [77/100], Step [20/313], Loss: 0.8125, Acc: 77.03%\n",
      "Epoch [77/100], Step [30/313], Loss: 0.7270, Acc: 76.93%\n",
      "Epoch [77/100], Step [40/313], Loss: 0.7237, Acc: 76.80%\n",
      "Epoch [77/100], Step [50/313], Loss: 1.0371, Acc: 77.20%\n",
      "Epoch [77/100], Step [60/313], Loss: 0.6760, Acc: 77.24%\n",
      "Epoch [77/100], Step [70/313], Loss: 0.7029, Acc: 77.23%\n",
      "Epoch [77/100], Step [80/313], Loss: 0.8470, Acc: 77.29%\n",
      "Epoch [77/100], Step [90/313], Loss: 0.8516, Acc: 77.18%\n",
      "Epoch [77/100], Step [100/313], Loss: 0.5886, Acc: 77.05%\n",
      "Epoch [77/100], Step [110/313], Loss: 0.8329, Acc: 76.86%\n",
      "Epoch [77/100], Step [120/313], Loss: 0.7592, Acc: 76.92%\n",
      "Epoch [77/100], Step [130/313], Loss: 0.6551, Acc: 76.89%\n",
      "Epoch [77/100], Step [140/313], Loss: 0.7621, Acc: 77.00%\n",
      "Epoch [77/100], Step [150/313], Loss: 0.8786, Acc: 76.84%\n",
      "Epoch [77/100], Step [160/313], Loss: 0.6461, Acc: 76.81%\n",
      "Epoch [77/100], Step [170/313], Loss: 0.7544, Acc: 76.72%\n",
      "Epoch [77/100], Step [180/313], Loss: 0.7101, Acc: 76.63%\n",
      "Epoch [77/100], Step [190/313], Loss: 0.6848, Acc: 76.72%\n",
      "Epoch [77/100], Step [200/313], Loss: 0.7462, Acc: 76.72%\n",
      "Epoch [77/100], Step [210/313], Loss: 0.8350, Acc: 76.75%\n",
      "Epoch [77/100], Step [220/313], Loss: 0.9021, Acc: 76.78%\n",
      "Epoch [77/100], Step [230/313], Loss: 0.7363, Acc: 76.83%\n",
      "Epoch [77/100], Step [240/313], Loss: 0.9519, Acc: 76.86%\n",
      "Epoch [77/100], Step [250/313], Loss: 0.6159, Acc: 76.91%\n",
      "Epoch [77/100], Step [260/313], Loss: 0.7254, Acc: 76.87%\n",
      "Epoch [77/100], Step [270/313], Loss: 0.7246, Acc: 76.83%\n",
      "Epoch [77/100], Step [280/313], Loss: 0.7052, Acc: 76.90%\n",
      "Epoch [77/100], Step [290/313], Loss: 0.7482, Acc: 76.90%\n",
      "Epoch [77/100], Step [300/313], Loss: 0.8172, Acc: 76.90%\n",
      "Epoch [77/100], Step [310/313], Loss: 0.9506, Acc: 76.90%\n",
      "Epoch [78/100], Step [10/313], Loss: 0.7306, Acc: 76.33%\n",
      "Epoch [78/100], Step [20/313], Loss: 0.9489, Acc: 75.98%\n",
      "Epoch [78/100], Step [30/313], Loss: 0.6840, Acc: 76.38%\n",
      "Epoch [78/100], Step [40/313], Loss: 0.7795, Acc: 76.21%\n",
      "Epoch [78/100], Step [50/313], Loss: 0.9209, Acc: 76.58%\n",
      "Epoch [78/100], Step [60/313], Loss: 0.5777, Acc: 77.17%\n",
      "Epoch [78/100], Step [70/313], Loss: 0.6529, Acc: 77.11%\n",
      "Epoch [78/100], Step [80/313], Loss: 0.8238, Acc: 77.16%\n",
      "Epoch [78/100], Step [90/313], Loss: 0.5845, Acc: 77.19%\n",
      "Epoch [78/100], Step [100/313], Loss: 0.7116, Acc: 77.37%\n",
      "Epoch [78/100], Step [110/313], Loss: 0.6565, Acc: 77.39%\n",
      "Epoch [78/100], Step [120/313], Loss: 0.8887, Acc: 77.32%\n",
      "Epoch [78/100], Step [130/313], Loss: 0.7540, Acc: 77.31%\n",
      "Epoch [78/100], Step [140/313], Loss: 0.9243, Acc: 77.22%\n",
      "Epoch [78/100], Step [150/313], Loss: 0.9301, Acc: 77.06%\n",
      "Epoch [78/100], Step [160/313], Loss: 0.5000, Acc: 77.11%\n",
      "Epoch [78/100], Step [170/313], Loss: 0.7543, Acc: 77.03%\n",
      "Epoch [78/100], Step [180/313], Loss: 0.7726, Acc: 76.99%\n",
      "Epoch [78/100], Step [190/313], Loss: 0.6416, Acc: 77.06%\n",
      "Epoch [78/100], Step [200/313], Loss: 0.7781, Acc: 77.08%\n",
      "Epoch [78/100], Step [210/313], Loss: 0.7851, Acc: 77.20%\n",
      "Epoch [78/100], Step [220/313], Loss: 0.8512, Acc: 77.19%\n",
      "Epoch [78/100], Step [230/313], Loss: 0.6675, Acc: 77.18%\n",
      "Epoch [78/100], Step [240/313], Loss: 0.7625, Acc: 77.27%\n",
      "Epoch [78/100], Step [250/313], Loss: 0.5861, Acc: 77.35%\n",
      "Epoch [78/100], Step [260/313], Loss: 0.6977, Acc: 77.32%\n",
      "Epoch [78/100], Step [270/313], Loss: 0.7901, Acc: 77.24%\n",
      "Epoch [78/100], Step [280/313], Loss: 0.5447, Acc: 77.21%\n",
      "Epoch [78/100], Step [290/313], Loss: 0.7036, Acc: 77.12%\n",
      "Epoch [78/100], Step [300/313], Loss: 0.9096, Acc: 77.08%\n",
      "Epoch [78/100], Step [310/313], Loss: 0.9556, Acc: 77.05%\n",
      "Epoch [79/100], Step [10/313], Loss: 0.7593, Acc: 77.03%\n",
      "Epoch [79/100], Step [20/313], Loss: 0.9221, Acc: 76.72%\n",
      "Epoch [79/100], Step [30/313], Loss: 0.6408, Acc: 77.16%\n",
      "Epoch [79/100], Step [40/313], Loss: 0.6082, Acc: 77.23%\n",
      "Epoch [79/100], Step [50/313], Loss: 0.9351, Acc: 77.62%\n",
      "Epoch [79/100], Step [60/313], Loss: 0.6649, Acc: 77.57%\n",
      "Epoch [79/100], Step [70/313], Loss: 0.7616, Acc: 77.59%\n",
      "Epoch [79/100], Step [80/313], Loss: 0.6810, Acc: 77.78%\n",
      "Epoch [79/100], Step [90/313], Loss: 0.7026, Acc: 77.85%\n",
      "Epoch [79/100], Step [100/313], Loss: 0.6783, Acc: 77.63%\n",
      "Epoch [79/100], Step [110/313], Loss: 0.6199, Acc: 77.77%\n",
      "Epoch [79/100], Step [120/313], Loss: 0.7897, Acc: 77.76%\n",
      "Epoch [79/100], Step [130/313], Loss: 0.6477, Acc: 77.66%\n",
      "Epoch [79/100], Step [140/313], Loss: 1.0600, Acc: 77.61%\n",
      "Epoch [79/100], Step [150/313], Loss: 0.8387, Acc: 77.42%\n",
      "Epoch [79/100], Step [160/313], Loss: 0.6030, Acc: 77.33%\n",
      "Epoch [79/100], Step [170/313], Loss: 0.6760, Acc: 77.21%\n",
      "Epoch [79/100], Step [180/313], Loss: 0.6832, Acc: 77.10%\n",
      "Epoch [79/100], Step [190/313], Loss: 0.7136, Acc: 77.15%\n",
      "Epoch [79/100], Step [200/313], Loss: 0.6992, Acc: 77.06%\n",
      "Epoch [79/100], Step [210/313], Loss: 0.6888, Acc: 77.17%\n",
      "Epoch [79/100], Step [220/313], Loss: 0.8943, Acc: 77.16%\n",
      "Epoch [79/100], Step [230/313], Loss: 0.6086, Acc: 77.25%\n",
      "Epoch [79/100], Step [240/313], Loss: 0.7135, Acc: 77.20%\n",
      "Epoch [79/100], Step [250/313], Loss: 0.4615, Acc: 77.29%\n",
      "Epoch [79/100], Step [260/313], Loss: 0.6834, Acc: 77.25%\n",
      "Epoch [79/100], Step [270/313], Loss: 0.7427, Acc: 77.22%\n",
      "Epoch [79/100], Step [280/313], Loss: 0.6157, Acc: 77.21%\n",
      "Epoch [79/100], Step [290/313], Loss: 0.7402, Acc: 77.07%\n",
      "Epoch [79/100], Step [300/313], Loss: 0.8573, Acc: 77.05%\n",
      "Epoch [79/100], Step [310/313], Loss: 1.0543, Acc: 77.05%\n",
      "Epoch [80/100], Step [10/313], Loss: 0.9653, Acc: 75.86%\n",
      "Epoch [80/100], Step [20/313], Loss: 1.0079, Acc: 76.64%\n",
      "Epoch [80/100], Step [30/313], Loss: 0.7086, Acc: 75.99%\n",
      "Epoch [80/100], Step [40/313], Loss: 0.6759, Acc: 76.23%\n",
      "Epoch [80/100], Step [50/313], Loss: 1.0678, Acc: 76.20%\n",
      "Epoch [80/100], Step [60/313], Loss: 0.6420, Acc: 76.61%\n",
      "Epoch [80/100], Step [70/313], Loss: 0.8654, Acc: 76.52%\n",
      "Epoch [80/100], Step [80/313], Loss: 0.8484, Acc: 76.57%\n",
      "Epoch [80/100], Step [90/313], Loss: 0.6471, Acc: 76.92%\n",
      "Epoch [80/100], Step [100/313], Loss: 0.7369, Acc: 76.95%\n",
      "Epoch [80/100], Step [110/313], Loss: 0.6708, Acc: 77.16%\n",
      "Epoch [80/100], Step [120/313], Loss: 0.7477, Acc: 77.27%\n",
      "Epoch [80/100], Step [130/313], Loss: 0.7118, Acc: 77.25%\n",
      "Epoch [80/100], Step [140/313], Loss: 0.9661, Acc: 77.25%\n",
      "Epoch [80/100], Step [150/313], Loss: 0.9206, Acc: 77.27%\n",
      "Epoch [80/100], Step [160/313], Loss: 0.4863, Acc: 77.33%\n",
      "Epoch [80/100], Step [170/313], Loss: 0.7180, Acc: 77.39%\n",
      "Epoch [80/100], Step [180/313], Loss: 0.6977, Acc: 77.34%\n",
      "Epoch [80/100], Step [190/313], Loss: 0.6572, Acc: 77.43%\n",
      "Epoch [80/100], Step [200/313], Loss: 0.6877, Acc: 77.33%\n",
      "Epoch [80/100], Step [210/313], Loss: 0.8423, Acc: 77.40%\n",
      "Epoch [80/100], Step [220/313], Loss: 0.8140, Acc: 77.42%\n",
      "Epoch [80/100], Step [230/313], Loss: 0.5910, Acc: 77.43%\n",
      "Epoch [80/100], Step [240/313], Loss: 0.7251, Acc: 77.51%\n",
      "Epoch [80/100], Step [250/313], Loss: 0.5635, Acc: 77.53%\n",
      "Epoch [80/100], Step [260/313], Loss: 0.7944, Acc: 77.54%\n",
      "Epoch [80/100], Step [270/313], Loss: 0.7330, Acc: 77.59%\n",
      "Epoch [80/100], Step [280/313], Loss: 0.6881, Acc: 77.62%\n",
      "Epoch [80/100], Step [290/313], Loss: 0.6947, Acc: 77.63%\n",
      "Epoch [80/100], Step [300/313], Loss: 0.9447, Acc: 77.58%\n",
      "Epoch [80/100], Step [310/313], Loss: 1.0352, Acc: 77.57%\n",
      "Epoch [81/100], Step [10/313], Loss: 0.6931, Acc: 78.67%\n",
      "Epoch [81/100], Step [20/313], Loss: 0.8527, Acc: 77.93%\n",
      "Epoch [81/100], Step [30/313], Loss: 0.6757, Acc: 78.44%\n",
      "Epoch [81/100], Step [40/313], Loss: 0.6616, Acc: 77.81%\n",
      "Epoch [81/100], Step [50/313], Loss: 0.9254, Acc: 77.86%\n",
      "Epoch [81/100], Step [60/313], Loss: 0.6010, Acc: 78.15%\n",
      "Epoch [81/100], Step [70/313], Loss: 0.6958, Acc: 77.90%\n",
      "Epoch [81/100], Step [80/313], Loss: 0.6873, Acc: 78.10%\n",
      "Epoch [81/100], Step [90/313], Loss: 0.5463, Acc: 78.09%\n",
      "Epoch [81/100], Step [100/313], Loss: 0.8235, Acc: 77.98%\n",
      "Epoch [81/100], Step [110/313], Loss: 0.6961, Acc: 78.05%\n",
      "Epoch [81/100], Step [120/313], Loss: 0.7652, Acc: 78.05%\n",
      "Epoch [81/100], Step [130/313], Loss: 0.6396, Acc: 77.91%\n",
      "Epoch [81/100], Step [140/313], Loss: 0.8716, Acc: 77.99%\n",
      "Epoch [81/100], Step [150/313], Loss: 0.7314, Acc: 77.87%\n",
      "Epoch [81/100], Step [160/313], Loss: 0.5876, Acc: 77.99%\n",
      "Epoch [81/100], Step [170/313], Loss: 0.7143, Acc: 77.90%\n",
      "Epoch [81/100], Step [180/313], Loss: 0.6985, Acc: 77.85%\n",
      "Epoch [81/100], Step [190/313], Loss: 0.7497, Acc: 77.95%\n",
      "Epoch [81/100], Step [200/313], Loss: 0.6750, Acc: 77.86%\n",
      "Epoch [81/100], Step [210/313], Loss: 0.8541, Acc: 77.83%\n",
      "Epoch [81/100], Step [220/313], Loss: 0.9201, Acc: 77.76%\n",
      "Epoch [81/100], Step [230/313], Loss: 0.6058, Acc: 77.71%\n",
      "Epoch [81/100], Step [240/313], Loss: 0.7695, Acc: 77.74%\n",
      "Epoch [81/100], Step [250/313], Loss: 0.6958, Acc: 77.72%\n",
      "Epoch [81/100], Step [260/313], Loss: 0.5872, Acc: 77.61%\n",
      "Epoch [81/100], Step [270/313], Loss: 0.6837, Acc: 77.57%\n",
      "Epoch [81/100], Step [280/313], Loss: 0.6770, Acc: 77.58%\n",
      "Epoch [81/100], Step [290/313], Loss: 0.6489, Acc: 77.47%\n",
      "Epoch [81/100], Step [300/313], Loss: 0.9194, Acc: 77.46%\n",
      "Epoch [81/100], Step [310/313], Loss: 0.9081, Acc: 77.46%\n",
      "Epoch [82/100], Step [10/313], Loss: 0.7878, Acc: 77.66%\n",
      "Epoch [82/100], Step [20/313], Loss: 0.8271, Acc: 77.58%\n",
      "Epoch [82/100], Step [30/313], Loss: 0.6820, Acc: 77.03%\n",
      "Epoch [82/100], Step [40/313], Loss: 0.7570, Acc: 76.27%\n",
      "Epoch [82/100], Step [50/313], Loss: 1.0556, Acc: 76.31%\n",
      "Epoch [82/100], Step [60/313], Loss: 0.6740, Acc: 76.73%\n",
      "Epoch [82/100], Step [70/313], Loss: 0.6540, Acc: 76.70%\n",
      "Epoch [82/100], Step [80/313], Loss: 0.8434, Acc: 76.88%\n",
      "Epoch [82/100], Step [90/313], Loss: 0.5910, Acc: 77.13%\n",
      "Epoch [82/100], Step [100/313], Loss: 0.6523, Acc: 77.15%\n",
      "Epoch [82/100], Step [110/313], Loss: 0.7069, Acc: 77.29%\n",
      "Epoch [82/100], Step [120/313], Loss: 0.7347, Acc: 77.55%\n",
      "Epoch [82/100], Step [130/313], Loss: 0.8337, Acc: 77.41%\n",
      "Epoch [82/100], Step [140/313], Loss: 0.7936, Acc: 77.45%\n",
      "Epoch [82/100], Step [150/313], Loss: 0.8684, Acc: 77.46%\n",
      "Epoch [82/100], Step [160/313], Loss: 0.6139, Acc: 77.44%\n",
      "Epoch [82/100], Step [170/313], Loss: 0.8408, Acc: 77.48%\n",
      "Epoch [82/100], Step [180/313], Loss: 0.6929, Acc: 77.49%\n",
      "Epoch [82/100], Step [190/313], Loss: 0.6488, Acc: 77.66%\n",
      "Epoch [82/100], Step [200/313], Loss: 0.7027, Acc: 77.72%\n",
      "Epoch [82/100], Step [210/313], Loss: 0.7053, Acc: 77.78%\n",
      "Epoch [82/100], Step [220/313], Loss: 0.8040, Acc: 77.88%\n",
      "Epoch [82/100], Step [230/313], Loss: 0.6050, Acc: 77.95%\n",
      "Epoch [82/100], Step [240/313], Loss: 0.7426, Acc: 77.99%\n",
      "Epoch [82/100], Step [250/313], Loss: 0.5261, Acc: 78.10%\n",
      "Epoch [82/100], Step [260/313], Loss: 0.6214, Acc: 78.09%\n",
      "Epoch [82/100], Step [270/313], Loss: 0.6363, Acc: 78.05%\n",
      "Epoch [82/100], Step [280/313], Loss: 0.5298, Acc: 78.05%\n",
      "Epoch [82/100], Step [290/313], Loss: 0.6536, Acc: 78.01%\n",
      "Epoch [82/100], Step [300/313], Loss: 0.8582, Acc: 77.93%\n",
      "Epoch [82/100], Step [310/313], Loss: 0.9869, Acc: 77.94%\n",
      "Epoch [83/100], Step [10/313], Loss: 0.6923, Acc: 77.03%\n",
      "Epoch [83/100], Step [20/313], Loss: 0.8431, Acc: 78.40%\n",
      "Epoch [83/100], Step [30/313], Loss: 0.6343, Acc: 77.99%\n",
      "Epoch [83/100], Step [40/313], Loss: 0.6808, Acc: 77.79%\n",
      "Epoch [83/100], Step [50/313], Loss: 0.8533, Acc: 77.66%\n",
      "Epoch [83/100], Step [60/313], Loss: 0.5650, Acc: 77.93%\n",
      "Epoch [83/100], Step [70/313], Loss: 0.5761, Acc: 78.01%\n",
      "Epoch [83/100], Step [80/313], Loss: 0.6660, Acc: 78.17%\n",
      "Epoch [83/100], Step [90/313], Loss: 0.6125, Acc: 78.18%\n",
      "Epoch [83/100], Step [100/313], Loss: 0.6835, Acc: 78.31%\n",
      "Epoch [83/100], Step [110/313], Loss: 0.7630, Acc: 78.30%\n",
      "Epoch [83/100], Step [120/313], Loss: 0.8135, Acc: 78.31%\n",
      "Epoch [83/100], Step [130/313], Loss: 0.7424, Acc: 78.37%\n",
      "Epoch [83/100], Step [140/313], Loss: 0.9589, Acc: 78.42%\n",
      "Epoch [83/100], Step [150/313], Loss: 0.8547, Acc: 78.18%\n",
      "Epoch [83/100], Step [160/313], Loss: 0.6322, Acc: 78.18%\n",
      "Epoch [83/100], Step [170/313], Loss: 0.8444, Acc: 78.13%\n",
      "Epoch [83/100], Step [180/313], Loss: 0.8102, Acc: 78.02%\n",
      "Epoch [83/100], Step [190/313], Loss: 0.7351, Acc: 78.05%\n",
      "Epoch [83/100], Step [200/313], Loss: 0.6973, Acc: 77.99%\n",
      "Epoch [83/100], Step [210/313], Loss: 0.7260, Acc: 78.02%\n",
      "Epoch [83/100], Step [220/313], Loss: 0.7589, Acc: 77.92%\n",
      "Epoch [83/100], Step [230/313], Loss: 0.6609, Acc: 77.98%\n",
      "Epoch [83/100], Step [240/313], Loss: 0.7466, Acc: 77.98%\n",
      "Epoch [83/100], Step [250/313], Loss: 0.5357, Acc: 78.06%\n",
      "Epoch [83/100], Step [260/313], Loss: 0.6659, Acc: 78.04%\n",
      "Epoch [83/100], Step [270/313], Loss: 0.6466, Acc: 78.04%\n",
      "Epoch [83/100], Step [280/313], Loss: 0.8134, Acc: 78.02%\n",
      "Epoch [83/100], Step [290/313], Loss: 0.5975, Acc: 78.01%\n",
      "Epoch [83/100], Step [300/313], Loss: 0.9092, Acc: 78.07%\n",
      "Epoch [83/100], Step [310/313], Loss: 0.9079, Acc: 78.06%\n",
      "Epoch [84/100], Step [10/313], Loss: 0.8728, Acc: 78.12%\n",
      "Epoch [84/100], Step [20/313], Loss: 0.6977, Acc: 78.48%\n",
      "Epoch [84/100], Step [30/313], Loss: 0.6578, Acc: 78.65%\n",
      "Epoch [84/100], Step [40/313], Loss: 0.6764, Acc: 78.32%\n",
      "Epoch [84/100], Step [50/313], Loss: 0.9928, Acc: 78.22%\n",
      "Epoch [84/100], Step [60/313], Loss: 0.6332, Acc: 78.27%\n",
      "Epoch [84/100], Step [70/313], Loss: 0.5527, Acc: 78.26%\n",
      "Epoch [84/100], Step [80/313], Loss: 0.7732, Acc: 78.28%\n",
      "Epoch [84/100], Step [90/313], Loss: 0.6689, Acc: 78.49%\n",
      "Epoch [84/100], Step [100/313], Loss: 0.5857, Acc: 78.38%\n",
      "Epoch [84/100], Step [110/313], Loss: 0.6250, Acc: 78.39%\n",
      "Epoch [84/100], Step [120/313], Loss: 0.8944, Acc: 78.44%\n",
      "Epoch [84/100], Step [130/313], Loss: 0.6452, Acc: 78.32%\n",
      "Epoch [84/100], Step [140/313], Loss: 0.7065, Acc: 78.31%\n",
      "Epoch [84/100], Step [150/313], Loss: 0.8347, Acc: 78.17%\n",
      "Epoch [84/100], Step [160/313], Loss: 0.6569, Acc: 78.24%\n",
      "Epoch [84/100], Step [170/313], Loss: 0.6981, Acc: 78.24%\n",
      "Epoch [84/100], Step [180/313], Loss: 0.6530, Acc: 78.22%\n",
      "Epoch [84/100], Step [190/313], Loss: 0.5452, Acc: 78.36%\n",
      "Epoch [84/100], Step [200/313], Loss: 0.7501, Acc: 78.20%\n",
      "Epoch [84/100], Step [210/313], Loss: 0.7165, Acc: 78.23%\n",
      "Epoch [84/100], Step [220/313], Loss: 0.9250, Acc: 78.22%\n",
      "Epoch [84/100], Step [230/313], Loss: 0.6328, Acc: 78.23%\n",
      "Epoch [84/100], Step [240/313], Loss: 0.8363, Acc: 78.23%\n",
      "Epoch [84/100], Step [250/313], Loss: 0.6056, Acc: 78.32%\n",
      "Epoch [84/100], Step [260/313], Loss: 0.6187, Acc: 78.29%\n",
      "Epoch [84/100], Step [270/313], Loss: 0.6309, Acc: 78.27%\n",
      "Epoch [84/100], Step [280/313], Loss: 0.5598, Acc: 78.32%\n",
      "Epoch [84/100], Step [290/313], Loss: 0.6132, Acc: 78.30%\n",
      "Epoch [84/100], Step [300/313], Loss: 0.8526, Acc: 78.36%\n",
      "Epoch [84/100], Step [310/313], Loss: 0.9542, Acc: 78.39%\n",
      "Epoch [85/100], Step [10/313], Loss: 0.6600, Acc: 79.61%\n",
      "Epoch [85/100], Step [20/313], Loss: 1.0041, Acc: 78.09%\n",
      "Epoch [85/100], Step [30/313], Loss: 0.7592, Acc: 78.18%\n",
      "Epoch [85/100], Step [40/313], Loss: 0.6487, Acc: 78.32%\n",
      "Epoch [85/100], Step [50/313], Loss: 0.9184, Acc: 78.44%\n",
      "Epoch [85/100], Step [60/313], Loss: 0.7053, Acc: 78.72%\n",
      "Epoch [85/100], Step [70/313], Loss: 0.8409, Acc: 78.78%\n",
      "Epoch [85/100], Step [80/313], Loss: 0.7196, Acc: 78.94%\n",
      "Epoch [85/100], Step [90/313], Loss: 0.7219, Acc: 79.03%\n",
      "Epoch [85/100], Step [100/313], Loss: 0.6167, Acc: 79.11%\n",
      "Epoch [85/100], Step [110/313], Loss: 0.6643, Acc: 79.09%\n",
      "Epoch [85/100], Step [120/313], Loss: 0.7621, Acc: 79.01%\n",
      "Epoch [85/100], Step [130/313], Loss: 0.5650, Acc: 78.95%\n",
      "Epoch [85/100], Step [140/313], Loss: 0.7013, Acc: 78.97%\n",
      "Epoch [85/100], Step [150/313], Loss: 0.8713, Acc: 78.88%\n",
      "Epoch [85/100], Step [160/313], Loss: 0.4921, Acc: 78.96%\n",
      "Epoch [85/100], Step [170/313], Loss: 0.8709, Acc: 78.96%\n",
      "Epoch [85/100], Step [180/313], Loss: 0.6905, Acc: 78.91%\n",
      "Epoch [85/100], Step [190/313], Loss: 0.6860, Acc: 79.02%\n",
      "Epoch [85/100], Step [200/313], Loss: 0.7249, Acc: 78.92%\n",
      "Epoch [85/100], Step [210/313], Loss: 0.7135, Acc: 78.90%\n",
      "Epoch [85/100], Step [220/313], Loss: 0.8843, Acc: 78.79%\n",
      "Epoch [85/100], Step [230/313], Loss: 0.6705, Acc: 78.76%\n",
      "Epoch [85/100], Step [240/313], Loss: 0.7964, Acc: 78.84%\n",
      "Epoch [85/100], Step [250/313], Loss: 0.4978, Acc: 78.93%\n",
      "Epoch [85/100], Step [260/313], Loss: 0.7123, Acc: 78.87%\n",
      "Epoch [85/100], Step [270/313], Loss: 0.6482, Acc: 78.88%\n",
      "Epoch [85/100], Step [280/313], Loss: 0.6144, Acc: 78.88%\n",
      "Epoch [85/100], Step [290/313], Loss: 0.6474, Acc: 78.80%\n",
      "Epoch [85/100], Step [300/313], Loss: 0.7658, Acc: 78.84%\n",
      "Epoch [85/100], Step [310/313], Loss: 1.0015, Acc: 78.91%\n",
      "Epoch [86/100], Step [10/313], Loss: 0.6727, Acc: 77.66%\n",
      "Epoch [86/100], Step [20/313], Loss: 0.8665, Acc: 78.20%\n",
      "Epoch [86/100], Step [30/313], Loss: 0.5965, Acc: 78.75%\n",
      "Epoch [86/100], Step [40/313], Loss: 0.6287, Acc: 78.48%\n",
      "Epoch [86/100], Step [50/313], Loss: 0.8718, Acc: 78.22%\n",
      "Epoch [86/100], Step [60/313], Loss: 0.5158, Acc: 78.52%\n",
      "Epoch [86/100], Step [70/313], Loss: 0.7230, Acc: 78.47%\n",
      "Epoch [86/100], Step [80/313], Loss: 0.6555, Acc: 78.74%\n",
      "Epoch [86/100], Step [90/313], Loss: 0.5391, Acc: 79.09%\n",
      "Epoch [86/100], Step [100/313], Loss: 0.7036, Acc: 79.07%\n",
      "Epoch [86/100], Step [110/313], Loss: 0.6420, Acc: 79.33%\n",
      "Epoch [86/100], Step [120/313], Loss: 0.7025, Acc: 79.38%\n",
      "Epoch [86/100], Step [130/313], Loss: 0.5389, Acc: 79.29%\n",
      "Epoch [86/100], Step [140/313], Loss: 0.7816, Acc: 79.45%\n",
      "Epoch [86/100], Step [150/313], Loss: 0.9492, Acc: 79.30%\n",
      "Epoch [86/100], Step [160/313], Loss: 0.5264, Acc: 79.24%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m correct \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     12\u001b[0m total \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 14\u001b[0m \u001b[39mfor\u001b[39;00m i, (inputs, labels) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     15\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     16\u001b[0m     inputs \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    677\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 678\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    679\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    680\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data0/tianjunchao/anaconda3/envs/tian/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/data0/tianjunchao/code/Tian-EEG-Image/prepare/eegdataset.py:233\u001b[0m, in \u001b[0;36mGeneralEEGPointDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    228\u001b[0m filepath \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepaths[idx]\n\u001b[1;32m    230\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filepath, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m    231\u001b[0m \n\u001b[1;32m    232\u001b[0m     \u001b[39m# 读取数据 [t, w, h]\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m     x \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m    235\u001b[0m     \u001b[39m# 去除边缘\u001b[39;00m\n\u001b[1;32m    236\u001b[0m     x \u001b[39m=\u001b[39m x[:, \u001b[39m2\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)\n",
    "model = MLPModel(input_size, hidden_size, num_classes).to(device)\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    # compute acc\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs = inputs.squeeze()\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 统计预测信息\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 反向传播并优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 10 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}%'\n",
    "                     .format(epoch+1, num_epochs, i+1, total_step, loss.item(), 100 * correct / total))\n",
    "        \n",
    "    # test model\n",
    "    # model.eval()\n",
    "    # with torch.no_grad():\n",
    "    #     correct = 0\n",
    "    #     total = 0\n",
    "    #     for inputs, labels in train_loader:\n",
    "    #         inputs = inputs.squeeze()\n",
    "    #         inputs = inputs.to(device)\n",
    "    #         labels = labels.to(device)\n",
    "    #         outputs = model(inputs)\n",
    "    #         _, predicted = torch.max(outputs.data, 1)\n",
    "    #         total += labels.size(0)\n",
    "    #         correct += (predicted == labels).sum().item()\n",
    "    #     print('Test Accuracy of the model on the train images: {} %'.format(100 * correct / total))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tian",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
